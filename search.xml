<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[A gentle guide to the Python features]]></title>
    <url>%2F2019%2F11%2F14%2Fpython-is-cool%2F</url>
    <content type="text"><![CDATA[沈阳下雪了。 原文地址：github Lambda, map, filter, reduceThe lambda keyword is used to create inline functions. The functionssquare_fn and square_ld below are identical. 1234567def square_fn(x): return x * xsquare_ld = lambda x: x * xfor i in range(10): assert square_fn(i) == square_ld(i) Its quick declaration makes lambda functions ideal for use in callbacks, and when functions are to be passed as arguments to other functions. They are especially useful when used in conjunction with functions like map, filter, and reduce. map(fn, iterable) applies the fn to all elements of the iterable (e.g. list, set, dictionary, tuple, string) and returns a map object. 12345nums = [1/3, 333/7, 2323/2230, 40/34, 2/3]nums_squared = [num * num for num in nums]print(nums_squared)==&gt; [0.1111111, 2263.04081632, 1.085147, 1.384083, 0.44444444] This is the same as calling using map with a callback function. 12345nums_squared_1 = map(square_fn, nums)nums_squared_2 = map(lambda x: x * x, nums)print(list(nums_squared_1))==&gt; [0.1111111, 2263.04081632, 1.085147, 1.384083, 0.44444444] You can also use map with more than one iterable. For example, if you want to calculate the mean squared error of a simple linear function f(x) = ax + b with the true label labels, these two methods are equivalent: 1234567891011121314151617a, b = 3, -0.5xs = [2, 3, 4, 5]labels = [6.4, 8.9, 10.9, 15.3]# Method 1: using a looperrors = []for i, x in enumerate(xs): errors.append((a * x + b - labels[i]) ** 2)result1 = sum(errors) ** 0.5 / len(xs)# Method 2: using mapdiffs = map(lambda x, y: (a * x + b - y) ** 2, xs, labels)result2 = sum(diffs) ** 0.5 / len(xs)print(result1, result2)==&gt; 0.35089172119045514 0.35089172119045514 Note that objects returned by map and filter are iterators, which means that their values aren’t stored but generated as needed. After you’ve called sum(diffs), diffs becomes empty. If you want to keep all elements in diffs, convert it to a list using list(diffs). filter(fn, iterable) works the same way as map, except that fn returns a boolean value and filter returns all the elements of the iterable for which the fn returns True. 1234bad_preds = filter(lambda x: x &gt; 0.5, errors)print(list(bad_preds))==&gt; [0.8100000000000006, 0.6400000000000011] reduce(fn, iterable, initializer) is used when we want to iteratively apply an operator to all elements in a list. For example, if we want to calculate the product of all elements in a list: 123456product = 1for num in nums: product *= numprint(product)==&gt; 12.95564683272412 This is equivalent to:12345from functools import reduceproduct = reduce(lambda x, y: x * y, nums)print(product)==&gt; 12.95564683272412 Note on the performance of lambda functions Lambda functions are meant for one time use. Each time lambda x: dosomething(x) is called, the function has to be created, which hurts the performance if you call lambda x: dosomething(x) multiple times (e.g. when you pass it inside reduce). When you assign a name to the lambda function as in fn = lambda x: dosomething(x), its performance is slightly slower than the same function defined using def, but the difference is negligible. See here. Even though I find lambdas cool, I personally recommend using named functions when you can for the sake of clarity. List manipulationPython lists are super cool. UnpackingWe can unpack a list by each element like this:12345elems = [1, 2, 3, 4]a, b, c, d = elemsprint(a, b, c, d)==&gt; 1 2 3 4 We can also unpack a list like this: 12345678a, *new_elems, d = elemsprint(a)print(new_elems)print(d)==&gt; 1 [2, 3] 4 SlicingWe know that we can reverse a list using [::-1]. 12345678elems = list(range(10))print(elems)==&gt; [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]print(elems[::-1])==&gt; [9, 8, 7, 6, 5, 4, 3, 2, 1, 0] The syntax [x:y:z] means \”take every zth element of a list from index x to index y\”. When z is negative, it indicates going backwards. When x isn’t specified, it defaults to the first element of the list in the direction you are traversing the list. When y isn’t specified, it defaults to the last element of the list. So if we want to take every 2th element of a list, we use [::2]. 12345678evens = elems[::2]print(evens)reversed_evens = elems[-2::-2]print(reversed_evens)==&gt; [0, 2, 4, 6, 8] [8, 6, 4, 2, 0] We can also use slicing to delete all the even numbers in the list. 1234del elems[::2]print(elems)==&gt; [1, 3, 5, 7, 9] InsertionWe can change the value of an element in a list to another value. 12345elems = list(range(10))elems[1] = 10print(elems)==&gt; [0, 10, 2, 3, 4, 5, 6, 7, 8, 9] If we want to replace the element at an index with multiple elements, e.g. replace the value 1 with 3 values 20, 30, 40: 12345elems = list(range(10))elems[1:2] = [20, 30, 40]print(elems)==&gt; [0, 20, 30, 40, 2, 3, 4, 5, 6, 7, 8, 9] If we want to insert 3 values 0.2, 0.3, 0.5 between element at index 0 and element at index 1: 12345elems = list(range(10))elems[1:1] = [0.2, 0.3, 0.5]print(elems)==&gt; [0, 0.2, 0.3, 0.5, 1, 2, 3, 4, 5, 6, 7, 8, 9] FlatteningWe can flatten a list of lists using sum. 1234list_of_lists = [[1], [2, 3], [4, 5, 6]]sum(list_of_lists, [])==&gt; [1, 2, 3, 4, 5, 6] If we have nested lists, we can recursively flatten it. That’s another beauty of lambda functions — we can use it in the same line as its creation. 123456nested_lists = [[1, 2], [[3, 4], [5, 6], [[7, 8], [9, 10], [[11, [12, 13]]]]]]flatten = lambda x: [y for l in x for y in flatten(l)] if type(x) is list else [x]flatten(nested_lists)# This line of code is from# https://github.com/sahands/python-by-example/blob/master/python-by-example.rst#flattening-lists List vs generatorTo illustrate the difference between a list and a generator, let’s look at an example of creating n-grams out of a list of tokens. One way to create n-grams is to use a sliding window. 123456789101112131415tokens = ['i', 'want', 'to', 'go', 'to', 'school']def ngrams(tokens, n): length = len(tokens) grams = [] for i in range(length - n + 1): grams.append(tokens[i:i+n]) return gramsprint(ngrams(tokens, 3))==&gt; [['i', 'want', 'to'], ['want', 'to', 'go'], ['to', 'go', 'to'], ['go', 'to', 'school']] In the above example, we have to store all the n-grams at the same time. If the text has m tokens, then the memory requirement is O(nm), which can be problematic when m is large. Instead of using a list to store all n-grams, we can use a generator that generates the next n-gram when it’s asked for. This is known as lazy evaluation. We can make the function ngrams returns a generator using the keyword yield. Then the memory requirement is O(m+n). 1234567891011121314151617def ngrams(tokens, n): length = len(tokens) for i in range(length - n + 1): yield tokens[i:i+n]ngrams_generator = ngrams(tokens, 3)print(ngrams_generator)==&gt; &lt;generator object ngrams at 0x1069b26d0&gt;for ngram in ngrams_generator: print(ngram)==&gt; ['i', 'want', 'to'] ['want', 'to', 'go'] ['to', 'go', 'to'] ['go', 'to', 'school'] Another way to generate n-grams is to use slices to create lists: [0, 1, ..., -n], [1, 2, ..., -n+1], …, [n-1, n, ..., -1], and then zip them together. 1234567891011121314151617def ngrams(tokens, n): length = len(tokens) slices = (tokens[i:length-n+i+1] for i in range(n)) return zip(*slices)ngrams_generator = ngrams(tokens, 3)print(ngrams_generator)==&gt; &lt;zip object at 0x1069a7dc8&gt; # zip objects are generatorsfor ngram in ngrams_generator: print(ngram)==&gt; ('i', 'want', 'to') ('want', 'to', 'go') ('to', 'go', 'to') ('go', 'to', 'school') Note that to create slices, we use (tokens[...] for i in range(n)) instead of [tokens[...] for i in range(n)]. [] is the normal list comprehension that returns a list. () returns a generator. Classes and magic methodsIn Python, magic methods are prefixed and suffixed with the double underscore __, also known as dunder. The most wellknown magic method is probably __init__. 12345678class Node: """ A struct to denote the node of a binary tree. It contains a value and pointers to left and right children. """ def __init__(self, value, left=None, right=None): self.value = value self.left = left self.right = right When we try to print out a Node object, however, it’s not very interpretable. 12root = Node(5)print(root) # &lt;__main__.Node object at 0x1069c4518&gt; Ideally, when user prints out a node, we want to print out the node’s value and the values of its children if it has children. To do so, we use the magic method __repr__, which must return a printable object, like string. 123456789101112131415161718class Node: """ A struct to denote the node of a binary tree. It contains a value and pointers to left and right children. """ def __init__(self, value, left=None, right=None): self.value = value self.left = left self.right = right def __repr__(self): strings = [f'value: &#123;self.value&#125;'] strings.append(f'left: &#123;self.left.value&#125;' if self.left else 'left: None') strings.append(f'right: &#123;self.right.value&#125;' if self.right else 'right: None') return ', '.join(strings)left = Node(4)root = Node(5, left)print(root) # value: 5, left: 4, right: None We’d also like to compare two nodes by comparing their values. To do so, we overload the operator == with __eq__, &lt; with __lt__, and &gt;= with __ge__. 123456789101112131415161718192021222324class Node: """ A struct to denote the node of a binary tree. It contains a value and pointers to left and right children. """ def __init__(self, value, left=None, right=None): self.value = value self.left = left self.right = right def __eq__(self, other): return self.value == other.value def __lt__(self, other): return self.value &lt; other.value def __ge__(self, other): return self.value &gt;= other.valueleft = Node(4)root = Node(5, left)print(left == root) # Falseprint(left &lt; root) # Trueprint(left &gt;= root) # False For a comprehensive list of supported magic methods here or see the official Python documentation here (slightly harder to read). Some of the methods that I highly recommend: __len__: to overload the len() function. __str__: to overload the str() function. __iter__: if you want to your objects to be iterators. This also allows you to call next() on your object. For classes like Node where we know for sure all the attributes they can support (in the case of Node, they are value, left, and right), we might want to use __slots__ to denote those values for both performance boost and memory saving. For a comprehensive understanding of pros and cons of __slots__, see this absolutely amazing answer by Aaron Hall on StackOverflow. 123456789class Node: """ A struct to denote the node of a binary tree. It contains a value and pointers to left and right children. """ __slots__ = ('value', 'left', 'right') def __init__(self, value, left=None, right=None): self.value = value self.left = left self.right = right local namespace, object’s attributesThe locals() function returns a dictionary containing the variables defined in the local namespace. 12345678910class Model1: def __init__(self, hidden_size=100, num_layers=3, learning_rate=3e-4): print(locals()) self.hidden_size = hidden_size self.num_layers = num_layers self.learning_rate = learning_ratemodel1 = Model1()==&gt; &#123;'learning_rate': 0.0003, 'num_layers': 3, 'hidden_size': 100, 'self': &lt;__main__.Model1 object at 0x1069b1470&gt;&#125; All attributes of an object are stored in its __dict__.123print(model1.__dict__)==&gt; &#123;'hidden_size': 100, 'num_layers': 3, 'learning_rate': 0.0003&#125; Note that manually assigning each of the arguments to an attribute can be quite tiring when the list of the arguments is large. To avoid this, we can directly assign the list of arguments to the object’s __dict__. 12345678910class Model2: def __init__(self, hidden_size=100, num_layers=3, learning_rate=3e-4): params = locals() del params['self'] self.__dict__ = paramsmodel2 = Model2()print(model2.__dict__)==&gt; &#123;'learning_rate': 0.0003, 'num_layers': 3, 'hidden_size': 100&#125; This can be especially convenient when the object is initiated using the catch-all **kwargs, though the use of **kwargs should be reduced to the minimum. 12345678class Model3: def __init__(self, **kwargs): self.__dict__ = kwargsmodel3 = Model3(hidden_size=100, num_layers=3, learning_rate=3e-4)print(model3.__dict__)==&gt; &#123;'hidden_size': 100, 'num_layers': 3, 'learning_rate': 0.0003&#125; Wild importOften, you run into this wild import * that looks something like this: file.py1from parts import * This is irresponsible because it will import everything in module, even the imports of that module. For example, if parts.py looks like this: parts.py1234567891011121314151617import numpyimport tensorflowclass Encoder: ...class Decoder: ...class Loss: ...def helper(*args, **kwargs): ...def utils(*args, **kwargs): ... Since parts.py doesn’t have __all__ specified, file.py will import Encoder, Decoder, Loss, utils, helper together with numpy and tensorflow. If we intend that only Encoder, Decoder, and Loss are ever to be imported and used in another module, we should specify that in parts.py using the __all__ keyword. parts.py123456 __all__ = ['Encoder', 'Decoder', 'Loss']import numpyimport tensorflowclass Encoder: ... Now, if some user irresponsibly does a wild import with parts, they can only import Encoder, Decoder, Loss. Personally, I also find __all__ helpful as it gives me an overview of the module.]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tensorflow Faster RCNN修改训练的类别数量]]></title>
    <url>%2F2019%2F11%2F10%2FFaster_RCNN_change_categorise_in_train%2F</url>
    <content type="text"><![CDATA[本文主要基于COCO数据集，需要某一类别或某几个类别的检测结果，所以针对特定的类别专门训练一个Faster RCNN的模型，后续可以针对特定的类别设置ancher和scale的大小以达到更好的效果。 源码地址：tf faster rcnn 训练要修改的文件：./tf-faster-rcnn/lib/datasets/coco.py 第39行： cats = self._COCO.loadCats(self._COCO.getCatIds()) 12345678910COCO.getCatIds?Signature: COCO.getCatIds(self, catNms=[], supNms=[], catIds=[])Docstring:filtering parameters. default skips that filter.:param catNms (str array) : get cats for given cat names:param supNms (str array) : get cats for given supercategory names:param catIds (int array) : get cats for given cat ids:return: ids (int array) : integer array of cat idsFile: d:\programs\anaconda3\envs\tensorflow1.x\lib\site-packages\pycocotools\coco.pyType: function 通过设置getCatIds的参数改变训练的类别，比如本例只训练一个检测person的模型，就改成cats = self._COCO.loadCats(self._COCO.getCatIds(catIds=[1]))，把需要训练的类别对应的id作为参数传入。 原始类别： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182coco.loadCats(coco.getCatIds())[&#123;'supercategory': 'person', 'id': 1, 'name': 'person'&#125;, &#123;'supercategory': 'vehicle', 'id': 2, 'name': 'bicycle'&#125;, &#123;'supercategory': 'vehicle', 'id': 3, 'name': 'car'&#125;, &#123;'supercategory': 'vehicle', 'id': 4, 'name': 'motorcycle'&#125;, &#123;'supercategory': 'vehicle', 'id': 5, 'name': 'airplane'&#125;, &#123;'supercategory': 'vehicle', 'id': 6, 'name': 'bus'&#125;, &#123;'supercategory': 'vehicle', 'id': 7, 'name': 'train'&#125;, &#123;'supercategory': 'vehicle', 'id': 8, 'name': 'truck'&#125;, &#123;'supercategory': 'vehicle', 'id': 9, 'name': 'boat'&#125;, &#123;'supercategory': 'outdoor', 'id': 10, 'name': 'traffic light'&#125;, &#123;'supercategory': 'outdoor', 'id': 11, 'name': 'fire hydrant'&#125;, &#123;'supercategory': 'outdoor', 'id': 13, 'name': 'stop sign'&#125;, &#123;'supercategory': 'outdoor', 'id': 14, 'name': 'parking meter'&#125;, &#123;'supercategory': 'outdoor', 'id': 15, 'name': 'bench'&#125;, &#123;'supercategory': 'animal', 'id': 16, 'name': 'bird'&#125;, &#123;'supercategory': 'animal', 'id': 17, 'name': 'cat'&#125;, &#123;'supercategory': 'animal', 'id': 18, 'name': 'dog'&#125;, &#123;'supercategory': 'animal', 'id': 19, 'name': 'horse'&#125;, &#123;'supercategory': 'animal', 'id': 20, 'name': 'sheep'&#125;, &#123;'supercategory': 'animal', 'id': 21, 'name': 'cow'&#125;, &#123;'supercategory': 'animal', 'id': 22, 'name': 'elephant'&#125;, &#123;'supercategory': 'animal', 'id': 23, 'name': 'bear'&#125;, &#123;'supercategory': 'animal', 'id': 24, 'name': 'zebra'&#125;, &#123;'supercategory': 'animal', 'id': 25, 'name': 'giraffe'&#125;, &#123;'supercategory': 'accessory', 'id': 27, 'name': 'backpack'&#125;, &#123;'supercategory': 'accessory', 'id': 28, 'name': 'umbrella'&#125;, &#123;'supercategory': 'accessory', 'id': 31, 'name': 'handbag'&#125;, &#123;'supercategory': 'accessory', 'id': 32, 'name': 'tie'&#125;, &#123;'supercategory': 'accessory', 'id': 33, 'name': 'suitcase'&#125;, &#123;'supercategory': 'sports', 'id': 34, 'name': 'frisbee'&#125;, &#123;'supercategory': 'sports', 'id': 35, 'name': 'skis'&#125;, &#123;'supercategory': 'sports', 'id': 36, 'name': 'snowboard'&#125;, &#123;'supercategory': 'sports', 'id': 37, 'name': 'sports ball'&#125;, &#123;'supercategory': 'sports', 'id': 38, 'name': 'kite'&#125;, &#123;'supercategory': 'sports', 'id': 39, 'name': 'baseball bat'&#125;, &#123;'supercategory': 'sports', 'id': 40, 'name': 'baseball glove'&#125;, &#123;'supercategory': 'sports', 'id': 41, 'name': 'skateboard'&#125;, &#123;'supercategory': 'sports', 'id': 42, 'name': 'surfboard'&#125;, &#123;'supercategory': 'sports', 'id': 43, 'name': 'tennis racket'&#125;, &#123;'supercategory': 'kitchen', 'id': 44, 'name': 'bottle'&#125;, &#123;'supercategory': 'kitchen', 'id': 46, 'name': 'wine glass'&#125;, &#123;'supercategory': 'kitchen', 'id': 47, 'name': 'cup'&#125;, &#123;'supercategory': 'kitchen', 'id': 48, 'name': 'fork'&#125;, &#123;'supercategory': 'kitchen', 'id': 49, 'name': 'knife'&#125;, &#123;'supercategory': 'kitchen', 'id': 50, 'name': 'spoon'&#125;, &#123;'supercategory': 'kitchen', 'id': 51, 'name': 'bowl'&#125;, &#123;'supercategory': 'food', 'id': 52, 'name': 'banana'&#125;, &#123;'supercategory': 'food', 'id': 53, 'name': 'apple'&#125;, &#123;'supercategory': 'food', 'id': 54, 'name': 'sandwich'&#125;, &#123;'supercategory': 'food', 'id': 55, 'name': 'orange'&#125;, &#123;'supercategory': 'food', 'id': 56, 'name': 'broccoli'&#125;, &#123;'supercategory': 'food', 'id': 57, 'name': 'carrot'&#125;, &#123;'supercategory': 'food', 'id': 58, 'name': 'hot dog'&#125;, &#123;'supercategory': 'food', 'id': 59, 'name': 'pizza'&#125;, &#123;'supercategory': 'food', 'id': 60, 'name': 'donut'&#125;, &#123;'supercategory': 'food', 'id': 61, 'name': 'cake'&#125;, &#123;'supercategory': 'furniture', 'id': 62, 'name': 'chair'&#125;, &#123;'supercategory': 'furniture', 'id': 63, 'name': 'couch'&#125;, &#123;'supercategory': 'furniture', 'id': 64, 'name': 'potted plant'&#125;, &#123;'supercategory': 'furniture', 'id': 65, 'name': 'bed'&#125;, &#123;'supercategory': 'furniture', 'id': 67, 'name': 'dining table'&#125;, &#123;'supercategory': 'furniture', 'id': 70, 'name': 'toilet'&#125;, &#123;'supercategory': 'electronic', 'id': 72, 'name': 'tv'&#125;, &#123;'supercategory': 'electronic', 'id': 73, 'name': 'laptop'&#125;, &#123;'supercategory': 'electronic', 'id': 74, 'name': 'mouse'&#125;, &#123;'supercategory': 'electronic', 'id': 75, 'name': 'remote'&#125;, &#123;'supercategory': 'electronic', 'id': 76, 'name': 'keyboard'&#125;, &#123;'supercategory': 'electronic', 'id': 77, 'name': 'cell phone'&#125;, &#123;'supercategory': 'appliance', 'id': 78, 'name': 'microwave'&#125;, &#123;'supercategory': 'appliance', 'id': 79, 'name': 'oven'&#125;, &#123;'supercategory': 'appliance', 'id': 80, 'name': 'toaster'&#125;, &#123;'supercategory': 'appliance', 'id': 81, 'name': 'sink'&#125;, &#123;'supercategory': 'appliance', 'id': 82, 'name': 'refrigerator'&#125;, &#123;'supercategory': 'indoor', 'id': 84, 'name': 'book'&#125;, &#123;'supercategory': 'indoor', 'id': 85, 'name': 'clock'&#125;, &#123;'supercategory': 'indoor', 'id': 86, 'name': 'vase'&#125;, &#123;'supercategory': 'indoor', 'id': 87, 'name': 'scissors'&#125;, &#123;'supercategory': 'indoor', 'id': 88, 'name': 'teddy bear'&#125;, &#123;'supercategory': 'indoor', 'id': 89, 'name': 'hair drier'&#125;, &#123;'supercategory': 'indoor', 'id': 90, 'name': 'toothbrush'&#125;] 根据需要的类别的id设置输出参数，本例输出： 12coco.loadCats(coco.getCatIds(catIds=[1]))[&#123;'supercategory': 'person', 'id': 1, 'name': 'person'&#125;] 第42行： self._class_to_coco_cat_id = dict(list(zip([c[&#39;name&#39;] for c in cats], self._COCO.getCatIds()))) 修改为 self._class_to_coco_cat_id = dict(list(zip([c[&#39;name&#39;] for c in cats], self._COCO.getCatIds(catId=[1])))) 同样加入训练的类别参数。 第75行： image_ids = self._COCO.getImgIds() 修改为 image_ids = self._COCO.getImgIds(catIds=[1]) 只获取和person有关的图片。感觉这里不是非必要的，因为后续获取anno的信息也会传入类别。 第133行： annIds = self._COCO.getAnnIds(imgIds=index, iscrowd=None) 修改为 annIds = self._COCO.getAnnIds(imgIds=index, catIds=[1], iscrowd=None) 获取和person有关的标注信息，用于生成roidb训练RPN网络。 改完这四处就可以跑训练了。 1234567891011121314iter: 27300 / 490000, total loss: 0.481602 &gt;&gt;&gt; rpn_loss_cls: 0.035242 &gt;&gt;&gt; rpn_loss_box: 0.018606 &gt;&gt;&gt; loss_cls: 0.139855 &gt;&gt;&gt; loss_box: 0.159181 &gt;&gt;&gt; lr: 0.001000speed: 0.645s / iteriter: 27320 / 490000, total loss: 0.867995 &gt;&gt;&gt; rpn_loss_cls: 0.085730 &gt;&gt;&gt; rpn_loss_box: 0.067610 &gt;&gt;&gt; loss_cls: 0.204145 &gt;&gt;&gt; loss_box: 0.381795 &gt;&gt;&gt; lr: 0.001000speed: 0.645s / iter Note： 我是用COCO2017训练的，如果要用COCO2017，还需要改几处。 factory.py中加入COCO2017信息 修改coco.py中image_path_from_index函数获取的图片路径，COCO2017图片直接就是id，没有别的字符。 删除以前生成的文件和模型。 12rm -rf outputrm data/cache/*.pkl 测试修改demo文件，./tf-faster-rcnn/tools/demo.py 第33行： CLASS修改为自己训练设置的类别，比如我的 CLASSES = (&#39;__background__&#39;, &#39;person&#39;) 第40行： NET中模型名改成自己的。 可能遇到的问题： tensorflow.python.framework.errors_impl.InvalidArgumentError: Assign requires shapes of both tensors to match. lhs shape= [x] rhs shape= [y] 第141行： net.create_architecture(&quot;TEST&quot;, 21, tag=&#39;default&#39;, anchor_scales=[8, 16, 32])，将21改成自己类别的数量，本例__background__和person两个类别，就改成2。 anchor和scale设置引起的维度不匹配错误，训练和测试的anchor和scale要对应。]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>深度学习</tag>
        <tag>tensorflow</tag>
        <tag>Faster RCNN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode-Median of Two Sorted Arrays]]></title>
    <url>%2F2019%2F11%2F07%2FLeetcode004-Median%20of%20Two%20Sorted%20Arrays%2F</url>
    <content type="text"><![CDATA[数据分布都不明显，让机器怎么学。 ProblemMerge two sorted linked lists and return it as a new list. The new list should be made by splicing together the nodes of the first two lists. Example: There are two sorted arrays nums1 and nums2 of size m and n respectively. Find the median of the two sorted arrays. The overall run time complexity should be O(log (m+n)). You may assume nums1 and nums2 cannot be both empty. Example 1: 1234nums1 = [1, 3]nums2 = [2]The median is 2.0 Example 2: 1234nums1 = [1, 2]nums2 = [3, 4]The median is (2 + 3)/2 = 2.5 Process 合并两个有序的数组 找到数组的中位数 std::meger 1234567891011template &lt;class InputIterator1, class InputIterator2, class OutputIterator&gt; OutputIterator merge (InputIterator1 first1, InputIterator1 last1, InputIterator2 first2, InputIterator2 last2, OutputIterator result)&#123; while (true) &#123; if (first1==last1) return std::copy(first2,last2,result); if (first2==last2) return std::copy(first1,last1,result); *result++ = (*first2&lt;*first1)? *first2++ : *first1++; &#125;&#125; Parameters first1, last1 Input iterators to the initial and final positions of the first sorted sequence. The range used is [first1,last1), which contains all the elements between first1 and last1, including the element pointed by first1 but not the element pointed by last1. first2, last2 Input iterators to the initial and final positions of the second sorted sequence. The range used is [first2,last2). result Output iterator to the initial position of the range where the resulting combined range is stored. Its size is equal to the sum of both ranges above. comp Binary function that accepts two arguments of the types pointed by the iterators, and returns a value convertible to bool. The value returned indicates whether the first argument is considered to go before the second in the specific strict weak ordering it defines. The function shall not modify any of its arguments. This can either be a function pointer or a function object. Return value An iterator pointing to the past-the-end element in the resulting sequence. Solution1234567891011121314151617181920class Solution &#123;public: double findMedianSortedArrays(vector&lt;int&gt;&amp; nums1, vector&lt;int&gt;&amp; nums2) &#123; vector&lt;int&gt; merged; double median; merge(nums1.begin(), nums1.end(), nums2.begin(), nums2.end(), back_inserter(merged)); if (merged.size() % 2 == 0) &#123; median = (double)(merged[merged.size() / 2 - 1] + merged[merged.size() / 2]) / 2; &#125; else &#123; median = merged[(merged.size() - 1) / 2]; &#125; return median; &#125;&#125;; Result Time Submitted Status Runtime Memory Language a few seconds ago Accepted 24 ms 10.5 MB cpp SummaryTODO：Solution的解法如何实现。]]></content>
      <categories>
        <category>Leetcode</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python中super的使用]]></title>
    <url>%2F2019%2F10%2F29%2FUse-of-super-in-python%2F</url>
    <content type="text"><![CDATA[等终等于等明等白 调用父类的初始化方法继承父类后，直接调用父类的初始化方法。 定义一个人的类Person，包含人的名字和年龄，学生类Student继承自Person，多了一个分数变量： 1234567891011121314151617181920class Person(): def __init__(self, name, age): self.name = name self.age = age def info(self): print("Person\'s name is &#123;&#125;, person\'s age is &#123;&#125;".format(self.name, self.age))class Student(Person): def __init__(self, name, age, score): super().__init__(name, age) self.score = score def info(self): print("Student\'s name is &#123;&#125;, age is &#123;&#125;, score is &#123;&#125;".format(self.name, self.age, self.score)) p1 = Person("Zhangsan", 20)p1.info()&gt;&gt;&gt; Person's name is zhangsan, person's age is 20s1 = Student("Lisi", 18, 100)s1.info()&gt;&gt;&gt; Student's name is Lisi, age is 18, score is 100 同时实现父类功能如上一个示例，在Student类中重定义info方法直接就覆盖了父类Person中的info方法，如果需要同时实现父类的功能，就用super调用父类中的方法。只需要在Student中简单的修改下就可以： 123456789101112class Student(Person): def __init__(self, name, age, score): super().__init__(name, age) self.score = score def info(self): super().info() print("Student\'s score is &#123;&#125;".format(self.score)) s1 = Student("Lisi", 18, 100)s1.info()&gt;&gt;&gt; Person's name is Lisi, person's age is 18&gt;&gt;&gt; Student's score is 100 使用super避免了直接用父类的名去调用，方便修改。 在上面的情况下，super 获得的类刚好是父类，但在其他情况就不一定了，super 其实和父类没有实质性的关联。 多重继承 上面说到的例子是单继承，用父类名.属性的方法调用出来代码维护时繁琐一点也并无不可，但多重继承时，还用这种方法来调用父类属性就会就会带来许多问题。假如有以下4个类，箭头指向父类，要在各子类方法中显示调用父类： 12345678910111213141516171819202122232425262728293031323334353637class Base(): def fun(self): print("enter Base") print("leave Base") class A(Base): def fun(self): print("enter A") Base.fun(self) print("leave A") class B(Base): def fun(self): print("enter B") Base.fun(self) print("leave B") class C(A, B): def fun(self): print("enter C") A.fun(self) B.fun(self) print("leave C") c = C()c.fun()&gt;&gt;&gt; enter C&gt;&gt;&gt; enter A&gt;&gt;&gt; enter Base&gt;&gt;&gt; leave Base&gt;&gt;&gt; leave A&gt;&gt;&gt; enter B&gt;&gt;&gt; enter Base&gt;&gt;&gt; leave Base&gt;&gt;&gt; leave B&gt;&gt;&gt; leave C Base类被实例化了两次，发生菱形继承，出现调用不明确问题，并且会造成数据冗余的问题 。 MRO列表 对于定义的每一个类，Python 会计算出一个方法解析顺序（Method Resolution Order, MRO）列表，它代表了类继承的顺序，类C的MRO表： 12C.mro()&gt;&gt;&gt; [__main__.C, __main__.A, __main__.B, __main__.Base, object] MRO 列表通过C3线性化算法来实现的，一个类的 MRO 列表就是合并所有父类的 MRO 列表，并遵循以下三条原则： 子类永远在父类前面 如果有多个父类，会根据它们在列表中的顺序被检查。 如果对下一个类存在两个合法的选择，选择第一个父类。 当用super调用父类的方法时，会按照mro表中的元素顺序去挨个查找方法。 12345678910111213141516171819202122232425262728293031323334class Base(): def fun(self): print("enter Base") print("leave Base") class A(Base): def fun(self): print("enter A") super().fun() print("leave A") class B(Base): def fun(self): print("enter B") super().fun() print("leave B") class C(A, B): def fun(self): print("enter C") super().fun() print("leave C") c = C()c.fun()&gt;&gt;&gt; enter C&gt;&gt;&gt; enter A&gt;&gt;&gt; enter B&gt;&gt;&gt; enter Base&gt;&gt;&gt; leave Base&gt;&gt;&gt; leave B&gt;&gt;&gt; leave A&gt;&gt;&gt; leave C 为什么继承顺序是 $A \rightarrow B \rightarrow Base$ ? super原理super的工作原理如下： 123def super(cls, inst): mro = inst.__class__.mro() return mro[mro.index(cls) + 1] 其中，cls代表类，inst代表实例，上面的代码做了两件事： 获取inst的MRO列表 查找cls在当前MRO列表中的index, 并返回它的下一个类，即mro[index + 1] 当你使用 super(cls, inst) 时，Python 会在inst的 MRO 列表上搜索cls的下一个类。 所以根据MRO表，类C的下一个类是A，以此类推，得到 $A \rightarrow B \rightarrow Base$ 的继承顺序。 参考 python 中 super函数的使用 Python中super的用法 菱形继承问题和虚继承]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tensorflow compute_gradirnts和apply_gradients原理浅析]]></title>
    <url>%2F2019%2F10%2F29%2FTensorflow-compute-gradirnts-and-apply-gradients%2F</url>
    <content type="text"><![CDATA[转自TensorFlow学习笔记之—[compute_gradients和apply_gradients原理浅析] 最近在看fatser rcnn的源码，发现优化梯度的时候不是直接用的Optimizer.minimize()，而是先计算梯度Optimizer.compute_gradients()，然后Optimizer.apply_gradients()。 optimizer.minimizer(loss, var_list) 我们都知道，TensorFlow为我们提供了丰富的优化函数，例如GradientDescentOptimizer。这个方法会自动根据loss计算对应variable的导数。示例如下： 123456789loss = ...opt = tf.tf.train.GradientDescentOptimizer(learning_rate=0.1)train_op = opt.minimize(loss)init = tf.initialize_all_variables()with tf.Seesion() as sess: sess.run(init) for step in range(10): session.run(train_op) 首先我们看一下minimize()的源代码(为方便说明，部分参数已删除): 12345678910111213def minimize(self, loss, global_step=None, var_list=None, name=None): grads_and_vars = self.compute_gradients(loss, var_list=var_list) vars_with_grad = [v for g, v in grads_and_vars if g is not None] if not vars_with_grad: raise ValueError( "No gradients provided for any variable, check your graph for ops" " that do not support gradients, between variables %s and loss %s." % ([str(v) for _, v in grads_and_vars], loss)) return self.apply_gradients(grads_and_vars, global_step=global_step, name=name) 由源代码可以知道minimize()实际上包含了两个步骤，即compute_gradients和apply_gradients，前者用于计算梯度，后者用于使用计算得到的梯度来更新对应的variable。下面对这两个函数做具体介绍。 compute_gradients(loss, val_list)参数含义: loss: 需要被优化的Tensor val_list: Optional list or tuple of tf.Variable to update to minimize loss. Defaults to the list of variables collected in the graph under the key GraphKeys.TRAINABLE_VARIABLES. 简单说该函数就是用于计算loss对于指定val_list的导数的，最终返回的是元组列表，即[(gradient, variable),…]。 看下面的示例: 123456789x = tf.Variable(initial_value=50., dtype='float32')w = tf.Variable(initial_value=10., dtype='float32')y = w*xopt = tf.train.GradientDescentOptimizer(0.1)grad = opt.compute_gradients(y, [w,x])with tf.Session() as sess: sess.run(tf.global_variables_initializer()) print(sess.run(grad)) 返回值如下: 1&gt;&gt;&gt; [(50.0, 10.0), (10.0, 50.0)] 可以看到返回了一个list，list中的元素是元组。第一个元组第一个元素是50，表示∂y∂w∂y∂w的计算结果，第二个元素表示ww。第二个元组同理不做赘述。 其中tf.gradients(loss, tf.variables)的作用和这个函数类似,但是它只会返回计算得到的梯度，而不会返回对应的variable。 123456789101112131415with tf.Graph().as_default(): x = tf.Variable(initial_value=3., dtype='float32') w = tf.Variable(initial_value=4., dtype='float32') y = w*x grads = tf.gradients(y, [w]) print(grads) opt = tf.train.GradientDescentOptimizer(0.1) grads_vals = opt.compute_gradients(y, [w]) print(grad_vals)&gt;&gt;&gt;[&lt;tf.Tensor 'gradients/mul_grad/Mul:0' shape=() dtype=float32&gt;][(&lt;tf.Tensor 'gradients_1/mul_grad/tuple/control_dependency:0' shape=() dtype=float32&gt;, &lt;tf.Variable 'Variable_1:0' shape=() dtype=float32_ref&gt;)] apply_gradients(grads_and_vars,global_tep=None,name=None)该函数的作用是将compute_gradients()返回的值作为输入参数对variable进行更新。 那为什么minimize()会分开两个步骤呢？原因是因为在某些情况下我们需要对梯度做一定的修正，例如为了防止梯度消失(gradient vanishing)或者梯度爆炸(gradient explosion)，我们需要事先干预一下以免程序出现Nan的尴尬情况；有的时候也许我们需要给计算得到的梯度乘以一个权重或者其他乱七八糟的原因，所以才分开了两个步骤。 Example 下面给出一个使用tf.clip_by_norm来修正梯度的例子: 12345678910111213141516171819with tf.Graph().as_default(): x = tf.Variable(initial_value=3., dtype='float32') w = tf.Variable(initial_value=4., dtype='float32') y = w*x opt = tf.train.GradientDescentOptimizer(0.1) grads_vals = opt.compute_gradients(y, [w]) for i, (g, v) in enumerate(grads_vals): if g is not None: grads_vals[i] = (tf.clip_by_norm(g, 5), v) # clip gradients train_op = opt.apply_gradients(grads_vals) with tf.Session() as sess: sess.run(tf.global_variables_initializer()) print(sess.run(grads_vals)) print(sess.run([x,w,y])) &gt;&gt;&gt; [(3.0, 4.0)][3.0, 4.0, 12.0] 参考 TensorFlow中Optimizer.minimize()与Optimizer.compute_gradients()和Optimizer.apply_gradients()的用法 TensorFlow2.0笔记12：梯度下降,函数优化实战,手写数字问题实战以及Tensorboard可视化！]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>tensorflow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode042-Trapping Rain Water]]></title>
    <url>%2F2019%2F10%2F22%2FLeetcode042-Trapping-Rain-Water%2F</url>
    <content type="text"><![CDATA[努力，奋斗。 Note: 这是一个标准的错误答案，但是思路我觉得还可以，只是记录一下，方便日后学习。 还以为自己想到了一个不错的方法，现实又是一记重拳。 Problem Given n non-negative integers representing an elevation map where the width of each bar is 1, compute how much water it is able to trap after raining. The above elevation map is represented by array [0,1,0,2,1,0,1,3,2,1,2,1]. In this case, 6 units of rain water (blue section) are being trapped. Example: 12Input: [0,1,0,2,1,0,1,3,2,1,2,1]Output: 6 题读起来很简单，就是将黑色部分看成一个容器，计算容器中雨水（蓝色块）的数量。 Process思路1：暴力方法，就是从前往后一点点比较，但是设置的变量越来越多，用的有点懵， 而且最后那一部分出来起来实在是闲麻烦，突然就想到一层一层统计了。 思路2：每层是否有雨水，肯定与容器的高度有关，可以统计每层雨水的数量，只要两边被块包围，中间为空的地方肯定就是有雨水的；所以按照框的长度和最高的高度创建一个容器，根据每列数组的大小设置每列中1的数量，最后分层处理，也就是一行一行统计，求和得到雨水的水量。 没想到内存炸了。 SolutionNote: 这个解法内存占用没通过测试。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970class Solution &#123;public: int trap(vector&lt;int&gt;&amp; height) &#123; int water = 0; int max = 0; for (int val: height) &#123; if (val &gt; max) &#123; max = val; &#125; &#125; // 创建二维数组 vector &lt;vector&lt;int&gt; &gt; rain_arr; rain_arr.resize(max); for(int i = 0 ; i &lt; max; i++) &#123; rain_arr[i].resize(height.size()); &#125; // 二维数组赋值 for (int i = 0; i &lt; max; i++) &#123; for (int j = 0; j &lt; height.size(); j++) &#123; rain_arr[i][j] = 0; &#125; &#125; // 根据每个bar的大小为每一列添加bar个1 // 注意索引的变化 for (int i = 0; i &lt; height.size(); i++) &#123; for (int j = 0; j &lt; height[i]; j++) &#123; rain_arr[j][i] = 1; &#125; &#125; for (int i = 0; i &lt; max; i++) &#123; for (int j = 0; j &lt; height.size(); j++) &#123; cout &lt;&lt; rain_arr[i][j] &lt;&lt; " "; &#125; cout &lt;&lt; endl; &#125; for (int i = 0; i &lt; max; i++) &#123; // 这里怎么求起始1和结束1之间0的个数有问题 // 暂时用vector了 vector &lt;int&gt; index_one; for (int j = 0; j &lt; height.size(); j++) &#123; if (rain_arr[i][j] == 1) &#123; index_one.push_back(j); &#125; &#125; // cout &lt;&lt; index_one.back() &lt;&lt; ", " &lt;&lt; index_one.front() &lt;&lt; ", " &lt;&lt; index_one.size() &lt;&lt; endl; // front和back是第一个元素和最后一个元素的引用，不是begin和end water += index_one.back() - index_one.front() + 1 - index_one.size(); &#125; return water; &#125;&#125;; Result Time Submitted Status Runtime Memory Language 7 minutes ago Memory Limit Exceeded N/A N/A cpp 314 / 315 test cases passed. 证明思路还是对的。 Summary兜兜转转，坏消息好消息轮着来，好在可能离算法近了一步；常师兄说话和张老师好像，感觉他俩的性格就很合适一起合作。]]></content>
      <categories>
        <category>Leetcode</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[栈和队列的应用——二叉树的深度遍历和广度遍历]]></title>
    <url>%2F2019%2F10%2F19%2FTraversalOfBinaryTree%2F</url>
    <content type="text"><![CDATA[莫名其妙，可能这就是生活的意义。 还是昨天面试的问题，问完栈和队列，说栈和队列的应用，当时就想起了括号的匹配，没想到二叉树的深度遍历和广度遍历，这两种遍历方式分别对应的就是栈和队列的一个应用。 1. 深度优先遍历1.1 定义深度优先遍历：对每一个可能的分支路径深入到不能再深入为止，而且每个结点只能访问一次。深度优先遍历可以细分为先序遍历、中序遍历、后序遍历。具体说明如下： 先序遍历：对任一子树，先访问根，然后遍历其左子树，最后遍历其右子树。 中序遍历：对任一子树，先遍历其左子树，然后访问根，最后遍历其右子树。 后序遍历：对任一子树，先遍历其左子树，然后遍历其右子树，最后访问根。 1.2 实现 因为深度优先搜索算法是先访问根节点，接着遍历左子树再遍历右子树。因为栈是后进先出的结构，先将右子树压栈，再将左子树压栈，这样左子树就位于栈顶，可以保证先遍历左子树再遍历右子树。 12345678910111213141516void depthFirstTravel(Node* root)&#123; stack&lt;Node *&gt; nodeStack; nodeStack.push(root); Node *node; while(!nodeStack.empty())&#123; node = nodeStack.top(); cout &lt;&lt; node-&gt;key &lt;&lt; endl; nodeStack.pop(); if(node-&gt;rchild)&#123; nodeStack.push(node-&gt;rchild); &#125; if(node-&gt;lchild)&#123; nodeStack.push(node-&gt;lchild); &#125; &#125;&#125; 2. 广度优先遍历2.1 定义 从根节点开始，沿着树的宽度遍历树的节点，直到所有节点都被遍历完为止。 2.2 实现因为是一层一层遍历的，所以使用队列这种数据结构，先将一层节点放到队列中，当遍历完当前这一层后，再分别出队列，同时遍历当前节点的子节点，达到一层一层遍历的目的。若使用栈，压入第二层时，出栈就无法按照正常顺序输出了。你品，你细品。 12345678910111213141516void breadthFirstTravel(Node* root)&#123;queue&lt;Node *&gt; nodeQueue; nodeQueue.push(root); Node *node; while(!nodeQueue.empty())&#123; node = nodeQueue.front(); nodeQueue.pop(); cout &lt;&lt; node-&gt;key &lt;&lt; endl; if(node-&gt;lchild)&#123; nodeQueue.push(node-&gt;lchild); &#125; if(node-&gt;rchild)&#123; nodeQueue.push(node-&gt;rchild); &#125; &#125;&#125; 3. 完整实现以下图的二叉树为例。 二叉树节点定义： 12345678910111213struct STreeNode&#123; char key; pSTreeNode lchild; pSTreeNode rchild; STreeNode(char Value) &#123; key = Value; lchild = NULL; rchild = NULL; &#125;&#125;; 1234567891011121314151617181920212223242526272829303132333435#include &lt;iostream&gt;#include &lt;stack&gt;#include &lt;queue&gt;using namespace std;int main()&#123; Node *root = new Node('A'); root-&gt;lchild = new Node('B'); root-&gt;rchild = new Node('G'); Node *p = root-&gt;lchild; Node *q = root-&gt;rchild; p-&gt;lchild = new Node('C'); p-&gt;rchild = new Node('D'); p = p-&gt;rchild; p-&gt;lchild = new Node('E'); p-&gt;rchild = new Node('F'); q-&gt;lchild = new Node('H'); q-&gt;rchild = new Node('I'); cout &lt;&lt; "depthFirstTravel is: " &lt;&lt; endl; depthFirstTravel(root); cout &lt;&lt; endl; cout &lt;&lt; "breadthFirstTravel is: " &lt;&lt; endl; breadthFirstTravel(root); cout &lt;&lt; endl; system("pause"); return 0;&#125;// 结果// depthFirstTravel is:// A B C D E F G H I// breadthFirstTravel is:// A B G C D H I E F 参考[1] 二叉树的深度遍历和广度遍历 [2] 二叉树的深度优先遍历和广度优先遍历]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>面试题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++判断一个单链表是否有环]]></title>
    <url>%2F2019%2F10%2F18%2FC%2B%2Blinklist-has-hoop%2F</url>
    <content type="text"><![CDATA[基础薄弱。 面试时只想到了最简单的遍历方法，每遍历一个节点，都保存节点，到新节点时，从保存的节点中查找是否存在地址相同的，存在就是有环的，否则无环。问我有没有别的方法时，就想不到了。 有环链表 看图更直观。 1234567// 指针节点定义struct node&#123; int val; struct node *next; node(int x) : val(x), next(NULL) &#123;&#125;&#125;; 方法1定义一个快指针和一个慢指针，慢指针一次走一步，快指针一次走两步。如果快指针追上了慢指针，则链表有环；如果快指针走到末尾也没追上慢指针，则无环。 123456789101112131415161718192021222324252627282930bool IsLoop(node *head)&#123; if (head == NULL) &#123; return false; &#125; node *slow = head-&gt;next; if (slow == NULL) &#123; return false; &#125; node *fast = slow-&gt;next; while (fast != NULL &amp;&amp; slow != NULL) &#123; if (fast == slow) &#123; return true; &#125; slow = slow-&gt;next; fast = fast-&gt;next; if (fast != NULL) &#123; fast = fast-&gt;next; &#125; &#125; return false;&#125; 方法2 通过使用STL库中的map表进行映射。首先定义 map&lt;node *, int&gt; m; 将一个 node *指针映射成数组的下标，并赋值为一个 int类型的数值。然后从链表的头指针开始往后遍历，每次遇到一个指针p，就判断m[p]是否为0。如果为0，则将m[p]赋值为1，表示该节点第一次访问；而如果m[p]的值为1，则说明这个节点已经被访问过一次了，说明链表有环。 1234567891011121314151617181920212223bool IsLoop_2(node *head)&#123; map&lt;node *, int&gt; m; if (head == NULL) &#123; return false; &#125; node *p = head; while (p) &#123; if (m[p] == 0) &#123; m[p] = 1; &#125; else if (m[p] == 1) &#123; return true; &#125; p = p-&gt;next; &#125; return false;&#125; 测试123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778#include &lt;iostream&gt;#include &lt;map&gt;using namespace std;int main()&#123; //创建单链表 node *l1 = new node(0); node *p = l1; for (int i = 1; i &lt;= 7; i++) &#123; p-&gt;next = new node(i); p = p-&gt;next; &#125; //创建有环链表 node *l2 = new node(0); p = l2; for (int i = 1; i &lt;= 7; i++) &#123; p-&gt;next = new node(i); p = p-&gt;next; &#125; node *q = l2; for (int i = 0; i &lt; 4; i++) &#123; q = q-&gt;next; &#125; p-&gt;next = q; //输出链表 // q = l2; // while (q) // &#123; // cout &lt;&lt; q-&gt;val &lt;&lt; endl; // q = q-&gt;next; // &#125; if (IsLoop(l1)) &#123; cout &lt;&lt; "List l1 is a cycle chain" &lt;&lt; endl; &#125; else &#123; cout &lt;&lt; "List l1 is not a cycle chain" &lt;&lt; endl; &#125; if (IsLoop(l2)) &#123; cout &lt;&lt; "List l2 is a cycle chain" &lt;&lt; endl; &#125; else &#123; cout &lt;&lt; "List l2 is not a cycle chain" &lt;&lt; endl; &#125; if (IsLoop_2(l1)) &#123; cout &lt;&lt; "List l1 is a cycle chain" &lt;&lt; endl; &#125; else &#123; cout &lt;&lt; "List l1 is not a cycle chain" &lt;&lt; endl; &#125; if (IsLoop_2(l2)) &#123; cout &lt;&lt; "List l2 is a cycle chain" &lt;&lt; endl; &#125; else &#123; cout &lt;&lt; "List l2 is not a cycle chain" &lt;&lt; endl; &#125; system("pause"); return 0;&#125; 12345// 结果List l1 is not a cycle chainList l2 is a cycle chainList l1 is not a cycle chainList l2 is a cycle chain 参考[1] 如何判断链表有环 [2] 判断一个单链表是否有环，若有，找出环的入口节点]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>面试题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Weight Initialization in Neural Networks$:$ A Journey From the Basics to Kaiming(上)]]></title>
    <url>%2F2019%2F10%2F17%2Fweight-Initialization-1%2F</url>
    <content type="text"><![CDATA[或许去趟沙滩 或许去看看夕阳 或许任何一个可以想心事的地方 ​ ——《手写的从前》 原文链接点击前往。 本文通过简短的实验说明为什么适当的初始化权值在深度神经网络训练中如此重要。 分别用Tensorflow2.0和Pytorch实现。 Why Initialize Weight 权重初始化的目的是防止层激活输出在深度神经网络的正向传递过程中爆炸或消失。如果发生以上任何一种情况，损失梯度不是太大就是太小，无法有利地反向传播，如果发生了以上的情况，网络收敛则需要更长的时间。 矩阵乘法是神经网络的基本数学运算。在多层的深度神经网络中，一个前向传播需要在每一层上执行入和权重矩阵之间的矩阵乘法，得到的结果又作为下一层的输入，以此类推。 举一个简单的例子，假设我们有一个向量 $x$ 作为网络的输入。训练神经网络时的标准做法是对输入做一个处理，使它的值落在均值为 $0$、标准差为 $1$ 的正态分布内。 1234# pytorch输入th_x= torch.randn(512)# tensorflow输入tf_x = tf.random.normal([512, 1], mean=0.0, stddev=1.0) 12345678# 查看输入x的均值和标准差th_mean = th_x.mean()th_var = th_x.var()print('mean of th_x is &#123;:.5f&#125;, var of th_x is &#123;:.5f&#125;'.format(th_mean, th_var))# mean of th_x is -0.00323, var of th_x is 1.04362tf_mean, tf_var = tf.nn.moments(tf_x, axes=0)print('mean of tf_x is &#123;:.5f&#125;, var of tf_x is &#123;:.5f&#125;'.format(tf_mean[0], tf_var[0])) 假设我们有一个简单的 $100$ 层网络，没有激活函数，每一层都有一个矩阵 $a$ 作为权值。为了完成单个的前向传递，我们必须在层输入和每一层的权值之间执行一个矩阵乘法，这将产生总计 $100$ 个连续的矩阵乘法。 由此看出使用相同的标准正态分布处理输入并不是一个好的办法。为了找出原因，我们可以模拟前向传播通过我们假设的网络。 123456789101112131415# pytorchfor i in range(100): th_a = torch.randn(512, 512) th_x = th_a @ th_xprint(th_x.mean(), th_x.std())# tensor(nan) tensor(nan)th_x = torch.randn(512)for i in range(100): th_a = torch.randn(512, 512) th_x = th_a @ th_x if torch.isnan(th_x.std()): breaki# 28 1234567891011121314151617# tensorflowfor i in range(100): tf_a = tf.random.normal([512, 512]) tf_x = tf.matmul(tf_a, tf_x)tf_mean, tf_var = tf.nn.moments(tf_x,axes=0)print(tf_mean, tf_var)# tf.Tensor([nan], shape=(1,), dtype=float32) tf.Tensor([nan], shape=(1,), dtype=float32)tf_x = tf.random.normal([512, 1])for i in range(100): tf_a = tf.random.normal([512, 512]) tf_x = tf.matmul(tf_a, tf_x) tf_mean, tf_var = tf.nn.moments(tf_x,axes=0) if np.isnan(tf_var): break # 在tf2.0中没有找到判断nan的函数，使用numpy判断i# 27 网络在 $29$ （tensorflow在 $28$ 层）层输出已经爆炸了。 除了防止输出结果爆炸，还要防止输出消失。调整网络的权值，使它们仍然落在均值为0的正态分布内，但标准差为0.01 。 12345678# pytorchth_x = torch.randn(512)for i in range(100): th_a = torch.randn(512, 512) * 0.01 th_x = th_a @ th_xth_x.mean(), th_x.var()# (tensor(0.), tensor(0.)) 123456789# tensorflowtf_x = tf.random.normal([512, 1])for i in range(100): tf_a = tf.random.normal([512, 512], mean=0.0, stddev=0.01) tf_x = tf.matmul(tf_a, tf_x) tf_mean, tf_var = tf.nn.moments(tf_x,axes=0)tf_mean.numpy(), tf_var.numpy()# (array([0.], dtype=float32), array([0.], dtype=float32)) 在上面假设的正向传播过程中，激活输出完全消失。 总而言之，当权重初始化过大或过小时，网络都不能很好的学习。 How can we find the sweet spot? 如上所述，完成通过神经网络的前向传播所需要的数学只不过是一系列矩阵乘法。如果我们有一个输出 $y$ 是输入向量 $x$ 和权重矩阵 $a$ 之间的矩阵乘法的乘积， $y$ 中的每个元素 $i$ 被定义为 \begin{equation}\begin{split} y_i = \sum_{k=1}^{n-1}{a_{i,k}x_k} \end{split}\end{equation} 其中 $i$ 是给定的权矩阵 $a$ 的行索引，$k$ 是给定的权矩阵 $a$ 的列索引和输入向量 $x$ 的元素索引，$n$ 是 $x$ 中元素的范围或总数，这在Python中也可以定义为: 1y[i] = sum([c*d for c,d in zip(a[i], x)]) 可以证明，在给定的层上，我们从标准正态分布初始化的输入 $x$ 和权重矩阵 $a$ 的矩阵乘积通常将非常接近输入层节点数的平方根， 它在我们的例子中是 $\sqrt512$。 123456789101112# pytorchth_mean, th_var = 0., 0.for i in range(10000): th_x = torch.randn(512) th_a = torch.randn(512, 512) th_y = th_a @ th_x th_mean += th_y.mean().item() th_var += th_y.pow(2).mean().item()print(th_mean/10000, np.sqrt(th_var/10000))print(np.sqrt(512))# -0.002851470077782869 22.624340364162048# 22.627416997969522 123456789101112# tensorflowtf_mean, tf_var = 0., 0.for i in range(10000): tf_x = tf.random.normal([512, 1]) tf_a = tf.random.normal([512, 512]) tf_y = tf.matmul(tf_a, tf_x) tf_mean += tf.reduce_mean(tf_y) tf_var += tf.reduce_mean(tf.square(tf_y))print(tf_mean/10000, np.sqrt(tf_var/10000))print(np.sqrt(512))# tf.Tensor(-0.011328138, shape=(), dtype=float32) 22.623604# 22.627416997969522 如果从定义矩阵乘法的角度来看，这个性质并不奇怪： 为了计算 $y$，我们将输入 $x$ 的一个元素与权重 $a$ 的一列相乘，得到 $512$ 个乘积。在我们的示例中，$x$ 和 $a$ 都使用标准正态分布初始化，这 $512$ 个乘积的均值为 $0$，标准差为 $1$。 12345678910# pytorchth_mean, th_var = 0., 0.for i in range(10000): th_x = torch.randn(1) th_a = torch.randn(1) th_y = th_a * th_x th_mean += th_y.item() th_var += th_y.pow(2).item()print(th_mean/10000, np.sqrt(th_var/10000))# 0.012777583549162991 0.9860565282847021 1234567891011# tensorflow# tensorflowtf_mean, tf_var = 0., 0.for i in range(10000): tf_x = tf.random.normal([1]) tf_a = tf.random.normal([1]) tf_y = tf.multiply(tf_a, tf_x) tf_mean += tf.reduce_mean(tf_y) tf_var += tf.reduce_mean(tf.square(tf_y))print(tf_mean/10000, np.sqrt(tf_var/10000))# tf.Tensor(-0.007080218, shape=(), dtype=float32) 1.004455 因此，这 $512$ 个乘积的和的均值为 $0$，方差为 $512$，因此标准差为 $\sqrt 512$。 这就是为什么在我们上面的例子中，我们看到我们的层输出在 $29$ 次连续的矩阵乘法后爆炸。在我们最基本的 $100$ 层网络架构中，我们希望每个层的输出的标准偏差为 $1$。可以想象，这将允许我们在任意多的网络层上重复矩阵乘法，而不会触发或消失。 如果我们首先通过将所有随机选择的值除以 $\sqrt 512$ 来对权重矩阵 $a$ 进行缩放，那么填充输出 $y$ 的一个元素的元素乘法现在的平均方差只有 $1/\sqrt 512$。 123456789101112# pytorchth_mean, th_var = 0., 0.for i in range(10000): th_x = torch.randn(1) th_a = torch.randn(1) * np.sqrt(1./512) th_y = th_a * th_x th_mean += th_y.item() th_var += th_y.pow(2).item()print(th_mean/10000, th_var/10000)print(1/512)# 0.0005586366911495901 0.0019827878041473895# 0.001953125 123456789101112# tensorflowtf_mean, tf_var = 0., 0.for i in range(10000): tf_x = tf.random.normal([1]) tf_a = tf.random.normal([1]) * np.sqrt(1./512) tf_y = tf.multiply(tf_a, tf_x) tf_mean += tf.reduce_mean(tf_y) tf_var += tf.reduce_mean(tf.square(tf_y))print(tf_mean/10000, tf_var/10000)print(1/512)# tf.Tensor(-0.00051529706, shape=(), dtype=float32) tf.Tensor(0.002007504, shape=(), dtype=float32)# 0.001953125 这意味着矩阵 $y$ 的标准差为 $1$，其中包含输入 $x$ 与权重 $a$ 相乘生成的 $512$ 个值中的每一个。让我们通过实验来证实这一点。 12345678910# pytorchth_mean, th_var = 0., 0.for i in range(10000): th_x = torch.randn(512) th_a = torch.randn(512, 512) * np.sqrt(1./512) th_y = th_a @ th_x th_mean += th_y.mean().item() th_var += th_y.pow(2).mean().item()print(th_mean/10000, np.sqrt(th_var/10000))# 0.0008099440926453099 1.0001812369800038 12345678910# tensorflowtf_mean, tf_var = 0., 0.for i in range(10000): tf_x = tf.random.normal([512, 1]) tf_a = tf.random.normal([512, 512]) * np.sqrt(1./512) tf_y = tf.matmul(tf_a, tf_x) tf_mean += tf.reduce_mean(tf_y) tf_var += tf.reduce_mean(tf.square(tf_y))print(tf_mean/10000, np.sqrt(tf_var/10000))# tf.Tensor(0.00010935542, shape=(), dtype=float32) 1.0003854 现在让我们重新运行我们的100层网络。和之前一样，我们首先从 $[-1,1]$ 内部的标准正态分布中随机选择层权值，但这次我们将这些权值缩放 $1/\sqrt n$，其中 $n$ 是一层的网络输入连接数，在我们的示例中为 $512$。 12345678# pytorchth_x = torch.randn(512)for i in range(100): th_a = torch.randn(512, 512) * np.sqrt(1./512) th_x = th_a @ th_xth_x.mean(), th_x.std()# (tensor(-0.0199), tensor(1.1058)) 123456789# tensorflowtf_x = tf.random.normal([512, 1])for i in range(100): tf_a = tf.random.normal([512, 512]) * np.sqrt(1./512) tf_x = tf.matmul(tf_a, tf_x)tf_mean, tf_var = tf.nn.moments(tf_x,axes=0)tf_mean.numpy(), tf_var.numpy()# (array([-0.06913895], dtype=float32), array([0.9944094], dtype=float32)) 乍一看似乎时可以收工了，但现实世界的神经网络并不像第一个例子所显示的那么简单，为了简单起见，这里省略了激活函数。然而，在实际中，神经网络每一层的结尾都会加上一层激活函数，以此，深度神经网络可以近似的逼近一个复杂的函数来描述实际生活中的现象，比如手写数字的分类 。]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode-Merge Two Sorted Lists]]></title>
    <url>%2F2019%2F10%2F16%2FLeetcode021-Merge%20Two%20Sorted%20Lists%2F</url>
    <content type="text"><![CDATA[天黑有伞，下雨有灯。 ProblemMerge two sorted linked lists and return it as a new list. The new list should be made by splicing together the nodes of the first two lists. Example: 12Input: 1-&gt;2-&gt;4, 1-&gt;3-&gt;4Output: 1-&gt;1-&gt;2-&gt;3-&gt;4-&gt;4 Process 遍历两个链表，比较元素的值 设置一个值，指向当前的节点，方便向合并的链表中增加元素 最后将剩余的值放到最后面 Solution123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354/** * Definition for singly-linked list. * struct ListNode &#123; * int val; * ListNode *next; * ListNode(int x) : val(x), next(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: ListNode* mergeTwoLists(ListNode* l1, ListNode* l2) &#123; if (l1 == NULL) &#123; return l2; &#125; if (l2 == NULL) &#123; return l1; &#125; ListNode *l3, *res; if (l1-&gt;val &lt;= l2-&gt;val) &#123; l3 = new ListNode(l1-&gt;val); l1 = l1-&gt;next; &#125; else &#123; l3 = new ListNode(l2-&gt;val); l2 = l2-&gt;next; &#125; res = l3; while (l1 != NULL &amp;&amp; l2 != NULL) &#123; if (l1-&gt;val &lt;= l2-&gt;val) &#123; l3-&gt;next = l1; l1 = l1-&gt;next; &#125; else &#123; l3-&gt;next = l2; l2 = l2-&gt;next; &#125; l3 = l3-&gt;next; &#125; if (l1 != NULL) &#123; l3-&gt;next = l1; &#125; if (l2 != NULL) &#123; l3-&gt;next = l2; &#125; return res; &#125;&#125;; Result Time Submitted Status Runtime Memory Language 2 minutes ago Accepted 8 ms 8.7 MB cpp Summary没什么特别的地方，做的还是稀碎。]]></content>
      <categories>
        <category>Leetcode</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode-Longest Substring Without Repeating Characters]]></title>
    <url>%2F2019%2F10%2F11%2FLeetcode003-Longest%20Substring%20Without%20Repeating%20Characters%2F</url>
    <content type="text"><![CDATA[金九已过，还在挣扎。 ProblemGiven a string, find the length of the longest substring without repeating characters. Example 1: 123Input: &quot;abcabcbb&quot;Output: 3 Explanation: The answer is &quot;abc&quot;, with the length of 3. Example 2: 123Input: &quot;bbbbb&quot;Output: 1Explanation: The answer is &quot;b&quot;, with the length of 1. Example 3: 1234Input: &quot;pwwkew&quot;Output: 3Explanation: The answer is &quot;wke&quot;, with the length of 3. Note that the answer must be a substring, &quot;pwke&quot; is a subsequence and not a substring. 题干要理解清楚，要找到最长的不重复的子序列，不是从重复的位置重新统计，踩坑了。 Process 从第二个元素开始，只要与已有的序列不重复，序列长度加1 如果重复，比较当前序列与上一个序列的长度，留下长度大的 反向遍历当前序列，从没有重复的位置开始继续保存序列 输出最长的序列的长度 Solution1234567891011121314151617181920212223242526272829303132333435363738394041class Solution &#123;public: int lengthOfLongestSubstring(string s) &#123; vector&lt;char&gt; subString; int length = 0; vector&lt;char&gt;::iterator iter; vector&lt;char&gt;::reverse_iterator riter; for (int i = 0; i &lt; s.size(); i++) &#123; if (subString.empty()) &#123; subString.push_back(s[i]); &#125; iter = find(subString.begin(), subString.end(), s[i]); if(iter != subString.end()) &#123; //s[i] in subString if (subString.size() &gt; length) &#123; length = subString.size(); &#125; // 反向迭代vector，找到s[i]之前与s[i]不相等的元素 int index = 0; for(riter = subString.rbegin(); riter != subString.rend();++riter) &#123; if (*riter == s[i]) &#123; break; &#125; index++; &#125; int delete_length = subString.size() - index; subString.erase(subString.begin(), subString.begin() + delete_length); subString.push_back(s[i]); &#125; else &#123; subString.push_back(s[i]); if (subString.size() &gt; length) &#123; length = subString.size(); &#125; &#125; &#125; return length; &#125;&#125;; Better Solution123456789101112131415class Solution &#123;public: int lengthOfLongestSubstring(string s) &#123; int left = 0, len = 0; map&lt;char, int&gt; dict; for (int right=0; right&lt;s.size(); right++) &#123; if (dict.find(s[right]) != dict.end()) &#123; left = max(left, dict[s[right]] + 1); &#125; dict[s[right]] = right; len = max(len, right - left + 1); &#125; return len; &#125;&#125;; Result Time Submitted Status Runtime Memory Language a few seconds ago Accepted 40 ms 9.3 MB cpp 2 minutes ago Wrong Answer N/A N/A cpp 40 minutes ago Wrong Answer N/A N/A cpp 44 minutes ago Wrong Answer N/A N/A cpp an hour ago Compile Error N/A N/A cpp Summary最开始想到的方法是栈，后来查找元素的时候发现用栈不太方便；后来换了vector，题没审明白，找到重复的元素直接清空了vector，导致结果出错。 从不重复的元素开始统计，正序遍历vector容易忽略后面存在的重复的元素，所以反向遍历vector，找到第一个重复的元素，然后删除其实元素到该重复元素，继续找不重复的序列，输出最长子序列的长度。 感觉用双端队列可能会稍微简单点吧，就不存在反向遍历的操作了。 better solution只是先拷过来，map操作还是不太能看得懂。]]></content>
      <categories>
        <category>Leetcode</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分类损失用交叉熵的原因]]></title>
    <url>%2F2019%2F10%2F11%2Freason-of-using-cross-entropy%2F</url>
    <content type="text"><![CDATA[最近一直在纠结的一个问题，为什么分类损失用交叉熵（cross entry）而不用看起来更简单的二次代价函数（square mean），偶然间搜到一篇博客（查看原文），貌似是领悟了一点，简单整理下。 前向传播前向传播的流程都是一样的，以二分类为例，以 $Sigmoid$ 为激活函数，当到达网络最后一层时： $z = w \cdot x + b$ $a = \sigma (z) = sigmoid(z)$ 反向传播为了方便计算，只取一个样本： 1. 二次代价函数损失： \begin{equation}\begin{split} c = \frac{(a-y)^2}{2} \end{split}\end{equation}$w$ 和 $b$ 的梯度为： \begin{equation}\begin{split} \frac{\partial c}{\partial w} &= (a - y ) \cdot a' \\ &= (a - y) \cdot [\sigma(wx + b)]' \\ &= (a - y) \cdot \sigma'(z) \cdot x \end{split}\end{equation} \begin{equation}\begin{split} \frac{\partial c}{\partial b} &= (a - y ) \cdot a' \\ &= (a - y) \cdot [\sigma(wx + b)]' \\ &= (a - y) \cdot \sigma'(z) \end{split}\end{equation}2. 交叉熵损失： \begin{equation}\begin{split} c = -y log(a) - (1 - y)log(1 - a) \end{split}\end{equation}$w$ 和 $b$ 的梯度为： \begin{equation}\begin{split} \frac{\partial c}{\partial w} &= -(\frac{y}{a} - \frac{1 - y}{1 - a}) \frac{\partial \sigma(z)}{\partial w} \\ &= -(\frac{y}{a} - \frac{1 - y}{1 - a}) \cdot \sigma'(z) \cdot x \\ &= -( \frac{y}{\sigma(z)} - \frac{1 - y}{1 - \sigma(z)} ) \cdot \sigma(z) \cdot (1 - \sigma(z)) \cdot x \\ &= -( \frac{(1 - \sigma(z))y - \sigma(z)(1 - y)}{\sigma(z)(1 - \sigma(z)} ) \cdot \sigma(z) \cdot (1 - \sigma(z)) \cdot x \\ &= (\sigma(z) - y) \cdot x \end{split}\end{equation} \begin{equation}\begin{split} \frac{\partial c}{\partial b} = \sigma(z) - y \end{split}\end{equation}Note: Sigmoid的导数为 $\sigma’(z) = \sigma(z) \cdot (1 - \sigma(z)$ 结论在反向传播时： 对于square mean在更新 $w$，$b$ 时候， $w$，$b$ 的梯度跟激活函数的梯度成正比，激活函数梯度越大， $w$，$b$ 调整就越快，训练收敛就越快，但是Simoid函数在值非常高时候，梯度是很小的，比较平缓。 对于cross entropy在更新 $w$，$b$ 时候， $w$，$b$ 的梯度跟激活函数的梯度没有关系了，$\sigma’(z)$ 已经被抵消掉了，其中$(\sigma(z) - y)$ 表示的是预测值跟实际值差距，如果差距越大，那么 $w$，$b$ 调整就越快，收敛就越快。]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 'Object of type '***' is not JSON serializable']]></title>
    <url>%2F2019%2F08%2F30%2FTypeError%2F</url>
    <content type="text"><![CDATA[这是想要将数据写到json文件遇到的问题，Object of type int32/int64/ndarray is not JSON serializable，归根结底都是一个问题。 解决方案由于numpy.array的数据类型不符合json的解码类型，使用tolist()方法将array转换成list。 NOTE: 不能使用list()方法，list()转换的list不会改变array的数据类型。 问题分析先看json可以解码的数据类型， Python操作json的标准api库： JSON Python object dict array list string str number (int) int number (real) float true True false False null None 支持的数据类型基本都是常见的int，str类型，而numpy.array的数据类型都是numpy内置的类型。 12345678910111213141516171819202122import numpy as npimport jsony = []for i in range(5): x = np.random.randint(10, size=(5,)) y.append(x)print(y)d = &#123;&#125;d["y"] = ywith open("res.json", "w") as f: json.dump(d, f)Output:[array([4, 6, 8, 8, 1]), array([2, 0, 9, 7, 1]), array([8, 7, 9, 7, 4]), array([2, 1, 2, 7, 2]), array([6, 4, 9, 3, 3])]TypeError: Object of type 'ndarray' is not JSON serializable ndarray类型不能保存，list总能保存吧，所以先尝试list()方法。 123456789101112y = []for i in range(5): x = np.random.randint(10, size=(5,)) y.append(list(x)print(y)Output:[[7, 9, 6, 8, 1], [2, 8, 6, 7, 8], [8, 4, 2, 4, 3], [8, 0, 4, 2, 5], [7, 1, 4, 7, 0]] 看似没有任何问题，但是每次保存json都会遇到Object of type &#39;int32&#39; is not JSON serializable的问题，参考json可以解码的数据类型，查看x中的数据类型。 12345x = np.random.randint(10, size=(5,))x = list(x)print(type(x[0]))Output:&lt;class 'numpy.int32'&gt; 因此判断是numpy.array的数据类型的问题，所以尝试tolist()方法。 12345x = np.random.randint(10, size=(5,))x = x.tolist()print(type(x[0]))Output:&lt;class 'int'&gt; 符合Json解码的标准，保存文件成功。 问题tolist()方法和list()方法的区别没查到，为什么一个改变数据类型，一个未改变数据类型。]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>json</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2013.6-2019.6]]></title>
    <url>%2F2019%2F06%2F09%2Fhualao1%2F</url>
    <content type="text"><![CDATA[一盏黄黄旧旧的灯 时间在旁闷不吭声 寂寞下手毫无分寸 不懂得轻重之分 用幽默的方式表达自己的情绪，真是一个令人羡慕的技能，然而我却一直学不会。 端午如果大BOSS不说放假，那默认就是不放了，想象中的做项目和现实中的做项目真是截然不同的两件事，都一年多了，从一开始的学习、兴奋，到现在厌倦，现在就希望它能早点结束。 前几天张老师就问我们端午回不回家，我就猜他要请我们吃饭，果然被我言中了，作为一个离不开女儿的父亲，他自然是不会去的，把发票给他就行了；作为一个组织能力极差的人，这顿饭我张罗的真费劲，同门叫不出来，张老师的第一反应就是同门是不是生他气了，不太理解老师为什么会这么想，而且不止一次了，哈哈哈，果然啊，孩子多了，做家长的真的很不容易啊，而且还是一个惯孩子的家长。 好久之前在网上看的一个短视频，说大部分人眼中的”公平“，所谓的公平，就是给我了没给你，这是“公平”，都给了，这就不算公平。然而这并不是一种健康的心态，共勉。 高考和端午撞车了，高考的被关注度又提高了不少，天天喜提热搜，虽然已经过去6年了，但有些体会就更深了。 @科普君XueShu雪树 题海战术非常痛苦，折磨人，也不太符合教育规律。可这是当下中国竞争激烈的高中生绕不过去的一道坎。衡水中学这样的通道毕竟是普罗大众的靠谱出路，高中生为美好未来拼搏奋斗也是国家和时代朝气蓬勃的象征。另一方面，我也不相信存在完美的教育，任何时代的教育都不会尽如人意，幻想通过教育改革有朝一日就能轻轻松松上大学也是幼稚的。题海战术是否一定会摧毁人的创造力和想象力？这不一定，看你怎么反刍和反思。题海战术最大弊端在于，它会给你一种假象，仿佛你必须通过海量做题把每一点知识都碾压得粉碎才能吸收和学习，如果不这样就感觉不踏实也没办法学好知识。这种假象一定要在大学里撕破。高中那点知识从含金量上说还不够大学里一个学期的内容。知识本身就浩如烟海了，你再指望题海战术，那是海的平方，肯定是寸步难行。好消息是，你根本不需要做这么多题，你只要能『独立』做出课后习题就足够了。一个高中生初看这句话一定会感到惊讶。如果你只会做数学和物理课本上的习题就去高考，后果可能很惨。问题在哪呢？中学的知识量有限，又年复一年这么多人这么多考试，只能导致一个后果:绝大部分试题都显得扭捏造作极不自然。 对于智商在Baseline徘徊的我们，高中的大部分时间都是在刷题，从老师的灌输到自己的憧憬，都认为大学的校门就是从地狱到天堂的一道门，迈过了那道坎，放眼望去，全是自由，这就是最大的误区，千万不要用自己以为的自由去类比大学的自由，大学自由的前提还是在完成当前学业的基础上，毕竟身份还是学生，所谓大学的自由，就是没有了题海的束缚，可以在学完知识的时候，做一些自己喜欢的事情，上网就算了，可以但没必要。 虽然小破博客没人看，但我还是想说，高考虽然是当下的全部，但不是人生的全部，考的好也罢，不好也罢，只要带着学习的热情，就不会太差。 一个笑话吃饭回来的时候，看到老年服装表演系在招生， 浩文就调侃说，“谁老年还去学这个？” 我，“不要小看这个，你60岁的时候说不定也要去学。” 贵儿哥，“60岁的时候打英雄联盟，一只手掐着自己的人中，另一只手和人对喷。” 都是嘴强王者。 话痨说有些东西，不说就憋得慌，但也不知道该和谁说，说多了，不免显得矫情，日记也好久没更新了，正好有个小破博客，主要就是Github好久没绿了，心里有点不舒服，天天泡实验室的时间很长，但做的东西就很少，磨洋工的一把好手，下午要把这周的周报写了，但愿我能写完。]]></content>
      <categories>
        <category>话痨说</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Leetcode-Add Two Numbers]]></title>
    <url>%2F2019%2F05%2F25%2FLeetcode002-Add%20Two%20Numbers%2F</url>
    <content type="text"><![CDATA[本打算好好看看数据结构，结果看到递归后就被一些乱七八糟的事一直拖着，一直也没往下看，而且隔段时间不回去看一下，就容易忘了，所以心血来潮，挑战了了第一道Medium，其实也没想的那么难，只不过考虑的东西要比Easy的多一些而已，然而，能踩的坑我还是都踩了一遍。 ProblemYou are given two non-empty linked lists representing two non-negative integers. The digits are stored in reverse order and each of their nodes contain a single digit. Add the two numbers and return it as a linked list. You may assume the two numbers do not contain any leading zero, except the number 0 itself. Example: 123Input: (2 -&gt; 4 -&gt; 3) + (5 -&gt; 6 -&gt; 4)Output: 7 -&gt; 0 -&gt; 8Explanation: 342 + 465 = 807. 给了两个非空的单链表，每一个单链表作为一个倒序的十进制的数，对这两个十进制数求和，得到的结果倒序输出，既然同样倒序放到一个新的列表中，其实这样就没那么复杂了，既然都是倒序，那就从头开始做，先从单链表的第一个元素，即十进制数对应的个位数开始计算，只需要考虑进位的问题就可以了。 Process 两个单链表的长度可能不同，如果不同，在短的后面补零； Note：对两个同时判断，否则长度相同时会死循环。 对同一个位置的数求和$ (sum) $，如果$sum &gt; 10$，则对$ sum $取余，进位数加$ 1 $； 当两个链表的next都为空时就意味着加法结束了，如果进位数$ &gt; 0 $，则结果再增加一位最高位，并设置为$ 1 $。 Solution1234567891011121314151617181920212223242526272829303132333435363738394041424344454647/** * Definition for singly-linked list. * struct ListNode &#123; * int val; * ListNode *next; * ListNode(int x) : val(x), next(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: ListNode* addTwoNumbers(ListNode* l1, ListNode* l2) &#123; ListNode* res = new ListNode(0); ListNode* ptr = res; int sum, carry = 0; while (l1 || l2) &#123; if (l1-&gt;next == NULL &amp;&amp; l2-&gt;next != NULL) &#123; l1-&gt;next = new ListNode(0); &#125; if (l2-&gt;next == NULL&amp;&amp; l1-&gt;next != NULL) &#123; l2-&gt;next = new ListNode(0); &#125; sum = l1-&gt;val + l2-&gt;val + carry; carry = 0; if (sum &gt;= 10) &#123; sum = sum % 10; carry = 1; &#125; ptr-&gt;next = new ListNode(sum); ptr = ptr-&gt;next; if (l1-&gt;next == NULL &amp;&amp; l2-&gt;next == NULL &amp;&amp; carry &gt; 0) &#123; ptr-&gt;next = new ListNode(1); l1 = l1-&gt;next; l2 = l2-&gt;next; &#125; else &#123; l1 = l1-&gt;next; l2 = l2-&gt;next; &#125; &#125; ptr = res-&gt;next; delete res; return ptr; &#125;&#125;; Better Solution12345678910111213141516171819202122232425class Solution &#123;public: ListNode* addTwoNumbers(ListNode* l1, ListNode* l2) &#123; int sum=0; ListNode *l3=NULL; ListNode **node=&amp;l3; while(l1!=NULL||l2!=NULL||sum&gt;0) &#123; if(l1!=NULL) &#123; sum+=l1-&gt;val; l1=l1-&gt;next; &#125; if(l2!=NULL) &#123; sum+=l2-&gt;val; l2=l2-&gt;next; &#125; (*node)=new ListNode(sum%10); sum/=10; node=&amp;((*node)-&gt;next); &#125; return l3; &#125;&#125;; 思路其实没什么区别，但是这样写很明显比我的更好理解。 Result Time Submitted Status Runtime Memory Language a few seconds ago Accepted 4 ms 8.4 MB cpp Summary数据结构和语言的学习要一直在路上了，这一道题，加踩坑加磨叽，用了好长时间，实在不应该。 p.s. 每次在学校的理发店剪完头都想和理发师拼命啊有木有！！！]]></content>
      <categories>
        <category>Leetcode</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tensorwatch——可视化深度学习库的使用]]></title>
    <url>%2F2019%2F05%2F24%2Ftensorwatch-tutorial%2F</url>
    <content type="text"><![CDATA[tensorwatch地址：Github TensorWatch is a debugging and visualization tool designed for deep learning and reinforcement learning. It fully leverages Jupyter Notebook to show real time visualizations and offers unique capabilities to query the live training process without having to sprinkle logging statements all over. You can also use TensorWatch to build your own UIs and dashboards. In addition, TensorWatch leverages several excellent libraries for visualizing model graph, review model statistics, explain prediction and so on. Tensorwatch可以在网络训练的过程中可视化网络的损失以及各种参数，相比于print，能看的更直观一些，而且，看着很高端啊。 通过pip安装tensorwatch： 1pip install tensorwatch 中间可能会在安装pytorch那里报错，只需要单独把torch装一下就行。话说这个东西为什么会和pytorch挂钩，而且，Anaconda的清华源已经不能用了啊！！！ 然后就是动态显示的过程了，这里官方文档说的不是很具体，走了不少弯路。 tensorwatch只是一个可视化的工具，不会产生任何数据，都是从执行代码的终端那里来的，都是从执行代码的终端那里来的，都是从执行代码的终端那里来的。 所以，首先要有产生数据的终端： 123456789101112131415161718#***************** gen_data.py *******************import timeimport tensorwatch as twimport random# create watcher, notice that we are not logging anythingw = tw.Watcher()for i in range(10000): x = i loss = random.random() * 10 train_accuracy = random.random() # we are just observing variables # observation has no cost, nothing gets logged anywhere w.observe(iter=x, loss=loss, train_accuracy=train_accuracy) time.sleep(1) 通过tw.Watcher()创建一个观察的对象，将要可视化的数据放在observe中，这里假设是个神经网络，x代表迭代的次数，loss代表每次迭代后的损失，train_accuracy代表每次迭代后在训练集上的准确率。 到这里，生成数据的终端就完成了，下一步，在jupyter notebook中可视化每一步的结果。 打开jupyter notebook，新建一个notebook 12%matplotlib notebookimport tensorwatch as tw 12# 连接执行tensorwatch的终端client = tw.WatcherClient() 12345# 使用lambda获取终端中的参数loss_stream = client.create_stream(expr='lambda d:(d.iter, d.loss)')# 可视化设置loss_plot = tw.Visualizer(loss_stream, vis_type='line', xtitle='Epoch', ytitle='Train Loss')loss_plot.show() 执行完上面的代码会生成一个可视化的界面，用来表示迭代次数和损失之间的关系： 继续执行，用以表示迭代次数和训练的正确率之间的关系： 123acc_stream = client.create_stream(expr='lambda d:(d.iter, d.train_accuracy)')acc_plot = tw.Visualizer(acc_stream, vis_type='line', host=loss_plot, xtitle='Epoch', ytitle='Train Accuracy', yrange=(0,))acc_plot.show() 执行完Figure会变成下图的样子： 注意在终端执行完之前不要关闭figure，否则可视化就结束了。 最后新建一个终端，在终端中执行： 1python gen_data.py 就可以在jupyter notebook中可视化结果啦。 至此，可视化的任务就结束了。 拿Tensorflow做了一个简单的测试，可视化的参数和上面jupyter notebook中的相同，只需要将终端中执行的gen_data.py换成mnist_train.py就可以了。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081#***************** mnist_train.py *******************# -*- coding: utf-8 -*-import tensorflow as tffrom tensorflow.examples.tutorials.mnist import input_dataimport tensorwatch as twdef weight_variable(shape): initial = tf.truncated_normal(shape, stddev=0.1) return tf.Variable(initial)def bias_variable(shape): initial = tf.constant(0.1, shape=shape) return tf.Variable(initial)def conv2d(x, W): return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')def max_pool_2x2(x): return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')def forward(x): # convolution layer 1 W_conv1 = weight_variable([5, 5, 1, 32]) b_conv1 = bias_variable([32]) x_image = tf.reshape(x, [-1, 28, 28, 1]) h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1) h_pool1 = max_pool_2x2(h_conv1) # convolution layer 2 W_conv2 = weight_variable([5, 5, 32, 64]) b_conv2 = bias_variable([64]) h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2) h_pool2 = max_pool_2x2(h_conv2) # full convolution W_fc1 = weight_variable([7 * 7 * 64, 1024]) b_fc1 = bias_variable([1024]) h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64]) h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1) # output layer, softmax W_fc2 = weight_variable([1024, 10]) b_fc2 = bias_variable([10]) y_conv=tf.nn.softmax(tf.matmul(h_fc1, W_fc2) + b_fc2, name="output") return y_convdef train(): mnist = input_data.read_data_sets("/MNIST_data", one_hot=True) w = tw.Watcher() x = tf.placeholder(tf.float32, [None, 784], name="input") y_ = tf.placeholder(tf.float32, [None, 10], name="label") y_conv = forward(x) cost = -tf.reduce_sum(y_*tf.log(y_conv)) train_step = tf.train.AdamOptimizer(1e-4).minimize(cost) correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1)) accuracy = tf.reduce_mean(tf.cast(correct_prediction, "float")) with tf.Session() as sess: sess.run(tf.global_variables_initializer()) for i in range(5000): batch = mnist.train.next_batch(64) _, loss = sess.run([train_step, cost], feed_dict=&#123;x: batch[0], y_: batch[1]&#125;) if i%100 == 0: train_accuracy = sess.run(accuracy, feed_dict=&#123;x:batch[0], y_: batch[1]&#125;) print("step %d, training accuracy %g"%(i, train_accuracy)) w.observe(iter=i, loss=loss, train_accuracy=train_accuracy)if __name__ == "__main__": train()]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>tensorflow</tag>
        <tag>可视化</tag>
        <tag>tensorwatch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Google免费云环境Colaboratory使用教程]]></title>
    <url>%2F2019%2F05%2F05%2FGoogle-Colaboratory-tutorial%2F</url>
    <content type="text"><![CDATA[Colaboratory是Google的一个免费的深度学习云端环境，提供免费的GPU和TPU，除了需要科学上网，用起来还是非常舒服的。 Colab地址：点击前往 基本使用进入Google云端硬盘，右键$\rightarrow$更多$\rightarrow$关联更多应用 搜索Colaboratory并添加，添加完成后，右键选择Colaboratory就可以创建一个新的notebook。 Colab的用法和Jupyter notebook一样，可以直接执行Python代码，也可以通过!+command执行linux命令。 执行Python代码： 123456789import numpy as npa = np.random.random((3, 3))print(a)print("sum: ", np.sum(a))[[0.24678976 0.47023166 0.00604048] [0.81917307 0.9650736 0.9974302 ] [0.88696709 0.92203368 0.31132943]]sum: 5.625068960056541 使用命令查看Ubuntu的版本： 1234567!lsb_release -aNo LSB modules are available.Distributor ID: UbuntuDescription: Ubuntu 18.04.2 LTSRelease: 18.04Codename: bionic 连接Google云端硬盘执行下面代码，点击输出链接，登陆Google账号，获取授权码，粘贴到输入框中，链接到云端硬盘，硬盘挂载在/content/drive下。 1234# Load the Drive helper and mountfrom google.colab import drive# This will prompt for authorization.drive.mount('/content/drive') 使用ls命令查看云端硬盘中的文件： 123456789!ls &quot;/content/drive/My Drive&quot; Cifar10&apos;Colab Notebooks&apos; CornerNet deep-learning-keras-tensorflow keras_Realtime_Multi-Person_Pose_Estimation-master MCM pose-residual-network-pytorch 也可以展开侧边栏查看文件： 查看配置点击 代码执行程序$\rightarrow$更改运行时类型$\rightarrow$硬件加速器 选择GPU。 执行： 123456789101112131415161718192021222324252627282930from tensorflow.python.client import device_libdevice_lib.list_local_devices()[name: "/device:CPU:0" device_type: "CPU" memory_limit: 268435456 locality &#123; &#125; incarnation: 677841662562579601, name: "/device:XLA_CPU:0" device_type: "XLA_CPU" memory_limit: 17179869184 locality &#123; &#125; incarnation: 9258589908592365980 physical_device_desc: "device: XLA_CPU device", name: "/device:XLA_GPU:0" device_type: "XLA_GPU" memory_limit: 17179869184 locality &#123; &#125; incarnation: 10896633435725669876 physical_device_desc: "device: XLA_GPU device", name: "/device:GPU:0" device_type: "GPU" memory_limit: 14800692839 locality &#123; bus_id: 1 links &#123; &#125; &#125; incarnation: 711525362527462258 physical_device_desc: "device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5"] 用nvidia命令查看显卡使用情况： 123456789101112131415161718!nvidia-smiSun May 5 11:51:49 2019 +-----------------------------------------------------------------------------+| NVIDIA-SMI 418.56 Driver Version: 410.79 CUDA Version: 10.0 ||-------------------------------+----------------------+----------------------+| GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC || Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. ||===============================+======================+======================|| 0 Tesla T4 Off | 00000000:00:04.0 Off | 0 || N/A 71C P0 31W / 70W | 221MiB / 15079MiB | 0% Default |+-------------------------------+----------------------+----------------------+ +-----------------------------------------------------------------------------+| Processes: GPU Memory || GPU PID Type Process name Usage ||=============================================================================|+-----------------------------------------------------------------------------+ 一个示例为了操作方便，先将路径换成云端硬盘的路径： 12import osos.chdir('/content/drive/My Drive/') 执行mnist_train： 1234567!python test_code/mnist_train.pystep 0, training accuracy 0.171875step 900, training accuracy 0.96875step 1900, training accuracy 1step 3900, training accuracy 0.984375step 4900, training accuracy 1 测试结果： 123!python test_code/mnist_test.pyaccuracy is: 0.9778 完整教程代码：点击前往 总结Colab对想搞深度学习没有好卡的人是一个非常好的工具，环境配置简单，自带tensorflow，还可以安装其他的深度学习的框架，还可以直接从github导入，虽然每次最多只能连续用12小时，但对于学习来说已经非常够用了。更重要的一点，对于动辄几百上千的GPU云服务器，colab是免费的！]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>tensorflow</tag>
        <tag>colaboratory</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tensorflow1.x加载模型的方法]]></title>
    <url>%2F2019%2F05%2F04%2FTensorflow1-x-lode-model%2F</url>
    <content type="text"><![CDATA[代码地址：查看完整代码 一个错误的使用之前有同学问过我这个问题，TF加载模型，跑出来的结果不对，代码见incurrect_usage.py，正确率和猜的一样，怀疑是模型加载那里出问题了。 123456789101112#****************** incurrent usage.py*********************x = tf.placeholder(tf.float32, [None, 784], name="input")y_ = tf.placeholder(tf.float32, [None, 10], name="label")pred = forward(x)with tf.Session() as sess: sess.run(tf.global_variables_initializer()) saver = tf.train.import_meta_graph('./model/mnist_model-4000.meta') saver.restore(sess, './model/mnist_model-4000') correct_prediction = tf.equal(tf.argmax(pred,1), tf.argmax(test_label, 1)) accuracy = tf.reduce_mean(tf.cast(correct_prediction, "float")) acc = sess.run(accuracy, feed_dict=&#123;x: test_image, y_: test_label&#125;) 跑出来的正确率都在0.1左右，训练正确率都在0.9以上，再差也不会这样，所以加载模型哪里出错了。 Tensorflow加载模型的方法本例使用tf.train.Saver()保存模型的方法，执行saver.save(sess, model_name)后，会得到3个名为model_name的文件，.data-00000-of-00001中保存了网络训练的参数，.meta保存了网络的图结构。 Tensorflow在加载模型的时候就需要上述的两个东西，网络参数和图结构，而加载图有两种方式，重新搭建网络或直接用.meta文件。 重新搭建网络顾名思义，在测试代码中重新把训练时forward的流程再搭一遍，这样就能得到由训练好的参数得到forward的结果。 123456789101112#****************** test with network.py*********************x = tf.placeholder(tf.float32, [None, 784], name="input")y_ = tf.placeholder(tf.float32, [None, 10], name="label")pred = forward(x)with tf.Session() as sess: sess.run(tf.global_variables_initializer()) saver = tf.train.Saver() saver.restore(sess, './model/mnist_model-4000') correct_prediction = tf.equal(tf.argmax(pred,1), tf.argmax(test_label, 1)) accuracy = tf.reduce_mean(tf.cast(correct_prediction, "float")) acc = sess.run(accuracy, feed_dict=&#123;x: test_image, y_: test_label&#125;) 因为forward流程和训练时一样，所以直接在训练代码里拿来用，已经重新搭建了图，就不要加载.meta文件了，所以直接restore参数文件就可以了。 拿测试集中前5000个样本做测试，测试结果： 123test with network: INFO:tensorflow:Restoring parameters from ./model/mnist_model-4000accuracy is: 0.9784 网络结构： 使用.meta文件构建图使用.meta文件需要注意，在训练时最好为输入和输出取一个名字，因为需要直接从.meta保存的图结构中取输入和输出，有名字的时候会更明确一些。 像这样： 12x = tf.placeholder(tf.float32, [None, 784], name="input")y_ = tf.placeholder(tf.float32, [None, 10], name="label") 加载.meta代码如下： 123456789101112#****************** test with meta.py*********************with tf.Session() as sess: saver = tf.train.import_meta_graph('./model/mnist_model-4000.meta') saver.restore(sess, tf.train.latest_checkpoint("./model/")) graph = tf.get_default_graph() input_x = graph.get_operation_by_name("input").outputs[0] feed_dict = &#123;"input:0":test_image, "label:0":test_label&#125; pred = graph.get_tensor_by_name("output:0") correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(test_label, 1)) accuracy = tf.reduce_mean(tf.cast(correct_prediction, "float")) acc = sess.run(accuracy, feed_dict=feed_dict) 使用.meta文件，直接根据名字找到对应的输出和输出，获取默认图结构，不需要重新初始化参数。 拿测试集中前5000个样本做测试，测试结果： 123test with .meta:INFO:tensorflow:Restoring parameters from ./model/mnist_model-4000accuracy is: 0.9784 测试结果和重新构建网络是一样的。 网络结构： 使用.meta测试时，网络输出那里出现了两个分支，猜测是.meta保存了训练时测试accuracy那部分图，我在测试的代码里又写了一个测试accuracy的部分，所以两部分都被保存了，但不影响测试的结果。 错误的原因很容易猜到，图加载了两次，已经重建网络了，然后又加载了.meta，导致图的结构乱了，看图： 网络的结构已经变了，所以加载训练好的模型时，要么重建图，要么加载.meta，混合起来就容易出错。 TODO：使用滑动平均如何加载模型 参考Mnist网络backbone：点击前往 TF加载模型方法： 点击前往]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>tensorflow</tag>
        <tag>加载模型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[论文阅读——Faster RCNN,详解RPN的好处]]></title>
    <url>%2F2019%2F04%2F30%2Fadvantage-of-RPN-in-Faster-RCNN%2F</url>
    <content type="text"><![CDATA[Faster RCNN是为目标检测而提出的一种网络，目标检测的任务是从一张给定的图片中不仅要对图像中的物体进行分类，而且要为每个类别的物体加一个Box，也就是要确定检测到的物体的位置。 阅读前准备Faster RCNN由Fast RCNN改进，所以简单了解RCNN和Fast RCNN。 RCNNRCNN使用selective search方法，为每张图片提出大概1k~2k个候选区域，然后将每个候选区域都输入到网络中，进行特征提取，之后输入到一个SVM分类器中判断物体类别，最后使用一个回归器得到物体的精确位置，即Box。通过简单描述就可以看出，RCNN的缺点非常明显，对于现在的网络，基本都是端到端的结构，而RCNN的处理流程很复杂，并且保存每个候选区域的特征也会占用非常多的空间；其二，对这么多的候选区域，计算会浪费非常多的时间，而且提取的特征会重复。 Fast RCNNFast RCNN作为RCNN的进阶版，主要改进在两方面，一个是只需要对输入图像提一次特征，然后将找到候选区域对应的特征，对特征进行分类和回归得到Box；另一方面是ROI Pooling，由于网络中全连接层的存在，所以要求网络所谓输入大小必须是相同的，但selective search选出的候选区域大小不同，如果直接将输入图像都缩放到相同的大小，会丢失图像的信息；通过ROI Pooling可以解决这个问题，相比较于Max Pooling固定的stride，ROI Pooling的stride是根据输出的大小来决定的，比如当前ROI feature map的大小为$h \times w$，经过ROI Pooling后输出的固定大小为$H \times W$，那么ROI Pooling的stride就是$\frac{h}{H} \times \frac{w}{W}$。 Faster RCNN论文核心 we introduce a Region Proposal Network (RPN) that shares full-image convolutional features with the detection network, thus enabling nearly cost-free region proposals. 论文中提出一种新的选择Region proposals的方法，用RPN代替Fast RCNN中Selective search，RPN与object detection network共享卷积层，节省了大量选择候选区域的时间，SS $2s$ per image, RPN $10ms$ per image。 Anchor RPNs are designed to efficiently predict region proposals with a wide range of scales and aspect ratios. 提出了anchor做多尺度和长宽比的参考，避免了枚举多个尺度的信息。 anchor的实现过程： 对一幅图像，经过网络下采样得到feature map，对feature map中的一个点，找到其在原始图形对应的区域，比如，一幅图像经过3次Pooling，那么得到的特征中的一个点对应原始图像就是一个$16 \times 16$ 的区域，对这个区域生成不同anchor。 首先对该区域生成3种长宽比的anchor（$ratios=[0.5,1,2]$）： 123456789def _whctrs(anchor): """ Return width, height, x center, and y center of an anchor. """ w = anchor[2] - anchor[0] + 1 h = anchor[3] - anchor[1] + 1 x_ctr = anchor[0] + 0.5 * (w - 1) y_ctr = anchor[1] + 0.5 * (h - 1) return w, h, x_ctr, y_ctr 12345678910111213141516171819def _mkanchors(ws, hs, x_ctr, y_ctr): """ Getting coordinates of different window width ratios around the same center. Parameters: ws : A sist of X coordinates in the upper left corner of a anchor. hs : A sist of Y coordinates in the upper left corner of a anchor. x_ctr : X-coordinates of the center of a anchor. y_ctr : Y-coordinates of the center of a anchor. Return: anchors : Coordinates with different aspect ratios. """ ws = ws[:, np.newaxis] hs = hs[:, np.newaxis] anchors = np.hstack((x_ctr - 0.5 * (ws - 1), y_ctr - 0.5 * (hs - 1), x_ctr + 0.5 * (ws - 1), y_ctr + 0.5 * (hs - 1))) return anchors 12345678910111213141516171819def _ratio_enum(anchor, ratios): ''' Enumerate a set of anchors for each aspect ratio wrt an anchor. Parameters: anchor : A list contains coordinates of the upper left and lower right corners. ratios : A list contains different aspect ratios. Return: anchors : Coordinates with different aspect ratios. ''' w, h, x_ctr, y_ctr = _whctrs(anchor) size = w * h #size:16*16=256 size_ratios = size / np.array(ratios) #256/ratios[0.5,1,2]=[512,256,128] ws = np.round(np.sqrt(size_ratios)) #ws:[23 16 11] hs = np.round(ws * ratios) #hs:[12 16 22] anchors = _mkanchors(ws, hs, x_ctr, y_ctr) return anchors 运行结果，得到同一中心3个长宽比的anchor： 12345_ratio_enum([0, 0, 15, 15], [0.5, 1, 2])array([[-3.5, 2. , 18.5, 13. ], [ 0. , 0. , 15. , 15. ], [ 2.5, -3. , 12.5, 18. ]]) 然后对每个长宽比的anchor进行3种面积变换（$scales=[8, 16, 32]$）： 123456789101112131415def _scale_enum(anchor, scales): """ Enumerate a set of anchors for each scale wrt an anchor. Parameters: anchor : Orginal anchor. scales : Scaling factor. Return: Scaled coordinates of anchor. """ w, h, x_ctr, y_ctr = _whctrs(anchor) ws = w * scales hs = h * scales anchors = _mkanchors(ws, hs, x_ctr, y_ctr) return anchors 运行结果，得到1个特征点对应的不同长宽比和不同缩放系数对应的9个anchor： 123456789101112131415scales = 2**np.arange(3, 6) #[8, 16, 32]#别问我里为什么是15不是16，我也在研究ratio_anchors = _ratio_enum([0,0,15,15], [0.5, 1, 2])np.vstack([_scale_enum(ratio_anchors[i, :], scales) for i in range(ratio_anchors.shape[0])])array([[ -84., -40., 99., 55.], [-176., -88., 191., 103.], [-360., -184., 375., 199.], [ -56., -56., 71., 71.], [-120., -120., 135., 135.], [-248., -248., 263., 263.], [ -36., -80., 51., 95.], [ -80., -168., 95., 183.], [-168., -344., 183., 359.]]) 下面这个表格对比了9种尺寸的anchor的变换： base_anchorratios宽，高，中心点横坐标，中心点纵坐标坐标 16x1623x122:1[184,96,7.5,7.5] scale=8[ -84. -40. 99. 55.][368,192,7.5,7.5] scale=16[-176. -88. 191. 103.] [736,384,7.5,7.5] scale=32[-360. -184. 375. 199.]16x161:1[128,128,7.5,7.5] scale=8[ -56. -56. 71. 71.][256,256,7.5,7.5] scale=16[-120. -120. 135. 135.][512,512,7.5,7.5] scale=32[-248. -248. 263. 263.]11x221:2[88,176,7.5,7.5] scale=8[ -36. -80. 51. 95.][176,352,7.5,7.5] scale=16[ -80. -168. 95. 183.][352,704,7.5,7.5] scale=32[-168. -344. 183. 359.] 得到的anchor如下图所示，蓝色点代表feature map中的特征点，每种颜色框代表一种长宽比，同一颜色不同大小的矩形框代表不同的尺度：手贱就想画图，结果就被自己蠢到了。 plt画矩形的默认坐标系大小都是1，所以想画大一点的矩形，一定要先设置坐标系的大小 我一度以为我发现了matplotlib的BUG😫😫😫 附代码： 12345678910111213import matplotlib.pyplot as pltcolors = ["red", "blue", "green"]fig = plt.figure(figsize=(10, 10))ax = fig.add_subplot(1,1,1)plt.xlim((-500, 500)) #设置x轴的大小plt.ylim((-500, 500)) #设置y轴的大小plt.scatter(7.5, 7.5)for i in range(9): rect = plt.Rectangle((anchors[i][0], anchors[i][1] + anchors[i][3] - anchors[i][1]), anchors[i][2] - anchors[i][0], anchors[i][1] - anchors[i][3], fill=False, edgecolor = colors[i//3],linewidth=2) ax.add_patch(rect)plt.show() Region proposal Network Faster R-CNN is composed of two modules. The first module is a deep fully convolutional network that proposes regions, and the second module is the Fast R-CNN detector that uses the proposed regions. Faster R-CNN由两部分组成，一部分是是Region proposal network，突出用于检测的候选区域，另一部分和Fast RCNN一样，对候选区域进行检测，输出目标的类别和框的位置，网络结构如图：这里我理解就是在网络提完特征后再加一层，用于选出候选区域。 对卷积得到的 $H\times W$ 的feature map，用一个 $n \times n$ 的滑动窗口对每个窗口的中心点提$k$个anchors，取3个长宽比，3个缩放比，即$k=9$，对该feature map，会生成 $k \times H \times W$ 个anchors ，对每个anchor的 $cls$ 分支，用一个 $score$ 判断这个anchor是前景还是背景，所以 $score$ 的数量是 $2k$ ；对 $reg$ 分支，需要判断框的位置，所以保存每个anchor的位置信息（左下和右上的坐标，这里有歧义，好多博客里写的都是左上右下，但实际画图第一个点是左下的坐标），所以 $coordinates$ 的数量是 $4k$ 。 相比于SS，RPN的优势上面说过anchor，用anchor的话，就相当于，先知道大致位置，再知道具体位置，举个例子，anchor就是先上这个区域看一眼是啥，比如一个anchor区域里看见了一个马身子（马头一部分不在区域里面），然后再看到的马身子猜测一下这个物体的位置。但穷举搜索就不是，马身子的这个区域不是一个马的区域，必须得去搜索这个区域，直到这个区域包含整个马。rpn的优点就是你能用神经网络去从一个图像区域拟合出目标的位置来，这在非神经网络方法上肯定不能用。因为神经网络是一个复杂的非线性函数，传统的方法并不能轻易的做出复杂函数来。虽然传统的方法也能拟合复杂函数，如svm。不过传统方法很多都是模板匹配类的方法，只能记住训练图片中的整体特征。神经网络是层级特征提取的，在图像上更加符合特点。例如识别自行车，svm方法就是把训练图像的自行车都记住 如果新来一辆车，和这些特点不太相同，svm就挂了。但神经网络不同，方式倾向于训练出车把和车轮子等的检测器，再对部件进行组合。所以rpn中训练的东西就是一些根据底层得到的部件检测器推测物体位置的一个函数。以上内容来自于老师给我的讲解，看完了也就能理解的差不多了，RPN的作用更像是人的感觉一样的网络，这么说可能不太合适，比如看一辆自行车，人可能只看到一部分，前轮或后轮，就能知道这是一辆自行车了，而RPN的作用正是如此，所以RPN可以选出更少的region proposal而且更加准确，anchor是在选好region proposal的基础上，用不同长宽比的不同尺度能去尽量的把这个物体包进去。 Share features采用4步交替训练的方法： 用一个ImageNet预训练模型对RPN网络做finetune（RPN的作用在上面说过，这里finetune的目的是为了生成更好的region proposal）； 用第一步得到的region proposal单独的训练一个Fast RCNN（Fast RCNN的参数也由ImageNet的与训练模型初始化，但这里不共享参数）； 使用第2步训练好的Fast RCNN模型做预训练模型，固定RPN层以外的参数，只对RPN层做finetune，这里已经开始共享卷积层了； 最后一步，固定共享卷积层的参数，对fast RCNN部分做finetune，至此，整个faster RCNN训练完成。]]></content>
      <categories>
        <category>论文阅读</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>Faster RCNN</tag>
        <tag>论文阅读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode-Search Insert Position]]></title>
    <url>%2F2019%2F04%2F29%2FLeetcode035-Search%20Insert%20Position%2F</url>
    <content type="text"><![CDATA[Given a sorted array and a target value, return the index if the target is found. If not, return the index where it would be if it were inserted in order. You may assume no duplicates in the array. Example 1: 12Input: [1,3,5,6], 5Output: 2 Example 2: 12Input: [1,3,5,6], 2Output: 1 Example 3: 12Input: [1,3,5,6], 7Output: 4 Example 4: 12Input: [1,3,5,6], 0Output: 0 Solution: 1234567891011121314151617181920212223class Solution &#123;public: int searchInsert(vector&lt;int&gt;&amp; nums, int target) &#123; int res = 0; if (nums.size() == 0 || nums[0] &gt; target) &#123; return 0; &#125; else if (nums.back() &lt; target) &#123; return nums.size(); &#125; else &#123; for (int i = 0; i &lt; nums.size() - 1; i++) &#123; if (nums[i] == target) &#123; res = i; &#125; if (nums[i] &lt; target &amp;&amp; nums[i+1] &gt;= target) &#123; res = i+1; &#125; &#125; return res; &#125; &#125;&#125;; Time Submitted Status Runtime Memory Language a few seconds ago Accepted 8 ms 8.9 MB cpp 12Runtime: 8 ms, faster than 98.61% of C++ online submissions for Search Insert Position.Memory Usage: 8.9 MB, less than 98.08% of C++ online submissions for Search Insert Position. 查找的部分应该还可以优化，用二分查找做还可以再快一点。]]></content>
      <categories>
        <category>Leetcode</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++多线程编程中std::future的使用]]></title>
    <url>%2F2019%2F04%2F23%2FC%2B%2Buse-of-future%2F</url>
    <content type="text"><![CDATA[最近一直在搞多线程，C++的底子较烂，直接用.detach()方法创建线程，无法使输入顺序和输出顺序同步，而且输入数据在不断的产生，类似生产者和消费者问题，不断的创建新线程会浪费时间，所以想到用线程池的方法。 std::future是一个类模板(class template)，其对象存储未来的值，一个std::future对象在内部存储一个将来会被赋值的值，并提供了一个访问该值的机制，通过get()成员函数实现。但如果有人视图在get()函数可用之前通过它来访问相关的值，那么get()函数将会阻塞，直到该值可用。来源：https://blog.csdn.net/lijinqi1987/article/details/78507623 我理解这段话的意思就是因为多线程输出没办法控制输出的顺序，那么future就为所有会有输出的位置放一个占位符，认定这个位置会有一个输出，但是具体什么时间会有不确定。 测试结果： 来源：https://github.com/progschj/ThreadPool GitHub2k多star的一个线程池的项目，改了一下example，看输出更直观一些。 话说昨天有个小破站的后台源码被push上来了，golang的教程可能要火了，push一时爽，牢饭吃到老，职业道德还是要有的。 123456hello hello hello hello hello hello hello hello hello hello 1 2 0 1 2 2 0 1 0 0 world 1world 2 world 0 world 1 hello 2 world 2 world 2 hello 0 hello 3 world 0 world 0 hello 1hello 3 hello 0 hello 1 hello 2 world 0 world 1 hello 1 hello 2 world 2 world 0 hello 3 world 3 world 1 world 3 world 0world 1 world 2 world 2 world 1 world 30 1 2 0 1 2 0 1 2 0 1 2 3 0 1 2 3 0 1 2 3 可以发现，创建了10个线程，线程的执行是并行的，但是输出的结果和输出的顺序是一样的。 完整代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899//*****************ThreadPool.h**********************#ifndef THREAD_POOL_H#define THREAD_POOL_H#include &lt;vector&gt;#include &lt;queue&gt;#include &lt;memory&gt;#include &lt;thread&gt;#include &lt;mutex&gt;#include &lt;condition_variable&gt;#include &lt;future&gt;#include &lt;functional&gt;#include &lt;stdexcept&gt;class ThreadPool &#123;public: ThreadPool(size_t); template&lt;class F, class... Args&gt; auto enqueue(F&amp;&amp; f, Args&amp;&amp;... args) -&gt; std::future&lt;typename std::result_of&lt;F(Args...)&gt;::type&gt;; ~ThreadPool();private: // need to keep track of threads so we can join them std::vector&lt; std::thread &gt; workers; // the task queue std::queue&lt; std::function&lt;void()&gt; &gt; tasks; // synchronization std::mutex queue_mutex; std::condition_variable condition; bool stop;&#125;; // the constructor just launches some amount of workersinline ThreadPool::ThreadPool(size_t threads) : stop(false)&#123; for(size_t i = 0;i&lt;threads;++i) workers.emplace_back( [this] &#123; for(;;) &#123; std::function&lt;void()&gt; task; &#123; std::unique_lock&lt;std::mutex&gt; lock(this-&gt;queue_mutex); this-&gt;condition.wait(lock, [this]&#123; return this-&gt;stop || !this-&gt;tasks.empty(); &#125;); if(this-&gt;stop &amp;&amp; this-&gt;tasks.empty()) return; task = std::move(this-&gt;tasks.front()); this-&gt;tasks.pop(); &#125; task(); &#125; &#125; );&#125;// add new work item to the pooltemplate&lt;class F, class... Args&gt;auto ThreadPool::enqueue(F&amp;&amp; f, Args&amp;&amp;... args) -&gt; std::future&lt;typename std::result_of&lt;F(Args...)&gt;::type&gt;&#123; using return_type = typename std::result_of&lt;F(Args...)&gt;::type; auto task = std::make_shared&lt; std::packaged_task&lt;return_type()&gt; &gt;( std::bind(std::forward&lt;F&gt;(f), std::forward&lt;Args&gt;(args)...) ); std::future&lt;return_type&gt; res = task-&gt;get_future(); &#123; std::unique_lock&lt;std::mutex&gt; lock(queue_mutex); // don't allow enqueueing after stopping the pool if(stop) throw std::runtime_error("enqueue on stopped ThreadPool"); tasks.emplace([task]()&#123; (*task)(); &#125;); &#125; condition.notify_one(); return res;&#125;// the destructor joins all threadsinline ThreadPool::~ThreadPool()&#123; &#123; std::unique_lock&lt;std::mutex&gt; lock(queue_mutex); stop = true; &#125; condition.notify_all(); for(std::thread &amp;worker: workers) worker.join();&#125;#endif 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253//*****************example.cpp**********************#include &lt;iostream&gt;#include &lt;vector&gt;#include &lt;chrono&gt;#include "ThreadPool.h"std::vector&lt;std::vector&lt;int&gt;&gt; a;int main()&#123; ThreadPool pool(10); //create a &lt;future&gt; vector to wait the output std::vector&lt; std::future&lt;std::vector&lt;int&gt;&gt; &gt; results; std::vector&lt;int&gt; batch = &#123;3, 3, 3&#125;; int m = 3; for (int b = 0; b &lt; batch.size(); b++) &#123; if (m &gt; 0) &#123; batch.push_back(4); &#125; for (int i = 0; i &lt; batch[b]; i++) &#123; results.emplace_back( pool.enqueue([i] &#123; std::vector&lt;int&gt; res = &#123;i&#125;; std::cout &lt;&lt; "hello " &lt;&lt; i &lt;&lt; " "; std::this_thread::sleep_for(std::chrono::seconds(1)); std::cout &lt;&lt; "world " &lt;&lt; i &lt;&lt; " "; return res; &#125;)); &#125; m--; &#125; //get output for(auto &amp;&amp; result: results) a.emplace_back(result.get()); std::cout &lt;&lt; std::endl; std::cout &lt;&lt; std::endl; //after get all output, print it for (int i = 0; i &lt; a.size(); i++) &#123; for (int j = 0; j &lt; a[i].size(); j++) std::cout &lt;&lt; a[i][j] &lt;&lt; " "; &#125; system("pause"); return 0;&#125;]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>thread</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode-Remove Duplicates from Sorted Array]]></title>
    <url>%2F2019%2F04%2F17%2FLeetcode026-Remove%20Duplicates%20from%20Sorted%20Array%2F</url>
    <content type="text"><![CDATA[Given a sorted array nums, remove the duplicates in-place such that each element appear only once and return the new length. Do not allocate extra space for another array, you must do this by modifying the input array in-place with O(1) extra memory. Example 1: 12345Given nums = [1,1,2],Your function should return length = 2, with the first two elements of nums being 1 and 2 respectively.It doesn&apos;t matter what you leave beyond the returned length. Example 2: 12345Given nums = [0,0,1,1,1,2,2,3,3,4],Your function should return length = 5, with the first five elements of nums being modified to 0, 1, 2, 3, and 4 respectively.It doesn&apos;t matter what values are set beyond the returned length. Clarification: Confused why the returned value is an integer but your answer is an array? Note that the input array is passed in by reference, which means modification to the input array will be known to the caller as well. Internally you can think of this: 12345678// nums is passed in by reference. (i.e., without making a copy)int len = removeDuplicates(nums);// any modification to nums in your function would be known by the caller.// using the length returned by your function, it prints the first len elements.for (int i = 0; i &lt; len; i++) &#123; print(nums[i]);&#125; Solution:Vector在日常写程序用的比较多，所以看一眼就有了点想法。传入的是vector的引用，需要在原数组上操作，vector已经排序了，比较索引为i和i+1的元素是否相同就可以，因为美股元素只能出现一次，所以有两种解决办法，遇到相同的元素移到最后或者删除，移到最后还要额外增加一个变量来计算不同元素的数量，所以直接用删除的方式。需要注意的就是vector的删除问题，当删除索引为i的元素时，i后面的元素都会向前移动一位，要注意i++的索引的变化。 123456789101112131415class Solution &#123;public: int removeDuplicates(vector&lt;int&gt;&amp; nums) &#123; if (nums.size() == 0) &#123; return 0; &#125; for (int i = 0; i &lt; nums.size() - 1; i++) &#123; if (nums[i] == nums[i + 1]) &#123; nums.erase(nums.begin() + i + 1); i--; //注意索引的变化 &#125; &#125; return nums.size(); &#125;&#125;; Time Submitted Status Runtime Memory Language a few seconds ago Accepted 156 ms 9.9 MB cpp 大神的solution： 1234567class Solution &#123;public: int removeDuplicates(vector&lt;int&gt;&amp; nums) &#123; nums.erase(std::unique(nums.begin(), nums.end()), nums.end()); return nums.size(); &#125;&#125;; Time Submitted Status Runtime Memory Language a few seconds ago Accepted 24 ms 9.8 MB cpp]]></content>
      <categories>
        <category>Leetcode</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++调用Python版Mask-R-CNN并传递和接收参数]]></title>
    <url>%2F2019%2F04%2F14%2FC%2B%2B-call-Python-Mask-R-CNN%2F</url>
    <content type="text"><![CDATA[想做一个用Mask R-CNN只检测人的demo，发现github已经有人用Python实现了，但后处理用的是C++，所以想直接用C++器调用python，再将需要的结果返回给C++。 运行环境： Visual Studio 2015，Python3.6（Anaconda），OpenCV3.4.2（C++），tensorflow1.12，Keras2.0.8 C++环境配置 配置OpenCV 新建一个C++工程； 右键属性$\rightarrow$C++目录$\rightarrow$包含目录$\rightarrow$点击编辑，将 123D:\Programs\opencv\build\includeD:\Programs\opencv\build\include\opencvD:\Programs\opencv\build\include\opencv2 加入包含目录，注意配置的方案平台版本和当前运行的一致； 右键属性$\rightarrow$C++目录$\rightarrow$库目录$\rightarrow$点击编辑，将 1D:\Programs\opencv\build\x64\vc14\lib 加入库目录，注意VS的版本，2017改用vc15的目录； 右键属性$\rightarrow$链接器$\rightarrow$输入$\rightarrow$点击编辑，将 1opencv_world342.lib 加入其中。 配置Python环境 右键属性$\rightarrow$C++目录$\rightarrow$包含目录$\rightarrow$点击编辑，将 12D:\Programs\Anaconda3\includeD:\Programs\Anaconda3\Lib\site-packages\numpy\core\include 加入到包含目录中； 右键属性$\rightarrow$C++目录$\rightarrow$库目录$\rightarrow$点击编辑，将 12D:\Programs\Anaconda3\libsD:\Programs\Anaconda3\Lib\site-packages\numpy\core\lib 加入库目录; 右键属性$\rightarrow$链接器$\rightarrow$输入$\rightarrow$点击编辑，将 1python36.lib 加入其中，注意只有python36，没有python36d，所以调试的时候要用relese的版本，debug的版本会报错。 调用Python 从C++输入图片数据 由于C++用OpenCV读取的图片格式和Mask R-CNN的输入格式不同，所以需要先用C++处理好图片，传递给Python。 12345678910111213141516171819202122232425262728Mat img = imread("./image.jpg");auto sz = img.size();int x = sz.width;int y = sz.height;int z = img.channels();uchar *CArrays = new uchar[x*y*z];int iChannels = img.channels();int iRows = img.rows;int iCols = img.cols * iChannels;if (img.isContinuous())&#123; iCols *= iRows; iRows = 1;&#125;uchar* p;int id = -1;for (int i = 0; i &lt; iRows; i++)&#123; // get the pointer to the ith row p = img.ptr&lt;uchar&gt;(i); // operates on each pixel for (int j = 0; j &lt; iCols; j++) &#123; CArrays[++id] = p[j];//连续空间 &#125;&#125;npy_intp Dims[3] = &#123;y, x, z&#125;; //注意这个维度数据！PyObject *PyArray = PyArray_SimpleNewFromData(3, Dims, NPY_UBYTE, CArrays); 调用Mask R-CNN 1234567891011121314151617181920212223242526272829303132333435363738394041//初始化pythonPy_Initialize();import_array();PyRun_SimpleString("import sys"); PyRun_SimpleString("sys.path.append(r'C:\\Users\\Administrator\\Documents\\Keypoints-of-humanpose-with-Mask-R-CNN-master')");//定义python类型的变量PyObject *pModule = NULL;PyObject *pFunc = NULL;PyObject *pArg = NULL;PyObject *result = NULL;PyObject *pDict = NULL;//直接运行python代码PyRun_SimpleString("print('python start')");PyObject *ArgList = PyTuple_New(1);...PyTuple_SetItem(ArgList, 0, PyArray);//引入模块pModule = PyImport_ImportModule("human_detected");if (!pModule)&#123; cout &lt;&lt; "Import Module Failed" &lt;&lt; endl; system("pause"); return 0;&#125;//获取模块字典属性pDict = PyModule_GetDict(pModule);//直接获取模块中的函数pFunc = PyObject_GetAttrString(pModule, "detect");... Mask R-CNN接受参数并返回值 Mask R-CNN检测人项目地址：https://github.com/Junyuan12/Mask_RCNN_Humanpose Mask R-CNN的配置就不细说了，网上有很多教程，主要是windows下配置pycocotools可能会有问题， windows下pycocotools安装教程：https://blog.csdn.net/qq_29592829/article/details/82877494 在Mask R-CNN中新建一个py文件，human_detected.py 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172import osimport sysimport randomimport mathimport numpy as npimport skimage.ioimport matplotlibimport matplotlib.pyplot as pltimport cocoimport utilsimport model as modellibimport visualizefrom model import logimport cv2def detect(image): # print(image) ROOT_DIR = os.getcwd() # Directory to save logs and trained model MODEL_DIR = os.path.join(ROOT_DIR, "mylogs") # Local path to trained weights file COCO_MODEL_PATH = os.path.join(ROOT_DIR, "mask_rcnn_coco_humanpose.h5") # Download COCO trained weights from Releases if needed if not os.path.exists(COCO_MODEL_PATH): utils.download_trained_weights(COCO_MODEL_PATH) class InferenceConfig(coco.CocoConfig): GPU_COUNT = 1 IMAGES_PER_GPU = 1 KEYPOINT_MASK_POOL_SIZE = 7 inference_config = InferenceConfig() # Recreate the model in inference mode model = modellib.MaskRCNN(mode="inference", config=inference_config, model_dir=MODEL_DIR) # Get path to saved weights model_path = os.path.join(ROOT_DIR, "mask_rcnn_coco_humanpose.h5") assert model_path != "", "Provide path to trained weights" print("Loading weights from ", model_path) model.load_weights(model_path, by_name=True) # COCO Class names #For human pose task We just use "BG" and "person" class_names = ['BG', 'person'] #BGR-&gt;RGB image = image[:,:,::-1] #print(np.shape(image)) # Run detection results = model.detect_keypoint([image], verbose=1) r = results[0] # for one image log("rois",r['rois']) log("keypoints",r['keypoints']) log("class_ids",r['class_ids']) log("keypoints",r['keypoints']) log("masks",r['masks']) log("scores",r['scores']) visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], class_names, r['scores']) flat_roi = r['rois'].flatten() print(flat_roi) return flat_roi 其中包括一个函数detect(image)，用于接受C++传进来的图片，并最终返回每个人的roi。 C++接受返回参数 python将结果展开成一列，C++接受返回的一维数组并输出： 1234567891011121314151617181920212223// 调用直接获得的函数,并传递参数PyObject *pReturn = PyObject_CallObject(pFunc, ArgList);//获取python程序的返回结果//以下是对返回的一维数组结果进行处理if (pReturn)&#123; //将结果类型转换成数组对象类型 PyArrayObject *pyResultArr = (PyArrayObject *)pReturn; //从Python中的PyArrayObject解析出数组数据为c的double类型。 int *resDataArr = (int *)PyArray_DATA(pyResultArr); int dimNum = PyArray_NDIM(pyResultArr);//返回数组的维度数，此处恒为1 npy_intp *pdim = PyArray_DIMS(pyResultArr);//返回数组各维度上的元素个数值 //以下是对返回结果的输出显示 for (int i = 0; i &lt; dimNum; ++i) &#123; for (int j = 0; j &lt; pdim[0]; ++j) cout &lt;&lt; resDataArr[i * pdim[0] + j] &lt;&lt; ","; &#125; cout &lt;&lt; endl;&#125; 完整代码如下 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112#include &lt;Python.h&gt;#include &lt;iostream&gt;#include &lt;string&gt;#include &lt;numpy/arrayobject.h&gt;#include &lt;opencv2/highgui/highgui.hpp&gt;#include &lt;opencv2/imgproc/imgproc.hpp&gt;#include &lt;opencv2/core/core.hpp&gt;using namespace std;int main(int argc, char* argv[])&#123; cv::Mat img = cv::imread("./image.jpg"); //初始化python Py_Initialize(); import_array(); PyRun_SimpleString("import sys"); PyRun_SimpleString("sys.path.append(r'C:\\Users\\Administrator\\Documents\\Keypoints-of-humanpose-with-Mask-R-CNN-master')"); //PyRun_SimpleString("print(sys.path)"); //定义python类型的变量 PyObject *pModule = NULL; PyObject *pFunc = NULL; PyObject *pArg = NULL; PyObject *result = NULL; PyObject *pDict = NULL; //直接运行python代码 PyRun_SimpleString("print('python start')"); PyObject *ArgList = PyTuple_New(1); auto sz = img.size(); int x = sz.width; int y = sz.height; int z = img.channels(); uchar *CArrays = new uchar[x*y*z]; int iChannels = img.channels(); int iRows = img.rows; int iCols = img.cols * iChannels; if (img.isContinuous()) &#123; iCols *= iRows; iRows = 1; &#125; uchar* p; int id = -1; for (int i = 0; i &lt; iRows; i++) &#123; // get the pointer to the ith row p = img.ptr&lt;uchar&gt;(i); // operates on each pixel for (int j = 0; j &lt; iCols; j++) &#123; CArrays[++id] = p[j];//连续空间 &#125; &#125; npy_intp Dims[3] = &#123; y, x, z &#125;; //注意这个维度数据！ PyObject *PyArray = PyArray_SimpleNewFromData(3, Dims, NPY_UBYTE, CArrays); PyTuple_SetItem(ArgList, 0, PyArray); //引入模块 pModule = PyImport_ImportModule("human_detected"); if (!pModule) &#123; cout &lt;&lt; "Import Module Failed" &lt;&lt; endl; system("pause"); return 0; &#125; //获取模块字典属性 pDict = PyModule_GetDict(pModule); //直接获取模块中的函数 pFunc = PyObject_GetAttrString(pModule, "detect"); // 调用直接获得的函数,并传递参数 PyObject *pReturn = PyObject_CallObject(pFunc, ArgList); //获取python程序的返回结果 //以下是对返回的一维数组结果进行处理 if (pReturn) &#123; //将结果类型转换成数组对象类型 PyArrayObject *pyResultArr = (PyArrayObject *)pReturn; //从Python中的PyArrayObject解析出数组数据为c的double类型。 int *resDataArr = (int *)PyArray_DATA(pyResultArr); int dimNum = PyArray_NDIM(pyResultArr);//返回数组的维度数，此处恒为1 npy_intp *pdim = PyArray_DIMS(pyResultArr);//返回数组各维度上的元素个数值 //以下是对返回结果的输出显示 for (int i = 0; i &lt; dimNum; ++i) &#123; for (int j = 0; j &lt; pdim[0]; ++j) cout &lt;&lt; resDataArr[i * pdim[0] + j] &lt;&lt; ","; &#125; cout &lt;&lt; endl; &#125; PyRun_SimpleString("print('python end')"); ////释放python Py_Finalize(); system("pause"); return 0;&#125;]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>python</tag>
        <tag>mask rcnn</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++栈实现分隔符的匹配]]></title>
    <url>%2F2019%2F04%2F14%2FC%2B%2B-parenthesis-matching%2F</url>
    <content type="text"><![CDATA[栈是一种后进先出(LIFO)的线性数据结构。 栈适用于数据存储后以相反的顺序来检索的情况。站的一个应用是在程序中匹配分隔符。 在C++程序中存在下列分隔符：圆括号”(“和”)“、方括号”[“和”]“、花括号”{“和”}“、注释分隔符”/*“和”*/“ 栈的操作： clear()——清空栈。 isEmpty()——判断栈是否为空。 push(el)——将元素el放到栈的顶部。 pop()——弹出栈顶部的元素。 topEL()——获取栈顶部的元素，不删除。 genStack.h 1234567891011121314151617181920212223242526272829303132333435363738394041424344//******************* genStack.h ************************// generic class for vector implenmentation of stack#ifndef STACK#define STACK#include &lt;vector&gt;using namespace std;template&lt;class T, int capacity = 30&gt;class Stack &#123;public: Stack() &#123; pool.reserve(capacity); &#125; void clear() &#123; pool.clear(); &#125; bool isEmpty() const &#123; return pool.empty(); &#125; T&amp; topEl() &#123; return pool.back(); &#125; T pop() &#123; T el = pool.back(); pool.pop_back(); return el; &#125; void push(const T&amp; el) &#123; pool.push_back(el); &#125;private: vector&lt;T&gt; pool;&#125;;#endif genStack.cpp 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354//******************* genStack.h ************************//用栈实现分隔符的匹配#include &lt;iostream&gt;#include "genStack.h"#include &lt;string&gt;using namespace std;int main() &#123; string str = "s=t[5]+u/(v*(w+y))"; Stack&lt;char&gt; s1; for (int i = 0; i &lt; str.size(); i++) &#123; //注意单引号和双引号的使用！！！ if (str[i] == '(' || str[i] == '[' || str[i] == '&#123;') &#123; s1.push(str[i]); //cout &lt;&lt; "topEL: " &lt;&lt; s1.topEl() &lt;&lt; endl; &#125; else if (str[i] == ')' || str[i] == ']' || str[i] == '&#125;') &#123; if ((s1.topEl()=='(' &amp;&amp; str[i]==')') || (s1.topEl()=='[' &amp;&amp; str[i]==']') || (s1.topEl()=='&#123;' &amp;&amp; str[i]=='&#125;')) &#123; s1.pop(); &#125; else &#123; cout &lt;&lt; "error!" &lt;&lt; endl; system("pause"); return 0; &#125; &#125; else if (str[i] == '/') &#123; if (str[i + 1] == '*') &#123; for (int j = i; j &lt; str.size(); j++) &#123; if (str[j] == '*' &amp;&amp; str[j + 1] == '/') &#123; i = j + 1; break; &#125; else if (j == str.size()-1) &#123; cout &lt;&lt; "'/*' can not match '*/'" &lt;&lt; endl; system("pause"); return 0; &#125; &#125; &#125; else continue; &#125; &#125; if (s1.isEmpty()) cout &lt;&lt; "success!" &lt;&lt; endl; else cout &lt;&lt; "failed!" &lt;&lt; endl; system("pause"); return 0;&#125;]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode-Valid Parentheses]]></title>
    <url>%2F2019%2F04%2F12%2FLeetcode020-Valid%20Parentheses%2F</url>
    <content type="text"><![CDATA[之前就看到这道题，没想到好的方法，正好最近在搞数据结构，到栈这里一个应用就是括号的匹配。 Given a string containing just the characters &#39;(&#39;, &#39;)&#39;, &#39;{&#39;, &#39;}&#39;, &#39;[&#39; and &#39;]&#39;, determine if the input string is valid. An input string is valid if: Open brackets must be closed by the same type of brackets. Open brackets must be closed in the correct order. Note that an empty string is also considered valid. Example 1: 12Input: "()"Output: true Example 2: 12Input: "()[]&#123;&#125;"Output: true Example 3: 12Input: "(]"Output: false Example 4: 12Input: "([)]"Output: false Example 5: 12Input: "&#123;[]&#125;"Output: true Solution: 123456789101112131415161718192021222324252627class Solution &#123;public: bool isValid(string str) &#123; stack&lt;char&gt; s1; for (int i = 0; i &lt; str.size(); i++) &#123; if (str[i] == '(' || str[i] == '[' || str[i] == '&#123;') &#123; s1.push(str[i]); &#125; else if (str[i] == ')' || str[i] == ']' || str[i] == '&#125;') &#123; if (s1.empty()) &#123; return false; &#125; else if ((s1.top()=='(' &amp;&amp; str[i]==')') || (s1.top()=='[' &amp;&amp; str[i]==']') || (s1.top()=='&#123;' &amp;&amp; str[i]=='&#125;')) &#123; s1.pop(); &#125; else &#123; return false; &#125; &#125; &#125; if (s1.empty()) return true; else return false; &#125;&#125;; 数据结构果然很重要啊！！！ Time Submitted Status Runtime Memory Language a few seconds ago Accepted 4 ms 8.4 MB cpp]]></content>
      <categories>
        <category>Leetcode</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode-Longest Common Prefix]]></title>
    <url>%2F2019%2F04%2F11%2FLeetcode014-Longest%20Common%20Prefix%2F</url>
    <content type="text"><![CDATA[Write a function to find the longest common prefix string amongst an array of strings. If there is no common prefix, return an empty string &quot;&quot;. Example 1: 12Input: ["flower","flow","flight"]Output: "fl" Example 2: 123Input: ["dog","racecar","car"]Output: ""Explanation: There is no common prefix among the input strings. Note: All given inputs are in lowercase letters a-z. Solution： 1234567891011121314151617181920212223242526272829class Solution &#123;public: string longestCommonPrefix(vector&lt;string&gt;&amp; strs) &#123; if (strs.size() == 0) return ""; int minlen = INT_MAX; string res = ""; for (int i = 0; i &lt; strs.size(); i++) &#123; if (strs[i].size() &lt; minlen) minlen = strs[i].size(); &#125; for (int i = 0; i &lt; minlen; i++) &#123; bool flag = true; for (int j = 0; j &lt; strs.size() - 1; j++) &#123; if (strs[j][i] != strs[j + 1][i]) flag = false; &#125; if (flag == true) res = res + strs[0][i]; else break; &#125; return res; &#125;&#125;; 没什么亮点的写法。 Time Submitted Status Runtime Memory Language a few seconds ago Accepted 8 ms 9.1 MB cpp]]></content>
      <categories>
        <category>Leetcode</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode-Roman to Integer]]></title>
    <url>%2F2019%2F04%2F09%2FLeetcode013-Roman%20to%20Integer%2F</url>
    <content type="text"><![CDATA[Roman numerals are represented by seven different symbols: I, V, X, L, C, D and M. 12345678Symbol ValueI 1V 5X 10L 50C 100D 500M 1000 For example, two is written as II in Roman numeral, just two one’s added together. Twelve is written as, XII, which is simply X + II. The number twenty seven is written as XXVII, which is XX + V + II. Roman numerals are usually written largest to smallest from left to right. However, the numeral for four is not IIII. Instead, the number four is written as IV. Because the one is before the five we subtract it making four. The same principle applies to the number nine, which is written as IX. There are six instances where subtraction is used: I can be placed before V (5) and X (10) to make 4 and 9. X can be placed before L (50) and C (100) to make 40 and 90. C can be placed before D (500) and M (1000) to make 400 and 900. Given a roman numeral, convert it to an integer. Input is guaranteed to be within the range from 1 to 3999. Example 1: 12Input: "III"Output: 3 Example 2: 12Input: "IV"Output: 4 Example 3: 12Input: "IX"Output: 9 Example 4: 123Input: "LVIII"Output: 58Explanation: L = 50, V= 5, III = 3. Example 5: 123Input: "MCMXCIV"Output: 1994Explanation: M = 1000, CM = 900, XC = 90 and IV = 4. 最开始想用每种情况都写一遍，虽然会的不多，但还是嫌麻烦，想到了Python中的用两个list去对应相同的索引的不同类型，所以用数组老对应不同的罗马符号。 Solution： 1234567891011121314151617181920212223242526272829class Solution &#123;public: int romanToInt(string s) &#123; int num[] = &#123;1, 5, 10, 50, 100, 500, 1000&#125;; string rom = "IVXLCDM"; vector&lt;int&gt; tmp; int res = 0; for (int i = 0; i &lt; s.size(); i++) &#123; for (int j = 0; j &lt; 7; j++) &#123; if (s[i] == rom[j]) tmp.push_back(num[j]); &#125; &#125; for (int i = 0; i &lt; tmp.size(); i++) &#123; if (i == tmp.size() - 1 || tmp[i] &gt;= tmp[i + 1]) &#123; res += tmp[i]; &#125; else &#123; res -= tmp[i]; &#125; &#125; return res; &#125;&#125;; if (i == tmp.size() - 1 || tmp[i] &gt;= tmp[i + 1])，这里最开始是if(tmp[i] &gt;= tmp[i + 1])，处理&quot;MCDLXXVI&quot;时报错了，输出结果发现最后的I并没有加进去，很神奇，原因还没找到，先留个坑。 Time Submitted Status Runtime Memory Language a few seconds ago Accepted 20 ms 9 MB cpp]]></content>
      <categories>
        <category>Leetcode</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[通过git将项目上传到github]]></title>
    <url>%2F2019%2F04%2F09%2Fupdate-program-to-github-by-git%2F</url>
    <content type="text"><![CDATA[原文链接：https://blog.csdn.net/jerryhanjj/article/details/72777618 配置Git、SSH 下载、安装Git 绑定用户 12$ git config --global user.name &quot;Your Name&quot; $ git config --global user.email &quot;email@example.com&quot; 配置SSH 在用户主目录下，看看有没有.ssh目录，如果有，再看看这个目录下有没有id_rsa和id_rsa.pub这两个文件，如果已经有了，可直接跳到下一步。如果没有，打开Shell（Windows下打开GitBash），创建SSH Key，密码可以不设置直接回车。 1$ ssh-keygen -t rsa -C &quot;youremail@example.com&quot; 如果一切顺利的话，可以在用户主目录里找到 .ssh​目录，里面有 id_rsa 和id_rsa.pub 两个文件，这两个就是SSH Key 的秘钥对，id_rsa 是私钥，不能泄露出去，id_rsa.pub是公钥，可以放心地告诉任何人。用记事本打开 id_rsa.pub，得到ssh key 公钥。 为 Github 账户添加 ssh key 。登录 Github，展开个人头像的小三角，点settings，然后打开SSH keys菜单，点击Add SSH key新增密钥，填上标题。 上传项目 建立仓库 填一下仓库名称，Initialize this repository with a README是可选的，建议在创建时选上，可以在后面省一个步骤。填好之后，点Create repository完成仓库的建立。 克隆仓库 如果是全新的项目没有任何文件，也可以不用克隆仓库，跳过这一步。点开 Git Shell，进入命令行。首先我们先要把 GitHub 上的我们新建的仓库 clone下来。在初始化版本库之前，先要确认认证的公钥是否正确。 1$ ssh -T git@github.com 如果收到成功的确认消息，就可以开始克隆远程仓库了。 1$ git clone https://github.com/username/program-name.git 克隆仓库之后就在文件夹中出现了项目文件夹及文件,进入项目文件夹，对其进行初始化。 1$ git init 上传README文件 如果在创建 Github 仓库时没有勾选创建 README.md 文件，则要先创建 README.md 文件，不然上传文件会报错。如果已经勾选，可以跳过此步骤。 12345$ git init$ touch README.md$ git add README.md$ git commit -m &apos;first_commit&apos;$ git remote add origin 上传项目 跟踪项目文件夹中的所有文件和文件夹： 1$ git add . 输入本次的提交说明，准备提交暂存区中的更改的已跟踪文件，单引号内为说明内容： 1$ git commit -m &apos;first_commit&apos; 关联远程仓库，添加后，远程库的名字就是 origin，这是 Git 默认的叫法，也可以改成别的，但是 origin 这个名字一看就知道是远程库。 1$ git remote add origin https://github.com/username/program-name.git 如果关联出现错误 fatal: remote origin already exists，则执行git remote rm origin再进行关联。 把本地库的所有内容推送到远程库上： 1$ git push -u origin master 如果在推送时出现错误 error:failed to push som refs to.......，则执行下列语句： 1$ git pull origin master 将远程仓库 Github 上的文件拉下来合并之后重新推送上去。]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>github</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode-Palindrome Number]]></title>
    <url>%2F2019%2F04%2F07%2FLeetcode009-Palindrome%20Number%2F</url>
    <content type="text"><![CDATA[Determine whether an integer is a palindrome. An integer is a palindrome when it reads the same backward as forward. Example 1: 12Input: 121Output: true Example 2: 123Input: -121Output: falseExplanation: From left to right, it reads -121. From right to left, it becomes 121-. Therefore it is not a palindrome. Example 3: 123Input: 10Output: falseExplanation: Reads 01 from right to left. Therefore it is not a palindrome. Follow up: Coud you solve it without converting the integer to a string? 算法思想和第7题差不多，而且说了不让用string，就是第7题之后加个判断，感觉自己在偷懒，但是还是想了好长时间才想出来。 Solution： 1234567891011121314151617181920class Solution &#123;public: bool isPalindrome(int x) &#123; int res = 0, tmp = x; if (x &lt; 0) return false; while (tmp != 0) &#123; int pop = tmp % 10; tmp /= 10; if (res &gt; INT_MAX/10 || (res == INT_MAX / 10 &amp;&amp; pop &gt; 7)) return 0; if (res &lt; INT_MIN/10 || (res == INT_MIN / 10 &amp;&amp; pop &lt; -8)) return 0; res = res * 10 + pop; &#125; if (res == x) return true; else return false; &#125;&#125;; Time Submitted Status Runtime Memory Language a few seconds ago Accepted 32 ms 8 MB cpp 最近负能量有点多，需要心灵鸡汤透一透，最好是喝完能上头的那种。]]></content>
      <categories>
        <category>Leetcode</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode-Reverse Integer]]></title>
    <url>%2F2019%2F04%2F06%2FLeetcode007-Reverse%20Integer%2F</url>
    <content type="text"><![CDATA[Given a 32-bit signed integer, reverse digits of an integer. Example 1: 12Input: 123Output: 321 Example 2: 12Input: -123Output: -321 Example 3: 12Input: 120Output: 21 Note:Assume we are dealing with an environment which could only store integers within the 32-bit signed integer range: $[−2^{31}, 2^{31 − 1}]$. For the purpose of this problem, assume that your function returns 0 when the reversed integer overflows. 看起来是一个特别简单的问题，第一想法也是个野路子，先把整型转字符串，再将字符串逆序排列一下，在转换回整型，感觉不妥。 算法思想特别简单， 1res = res * 10 + x % 10; 其实我没想到，看了别人的答案才领悟。 这里很容易懂，但是数据溢出是个大问题，我以为一句 1x &gt;= INT_MIN || x &lt;= INT_MAX 就可以解决了，too young, too naive. 果然要偷偷看答案了。 核心思想： pop = x % 10, If $temp = res\times10 + pop$ causes overflow, then it must be that $res\geq\frac{INTMAX}{10}$ If $res\geq\frac{INTMAX}{10}$, then $temp = res\times10 + pop$ is guaranteed to overflow If $res==\frac{INTMAX}{10}$, then $temp = res\times10 + pop$ will overflow if and only if $pop &gt; 7$ 1234567891011121314class Solution &#123;public: int reverse(int x) &#123; int rev = 0; while (x != 0) &#123; int pop = x % 10; x /= 10; if (rev &gt; INT_MAX/10 || (rev == INT_MAX / 10 &amp;&amp; pop &gt; 7)) return 0; if (rev &lt; INT_MIN/10 || (rev == INT_MIN / 10 &amp;&amp; pop &lt; -8)) return 0; rev = rev * 10 + pop; &#125; return rev; &#125;&#125;;]]></content>
      <categories>
        <category>Leetcode</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode-Two Sum]]></title>
    <url>%2F2019%2F03%2F28%2FLeetcode001-Two%20Sum%2F</url>
    <content type="text"><![CDATA[Given an array of integers, return indices of the two numbers such that they add up to a specific target. You may assume that each input would have exactly one solution, and you may not use the same element twice. Example: 1234Given nums = [2, 7, 11, 15], target = 9,Because nums[0] + nums[1] = 2 + 7 = 9,return [0, 1]. Solution: 我的解决方案： 123456789101112131415161718class Solution &#123;public: vector&lt;int&gt; twoSum(vector&lt;int&gt;&amp; nums, int target) &#123; vector&lt;int&gt; index; for (int i = 0; i &lt; nums.size(); i++) &#123; for (int j = i; j &lt; nums.size(); j++) &#123; if (i != j &amp;&amp; (nums[i] + nums[j] == target)) &#123; index.push_back(i); index.push_back(j); &#125; &#125; &#125; return index; &#125;&#125;; 12Runtime: 384 ms, faster than 5.00% of C++ online submissions for Two Sum.Memory Usage: 9.4 MB, less than 90.00% of C++ online submissions for Two Sum. 算法比较蠢，单纯的遍历，长路漫漫，还要好好学。 Top Voted Solution： The basic idea is to maintain a hash table for each element num in nums, using num as key and its index (0-based) as value. For each num, search for target - num in the hash table. If it is found and is not the same element as num, then we are done. 12345678910111213class Solution &#123;public: vector&lt;int&gt; twoSum(vector&lt;int&gt;&amp; nums, int target) &#123; unordered_map&lt;int, int&gt; indices; for (int i = 0; i &lt; nums.size(); i++) &#123; if (indices.find(target - nums[i]) != indices.end()) &#123; return &#123;indices[target - nums[i]], i&#125;; &#125; indices[nums[i]] = i; &#125; return &#123;&#125;; &#125;&#125;;]]></content>
      <categories>
        <category>Leetcode</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[UnicodeDecodeError_ 'gbk' codec can't decode byte的解决办法]]></title>
    <url>%2F2019%2F03%2F27%2Fsolve-of-UnicodeDecodeError-%20'gbk'-codec-can't-decode-byte%2F</url>
    <content type="text"><![CDATA[这个《机器学习实战》朴素贝叶斯算法中遇到的问题。 #### 问题描述 UnicodeDecodeError: ‘gbk’ codec can’t decode byte 0xae in position 199: illegal multibyte sequence 解决方案 \email\ham中的23.txt中第二段多了一个®（使用记事本打开显示的是“？”），导致解码失败，删除‘®’之后便可以继续执行。 使用windows-1252编码的方式读取txt，open txt文档时加一条encoding=&#39;windows-1252&#39;，open(&#39;email/spam/%d.txt&#39; % i, encoding=&quot;windows-1252&quot;).read()。 问题分析UnicodeDecodeError解释为Unicode的解码（decode）出现错误了，也就当前正在处理某种编码类型的字符串，是想要将该字符串去解码，变成Unicode，但是在解码的过程中发生错误了。分别测试\email\ham\中的每一个txt文档，只有23.txt报错：123456789101112131415161718 ...: file = open('email\\ham\\23.txt') ...: fileRead = file.read() ...: wordList = bayes.textParse(fileRead) ...: docList.append(wordList) ...: fullText.extend(wordList) ...: classList.append(1) ...:---------------------------------------------------------------------------UnicodeDecodeError Traceback (most recent call last)&lt;ipython-input-33-598ed4b80c9a&gt; in &lt;module&gt;() 1 2 file = open('email\\ham\\23.txt')----&gt; 3 fileRead = file.read() 4 wordList = bayes.textParse(fileRead) 5 docList.append(wordList)UnicodeDecodeError: 'gbk' codec can't decode byte 0xae in position 199: illegalmultibyte sequence 23.txt第二段（记事本打开“®”显示为“？”）：SciFinance® is a derivatives pricing and risk model development tool that automatically generates C/C++ and GPU-enabled source code from concise, high-level model specifications. No parallel computing or CUDA programming expertise is required.使用gbk无法解码“®”，在sublime text中查看23.txt的编码方式为windows 1252，所以使用windows 1252的编码方式打开txt文档，程序便能够正常执行了。]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>DecodeError</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2019%2F03%2F26%2Fhello-world%2F</url>
    <content type="text"><![CDATA[​ 很早以前就觉得能搭建一个自己的博客是特别牛X的事情，终于在大神的慢慢影响下，逐渐去学习以前不扎实的东西，数学也好，算法也罢，起码每天前进一点。 ​ 终于学会用GitHub搭博客了，照着博客的流程玩了一小天，突然就觉得自己以前好蠢，保持更新。。。]]></content>
  </entry>
</search>
