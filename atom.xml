<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Junyuan&#39;s blog</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://www.junyuanw.com/"/>
  <updated>2020-08-09T11:08:27.696Z</updated>
  <id>http://www.junyuanw.com/</id>
  
  <author>
    <name>Junyuan Wang</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>A gentle guide to the Python features</title>
    <link href="http://www.junyuanw.com/2019/11/14/python-is-cool/"/>
    <id>http://www.junyuanw.com/2019/11/14/python-is-cool/</id>
    <published>2019-11-14T12:01:48.000Z</published>
    <updated>2020-08-09T11:08:27.696Z</updated>
    
    <content type="html"><![CDATA[<p>沈阳下雪了。</p> <a id="more"></a><p>原文地址：<a href="https://github.com/chiphuyen/python-is-cool" target="_blank" rel="noopener">github</a></p><h2 id="Lambda-map-filter-reduce"><a href="#Lambda-map-filter-reduce" class="headerlink" title="Lambda, map, filter, reduce"></a>Lambda, map, filter, reduce</h2><p>The lambda keyword is used to create inline functions. The functions<code>square_fn</code> and <code>square_ld</code> below are identical.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">square_fn</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> x * x</span><br><span class="line"></span><br><span class="line">square_ld = <span class="keyword">lambda</span> x: x * x</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">    <span class="keyword">assert</span> square_fn(i) == square_ld(i)</span><br></pre></td></tr></table></figure><p>Its quick declaration makes <code>lambda</code> functions ideal for use in callbacks, and when functions are to be passed as arguments to other functions. They are especially useful when used in conjunction with functions like <code>map</code>, <code>filter</code>, and <code>reduce</code>.</p><p><code>map(fn, iterable)</code> applies the <code>fn</code> to all elements of the <code>iterable</code> (e.g. list, set, dictionary, tuple, string) and returns a map object.</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">nums = [<span class="number">1</span>/<span class="number">3</span>, <span class="number">333</span>/<span class="number">7</span>, <span class="number">2323</span>/<span class="number">2230</span>, <span class="number">40</span>/<span class="number">34</span>, <span class="number">2</span>/<span class="number">3</span>]</span><br><span class="line">nums_squared = [num * num <span class="keyword">for</span> num <span class="keyword">in</span> nums]</span><br><span class="line">print(nums_squared)</span><br><span class="line"></span><br><span class="line">==&gt; [0.1111111, 2263.04081632, 1.085147, 1.384083, 0.44444444]</span><br></pre></td></tr></table></figure><p>This is the same as calling using <code>map</code> with a callback function.</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">nums_squared_1 = map(square_fn, nums)</span><br><span class="line">nums_squared_2 = map(<span class="keyword">lambda</span> x: x * x, nums)</span><br><span class="line">print(list(nums_squared_1))</span><br><span class="line"></span><br><span class="line">==&gt; [0.1111111, 2263.04081632, 1.085147, 1.384083, 0.44444444]</span><br></pre></td></tr></table></figure><p>You can also use <code>map</code> with more than one iterable. For example, if you want to calculate the mean squared error of a simple linear function <code>f(x) = ax + b</code> with the true label <code>labels</code>, these two methods are equivalent:</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">a, b = <span class="number">3</span>, <span class="number">-0.5</span></span><br><span class="line">xs = [<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>]</span><br><span class="line">labels = [<span class="number">6.4</span>, <span class="number">8.9</span>, <span class="number">10.9</span>, <span class="number">15.3</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Method 1: using a loop</span></span><br><span class="line">errors = []</span><br><span class="line"><span class="keyword">for</span> i, x <span class="keyword">in</span> enumerate(xs):</span><br><span class="line">    errors.append((a * x + b - labels[i]) ** <span class="number">2</span>)</span><br><span class="line">result1 = sum(errors) ** <span class="number">0.5</span> / len(xs)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Method 2: using map</span></span><br><span class="line">diffs = map(<span class="keyword">lambda</span> x, y: (a * x + b - y) ** <span class="number">2</span>, xs, labels)</span><br><span class="line">result2 = sum(diffs) ** <span class="number">0.5</span> / len(xs)</span><br><span class="line"></span><br><span class="line">print(result1, result2)</span><br><span class="line"></span><br><span class="line">==&gt; 0.35089172119045514 0.35089172119045514</span><br></pre></td></tr></table></figure><p>Note that objects returned by <code>map</code> and <code>filter</code> are iterators, which means that their values aren’t stored but generated as needed. After you’ve called <code>sum(diffs)</code>, <code>diffs</code> becomes empty. If you want to keep all elements in <code>diffs</code>, convert it to a list using <code>list(diffs)</code>.</p><p><code>filter(fn, iterable)</code> works the same way as <code>map</code>, except that <code>fn</code> returns a boolean value and <code>filter</code> returns all the elements of the <code>iterable</code> for which the <code>fn</code> returns True.</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">bad_preds = filter(<span class="keyword">lambda</span> x: x &gt; <span class="number">0.5</span>, errors)</span><br><span class="line">print(list(bad_preds))</span><br><span class="line"></span><br><span class="line">==&gt; [0.8100000000000006, 0.6400000000000011]</span><br></pre></td></tr></table></figure><p><code>reduce(fn, iterable, initializer)</code> is used when we want to iteratively apply an operator to all elements in a list. For example, if we want to calculate the product of all elements in a list:</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">product = <span class="number">1</span></span><br><span class="line"><span class="keyword">for</span> num <span class="keyword">in</span> nums:</span><br><span class="line">    product *= num</span><br><span class="line">print(product)</span><br><span class="line"></span><br><span class="line">==&gt; 12.95564683272412</span><br></pre></td></tr></table></figure><p>This is equivalent to:<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> functools <span class="keyword">import</span> reduce</span><br><span class="line">product = reduce(<span class="keyword">lambda</span> x, y: x * y, nums)</span><br><span class="line">print(product)</span><br><span class="line"></span><br><span class="line">==&gt; 12.95564683272412</span><br></pre></td></tr></table></figure></p><p><strong>Note on the performance of lambda functions</strong></p><p>Lambda functions are meant for one time use. Each time <code>lambda x: dosomething(x)</code> is called, the function has to be created, which hurts the performance if you call <code>lambda x: dosomething(x)</code> multiple times (e.g. when you pass it inside <code>reduce</code>).</p><p>When you assign a name to the lambda function as in <code>fn = lambda x: dosomething(x)</code>, its performance is slightly slower than the same function defined using <code>def</code>, but the difference is negligible. See <a href="https://stackoverflow.com/questions/26540885/lambda-is-slower-than-function-call-in-python-why" target="_blank" rel="noopener">here</a>.</p><p>Even though I find lambdas cool, I personally recommend using named functions when you can for the sake of clarity.</p><h2 id="List-manipulation"><a href="#List-manipulation" class="headerlink" title="List manipulation"></a>List manipulation</h2><p>Python lists are super cool.</p><h3 id="Unpacking"><a href="#Unpacking" class="headerlink" title="Unpacking"></a>Unpacking</h3><p>We can unpack a list by each element like this:<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">elems = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]</span><br><span class="line">a, b, c, d = elems</span><br><span class="line">print(a, b, c, d)</span><br><span class="line"></span><br><span class="line">==&gt; 1 2 3 4</span><br></pre></td></tr></table></figure></p><p>We can also unpack a list like this:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">a, *new_elems, d = elems</span><br><span class="line">print(a)</span><br><span class="line">print(new_elems)</span><br><span class="line">print(d)</span><br><span class="line"></span><br><span class="line">==&gt; 1</span><br><span class="line">    [<span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line">    <span class="number">4</span></span><br></pre></td></tr></table></figure><h3 id="Slicing"><a href="#Slicing" class="headerlink" title="Slicing"></a>Slicing</h3><p>We know that we can reverse a list using <code>[::-1]</code>.</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">elems = list(range(<span class="number">10</span>))</span><br><span class="line">print(elems)</span><br><span class="line"></span><br><span class="line">==&gt; [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]</span><br><span class="line"></span><br><span class="line">print(elems[::<span class="number">-1</span>])</span><br><span class="line"></span><br><span class="line">==&gt; [9, 8, 7, 6, 5, 4, 3, 2, 1, 0]</span><br></pre></td></tr></table></figure><p>The syntax <code>[x:y:z]</code> means \”take every <code>z</code>th element of a list from index <code>x</code> to index <code>y</code>\”. When <code>z</code> is negative, it indicates going backwards. When <code>x</code> isn’t specified, it defaults to the first element of the list in the direction you are traversing the list. When <code>y</code> isn’t specified, it defaults to the last element of the list. So if we want to take every 2th element of a list, we use <code>[::2]</code>.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">evens = elems[::<span class="number">2</span>]</span><br><span class="line">print(evens)</span><br><span class="line"></span><br><span class="line">reversed_evens = elems[<span class="number">-2</span>::<span class="number">-2</span>]</span><br><span class="line">print(reversed_evens)</span><br><span class="line"></span><br><span class="line">==&gt; [0, 2, 4, 6, 8]</span><br><span class="line">    [<span class="number">8</span>, <span class="number">6</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="number">0</span>]</span><br></pre></td></tr></table></figure><p>We can also use slicing to delete all the even numbers in the list.</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">del</span> elems[::<span class="number">2</span>]</span><br><span class="line">print(elems)</span><br><span class="line"></span><br><span class="line">==&gt; [1, 3, 5, 7, 9]</span><br></pre></td></tr></table></figure><h3 id="Insertion"><a href="#Insertion" class="headerlink" title="Insertion"></a>Insertion</h3><p>We can change the value of an element in a list to another value.</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">elems = list(range(<span class="number">10</span>))</span><br><span class="line">elems[<span class="number">1</span>] = <span class="number">10</span></span><br><span class="line">print(elems)</span><br><span class="line"></span><br><span class="line">==&gt; [0, 10, 2, 3, 4, 5, 6, 7, 8, 9]</span><br></pre></td></tr></table></figure><p>If we want to replace the element at an index with multiple elements, e.g. replace the value <code>1</code> with 3 values <code>20, 30, 40</code>:</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">elems = list(range(<span class="number">10</span>))</span><br><span class="line">elems[<span class="number">1</span>:<span class="number">2</span>] = [<span class="number">20</span>, <span class="number">30</span>, <span class="number">40</span>]</span><br><span class="line">print(elems)</span><br><span class="line"></span><br><span class="line">==&gt; [0, 20, 30, 40, 2, 3, 4, 5, 6, 7, 8, 9]</span><br></pre></td></tr></table></figure><p>If we want to insert 3 values <code>0.2, 0.3, 0.5</code> between element at index 0 and element at index 1:</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">elems = list(range(<span class="number">10</span>))</span><br><span class="line">elems[<span class="number">1</span>:<span class="number">1</span>] = [<span class="number">0.2</span>, <span class="number">0.3</span>, <span class="number">0.5</span>]</span><br><span class="line">print(elems)</span><br><span class="line"></span><br><span class="line">==&gt; [0, 0.2, 0.3, 0.5, 1, 2, 3, 4, 5, 6, 7, 8, 9]</span><br></pre></td></tr></table></figure><h3 id="Flattening"><a href="#Flattening" class="headerlink" title="Flattening"></a>Flattening</h3><p>We can flatten a list of lists using <code>sum</code>.</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">list_of_lists = [[<span class="number">1</span>], [<span class="number">2</span>, <span class="number">3</span>], [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]]</span><br><span class="line">sum(list_of_lists, [])</span><br><span class="line"></span><br><span class="line">==&gt; [1, 2, 3, 4, 5, 6]</span><br></pre></td></tr></table></figure><p>If we have nested lists, we can recursively flatten it. That’s another beauty of lambda functions — we can use it in the same line as its creation.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">nested_lists = [[<span class="number">1</span>, <span class="number">2</span>], [[<span class="number">3</span>, <span class="number">4</span>], [<span class="number">5</span>, <span class="number">6</span>], [[<span class="number">7</span>, <span class="number">8</span>], [<span class="number">9</span>, <span class="number">10</span>], [[<span class="number">11</span>, [<span class="number">12</span>, <span class="number">13</span>]]]]]]</span><br><span class="line">flatten = <span class="keyword">lambda</span> x: [y <span class="keyword">for</span> l <span class="keyword">in</span> x <span class="keyword">for</span> y <span class="keyword">in</span> flatten(l)] <span class="keyword">if</span> type(x) <span class="keyword">is</span> list <span class="keyword">else</span> [x]</span><br><span class="line">flatten(nested_lists)</span><br><span class="line"></span><br><span class="line"><span class="comment"># This line of code is from</span></span><br><span class="line"><span class="comment"># https://github.com/sahands/python-by-example/blob/master/python-by-example.rst#flattening-lists</span></span><br></pre></td></tr></table></figure><h3 id="List-vs-generator"><a href="#List-vs-generator" class="headerlink" title="List vs generator"></a>List vs generator</h3><p>To illustrate the difference between a list and a generator, let’s look at an example of creating n-grams out of a list of tokens.</p><p>One way to create n-grams is to use a sliding window.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">tokens = [<span class="string">'i'</span>, <span class="string">'want'</span>, <span class="string">'to'</span>, <span class="string">'go'</span>, <span class="string">'to'</span>, <span class="string">'school'</span>]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">ngrams</span><span class="params">(tokens, n)</span>:</span></span><br><span class="line">    length = len(tokens)</span><br><span class="line">    grams = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(length - n + <span class="number">1</span>):</span><br><span class="line">        grams.append(tokens[i:i+n])</span><br><span class="line">    <span class="keyword">return</span> grams</span><br><span class="line"></span><br><span class="line">print(ngrams(tokens, <span class="number">3</span>))</span><br><span class="line"></span><br><span class="line">==&gt; [['i', 'want', 'to'],</span><br><span class="line">     [<span class="string">'want'</span>, <span class="string">'to'</span>, <span class="string">'go'</span>],</span><br><span class="line">     [<span class="string">'to'</span>, <span class="string">'go'</span>, <span class="string">'to'</span>],</span><br><span class="line">     [<span class="string">'go'</span>, <span class="string">'to'</span>, <span class="string">'school'</span>]]</span><br></pre></td></tr></table></figure><p>In the above example, we have to store all the n-grams at the same time. If the text has m tokens, then the memory requirement is <code>O(nm)</code>, which can be problematic when m is large.</p><p>Instead of using a list to store all n-grams, we can use a generator that generates the next n-gram when it’s asked for. This is known as lazy evaluation. We can make the function <code>ngrams</code> returns a generator using the keyword <code>yield</code>. Then the memory requirement is <code>O(m+n)</code>.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">ngrams</span><span class="params">(tokens, n)</span>:</span></span><br><span class="line">    length = len(tokens)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(length - n + <span class="number">1</span>):</span><br><span class="line">        <span class="keyword">yield</span> tokens[i:i+n]</span><br><span class="line"></span><br><span class="line">ngrams_generator = ngrams(tokens, <span class="number">3</span>)</span><br><span class="line">print(ngrams_generator)</span><br><span class="line"></span><br><span class="line">==&gt; &lt;generator object ngrams at 0x1069b26d0&gt;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> ngram <span class="keyword">in</span> ngrams_generator:</span><br><span class="line">    print(ngram)</span><br><span class="line"></span><br><span class="line">==&gt; ['i', 'want', 'to']</span><br><span class="line">    [<span class="string">'want'</span>, <span class="string">'to'</span>, <span class="string">'go'</span>]</span><br><span class="line">    [<span class="string">'to'</span>, <span class="string">'go'</span>, <span class="string">'to'</span>]</span><br><span class="line">    [<span class="string">'go'</span>, <span class="string">'to'</span>, <span class="string">'school'</span>]</span><br></pre></td></tr></table></figure><p>Another way to generate n-grams is to use slices to create lists: <code>[0, 1, ..., -n]</code>, <code>[1, 2, ..., -n+1]</code>, …, <code>[n-1, n, ..., -1]</code>, and then <code>zip</code> them together.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">ngrams</span><span class="params">(tokens, n)</span>:</span></span><br><span class="line">    length = len(tokens)</span><br><span class="line">    slices = (tokens[i:length-n+i+<span class="number">1</span>] <span class="keyword">for</span> i <span class="keyword">in</span> range(n))</span><br><span class="line">    <span class="keyword">return</span> zip(*slices)</span><br><span class="line"></span><br><span class="line">ngrams_generator = ngrams(tokens, <span class="number">3</span>)</span><br><span class="line">print(ngrams_generator)</span><br><span class="line"></span><br><span class="line">==&gt; &lt;zip object at 0x1069a7dc8&gt; # zip objects are generators</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> ngram <span class="keyword">in</span> ngrams_generator:</span><br><span class="line">    print(ngram)</span><br><span class="line"></span><br><span class="line">==&gt; ('i', 'want', 'to')</span><br><span class="line">    (<span class="string">'want'</span>, <span class="string">'to'</span>, <span class="string">'go'</span>)</span><br><span class="line">    (<span class="string">'to'</span>, <span class="string">'go'</span>, <span class="string">'to'</span>)</span><br><span class="line">    (<span class="string">'go'</span>, <span class="string">'to'</span>, <span class="string">'school'</span>)</span><br></pre></td></tr></table></figure><p>Note that to create slices, we use <code>(tokens[...] for i in range(n))</code> instead of <code>[tokens[...] for i in range(n)]</code>. <code>[]</code> is the normal list comprehension that returns a list. <code>()</code> returns a generator.</p><h2 id="Classes-and-magic-methods"><a href="#Classes-and-magic-methods" class="headerlink" title="Classes and magic methods"></a>Classes and magic methods</h2><p>In Python, magic methods are prefixed and suffixed with the double underscore <code>__</code>, also known as dunder. The most wellknown magic method is probably <code>__init__</code>.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Node</span>:</span></span><br><span class="line">    <span class="string">""" A struct to denote the node of a binary tree.</span></span><br><span class="line"><span class="string">    It contains a value and pointers to left and right children.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, value, left=None, right=None)</span>:</span></span><br><span class="line">        self.value = value</span><br><span class="line">        self.left = left</span><br><span class="line">        self.right = right</span><br></pre></td></tr></table></figure><p>When we try to print out a Node object, however, it’s not very interpretable.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">root = Node(<span class="number">5</span>)</span><br><span class="line">print(root) <span class="comment"># &lt;__main__.Node object at 0x1069c4518&gt;</span></span><br></pre></td></tr></table></figure><p>Ideally, when user prints out a node, we want to print out the node’s value and the values of its children if it has children. To do so, we use the magic method <code>__repr__</code>, which must return a printable object, like string.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Node</span>:</span></span><br><span class="line">    <span class="string">""" A struct to denote the node of a binary tree.</span></span><br><span class="line"><span class="string">    It contains a value and pointers to left and right children.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, value, left=None, right=None)</span>:</span></span><br><span class="line">        self.value = value</span><br><span class="line">        self.left = left</span><br><span class="line">        self.right = right</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__repr__</span><span class="params">(self)</span>:</span></span><br><span class="line">        strings = [<span class="string">f'value: <span class="subst">&#123;self.value&#125;</span>'</span>]</span><br><span class="line">        strings.append(<span class="string">f'left: <span class="subst">&#123;self.left.value&#125;</span>'</span> <span class="keyword">if</span> self.left <span class="keyword">else</span> <span class="string">'left: None'</span>)</span><br><span class="line">        strings.append(<span class="string">f'right: <span class="subst">&#123;self.right.value&#125;</span>'</span> <span class="keyword">if</span> self.right <span class="keyword">else</span> <span class="string">'right: None'</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="string">', '</span>.join(strings)</span><br><span class="line"></span><br><span class="line">left = Node(<span class="number">4</span>)</span><br><span class="line">root = Node(<span class="number">5</span>, left)</span><br><span class="line">print(root) <span class="comment"># value: 5, left: 4, right: None</span></span><br></pre></td></tr></table></figure><p>We’d also like to compare two nodes by comparing their values. To do so, we overload the operator <code>==</code> with <code>__eq__</code>, <code>&lt;</code> with <code>__lt__</code>, and <code>&gt;=</code> with <code>__ge__</code>.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Node</span>:</span></span><br><span class="line">    <span class="string">""" A struct to denote the node of a binary tree.</span></span><br><span class="line"><span class="string">    It contains a value and pointers to left and right children.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, value, left=None, right=None)</span>:</span></span><br><span class="line">        self.value = value</span><br><span class="line">        self.left = left</span><br><span class="line">        self.right = right</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__eq__</span><span class="params">(self, other)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.value == other.value</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__lt__</span><span class="params">(self, other)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.value &lt; other.value</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__ge__</span><span class="params">(self, other)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.value &gt;= other.value</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">left = Node(<span class="number">4</span>)</span><br><span class="line">root = Node(<span class="number">5</span>, left)</span><br><span class="line">print(left == root) <span class="comment"># False</span></span><br><span class="line">print(left &lt; root) <span class="comment"># True</span></span><br><span class="line">print(left &gt;= root) <span class="comment"># False</span></span><br></pre></td></tr></table></figure><p>For a comprehensive list of supported magic methods <a href="https://www.tutorialsteacher.com/python/magic-methods-in-python" target="_blank" rel="noopener">here</a> or see the official Python documentation <a href="https://docs.python.org/3/reference/datamodel.html#special-method-names" target="_blank" rel="noopener">here</a> (slightly harder to read).</p><p>Some of the methods that I highly recommend:</p><ul><li><code>__len__</code>: to overload the <code>len()</code> function.</li><li><code>__str__</code>: to overload the <code>str()</code> function.</li><li><code>__iter__</code>: if you want to your objects to be iterators. This also allows you to call <code>next()</code> on your object.</li></ul><p>For classes like Node where we know for sure all the attributes they can support (in the case of Node, they are <code>value</code>, <code>left</code>, and <code>right</code>), we might want to use <code>__slots__</code> to denote those values for both performance boost and memory saving. For a comprehensive understanding of pros and cons of <code>__slots__</code>, see this <a href="https://stackoverflow.com/a/28059785/5029595" target="_blank" rel="noopener">absolutely amazing answer by Aaron Hall on StackOverflow</a>.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Node</span>:</span></span><br><span class="line">    <span class="string">""" A struct to denote the node of a binary tree.</span></span><br><span class="line"><span class="string">    It contains a value and pointers to left and right children.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    __slots__ = (<span class="string">'value'</span>, <span class="string">'left'</span>, <span class="string">'right'</span>)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, value, left=None, right=None)</span>:</span></span><br><span class="line">        self.value = value</span><br><span class="line">        self.left = left</span><br><span class="line">        self.right = right</span><br></pre></td></tr></table></figure><h2 id="local-namespace-object’s-attributes"><a href="#local-namespace-object’s-attributes" class="headerlink" title="local namespace, object’s attributes"></a>local namespace, object’s attributes</h2><p>The <code>locals()</code> function returns a dictionary containing the variables defined in the local namespace.</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Model1</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, hidden_size=<span class="number">100</span>, num_layers=<span class="number">3</span>, learning_rate=<span class="number">3e-4</span>)</span>:</span></span><br><span class="line">        print(locals())</span><br><span class="line">        self.hidden_size = hidden_size</span><br><span class="line">        self.num_layers = num_layers</span><br><span class="line">        self.learning_rate = learning_rate</span><br><span class="line"></span><br><span class="line">model1 = Model1()</span><br><span class="line"></span><br><span class="line">==&gt; &#123;'learning_rate': 0.0003, 'num_layers': 3, 'hidden_size': 100, 'self': &lt;__main__.Model1 object at 0x1069b1470&gt;&#125;</span><br></pre></td></tr></table></figure><p>All attributes of an object are stored in its <code>__dict__</code>.<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">print(model1.__dict__)</span><br><span class="line"></span><br><span class="line">==&gt; &#123;'hidden_size': 100, 'num_layers': 3, 'learning_rate': 0.0003&#125;</span><br></pre></td></tr></table></figure></p><p>Note that manually assigning each of the arguments to an attribute can be quite tiring when the list of the arguments is large. To avoid this, we can directly assign the list of arguments to the object’s <code>__dict__</code>.</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Model2</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, hidden_size=<span class="number">100</span>, num_layers=<span class="number">3</span>, learning_rate=<span class="number">3e-4</span>)</span>:</span></span><br><span class="line">        params = locals()</span><br><span class="line">        <span class="keyword">del</span> params[<span class="string">'self'</span>]</span><br><span class="line">        self.__dict__ = params</span><br><span class="line"></span><br><span class="line">model2 = Model2()</span><br><span class="line">print(model2.__dict__)</span><br><span class="line"></span><br><span class="line">==&gt; &#123;'learning_rate': 0.0003, 'num_layers': 3, 'hidden_size': 100&#125;</span><br></pre></td></tr></table></figure><p>This can be especially convenient when the object is initiated using the catch-all <code>**kwargs</code>, though the use of <code>**kwargs</code> should be reduced to the minimum.</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Model3</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, **kwargs)</span>:</span></span><br><span class="line">        self.__dict__ = kwargs</span><br><span class="line"></span><br><span class="line">model3 = Model3(hidden_size=<span class="number">100</span>, num_layers=<span class="number">3</span>, learning_rate=<span class="number">3e-4</span>)</span><br><span class="line">print(model3.__dict__)</span><br><span class="line"></span><br><span class="line">==&gt; &#123;'hidden_size': 100, 'num_layers': 3, 'learning_rate': 0.0003&#125;</span><br></pre></td></tr></table></figure><h2 id="Wild-import"><a href="#Wild-import" class="headerlink" title="Wild import"></a>Wild import</h2><p>Often, you run into this wild import <code>*</code> that looks something like this:</p><p><code>file.py</code><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> parts <span class="keyword">import</span> *</span><br></pre></td></tr></table></figure></p><p>This is irresponsible because it will import everything in module, even the imports of that module. For example, if <code>parts.py</code> looks like this:</p><p><code>parts.py</code><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy</span><br><span class="line"><span class="keyword">import</span> tensorflow</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Encoder</span>:</span></span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Decoder</span>:</span></span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Loss</span>:</span></span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">helper</span><span class="params">(*args, **kwargs)</span>:</span></span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">utils</span><span class="params">(*args, **kwargs)</span>:</span></span><br><span class="line">    ...</span><br></pre></td></tr></table></figure></p><p>Since <code>parts.py</code> doesn’t have <code>__all__</code> specified, <code>file.py</code> will import Encoder, Decoder, Loss, utils, helper together with numpy and tensorflow.</p><p>If we intend that only Encoder, Decoder, and Loss are ever to be imported and used in another module, we should specify that in <code>parts.py</code> using the <code>__all__</code> keyword.</p><p><code>parts.py</code><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"> __all__ = [<span class="string">'Encoder'</span>, <span class="string">'Decoder'</span>, <span class="string">'Loss'</span>]</span><br><span class="line"><span class="keyword">import</span> numpy</span><br><span class="line"><span class="keyword">import</span> tensorflow</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Encoder</span>:</span></span><br><span class="line">    ...</span><br></pre></td></tr></table></figure></p><p>Now, if some user irresponsibly does a wild import with <code>parts</code>, they can only import Encoder, Decoder, Loss. Personally, I also find <code>__all__</code> helpful as it gives me an overview of the module.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;沈阳下雪了。&lt;/p&gt;
    
    </summary>
    
      <category term="python" scheme="http://www.junyuanw.com/categories/python/"/>
    
    
      <category term="python" scheme="http://www.junyuanw.com/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>Tensorflow Faster RCNN修改训练的类别数量</title>
    <link href="http://www.junyuanw.com/2019/11/10/Faster_RCNN_change_categorise_in_train/"/>
    <id>http://www.junyuanw.com/2019/11/10/Faster_RCNN_change_categorise_in_train/</id>
    <published>2019-11-10T09:00:00.000Z</published>
    <updated>2020-08-09T11:08:27.656Z</updated>
    
    <content type="html"><![CDATA[<p>本文主要基于COCO数据集，需要某一类别或某几个类别的检测结果，所以针对特定的类别专门训练一个Faster RCNN的模型，后续可以针对特定的类别设置<code>ancher</code>和<code>scale</code>的大小以达到更好的效果。</p> <a id="more"></a><p>源码地址：<a href="https://github.com/endernewton/tf-faster-rcnn" target="_blank" rel="noopener">tf faster rcnn</a></p><h3 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h3><p>要修改的文件：<code>./tf-faster-rcnn/lib/datasets/coco.py</code></p><p><strong>第39行：</strong></p><p><code>cats = self._COCO.loadCats(self._COCO.getCatIds())</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">COCO.getCatIds?</span><br><span class="line">Signature: COCO.getCatIds(self, catNms=[], supNms=[], catIds=[])</span><br><span class="line">Docstring:</span><br><span class="line">filtering parameters. default skips that filter.</span><br><span class="line">:param catNms (str array)  : get cats <span class="keyword">for</span> given cat names</span><br><span class="line">:param supNms (str array)  : get cats <span class="keyword">for</span> given supercategory names</span><br><span class="line">:param catIds (int array)  : get cats <span class="keyword">for</span> given cat ids</span><br><span class="line">:<span class="keyword">return</span>: ids (int array)   : integer array of cat ids</span><br><span class="line">File:      d:\programs\anaconda3\envs\tensorflow1.x\lib\site-packages\pycocotools\coco.py</span><br><span class="line">Type:      function</span><br></pre></td></tr></table></figure><p>通过设置<code>getCatIds</code>的参数改变训练的类别，比如本例只训练一个检测<code>person</code>的模型，就改成<code>cats = self._COCO.loadCats(self._COCO.getCatIds(catIds=[1]))</code>，把需要训练的类别对应的<code>id</code>作为参数传入。</p><p>原始类别：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><span class="line">coco.loadCats(coco.getCatIds())</span><br><span class="line"></span><br><span class="line">[&#123;<span class="string">'supercategory'</span>: <span class="string">'person'</span>, <span class="string">'id'</span>: <span class="number">1</span>, <span class="string">'name'</span>: <span class="string">'person'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'supercategory'</span>: <span class="string">'vehicle'</span>, <span class="string">'id'</span>: <span class="number">2</span>, <span class="string">'name'</span>: <span class="string">'bicycle'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'supercategory'</span>: <span class="string">'vehicle'</span>, <span class="string">'id'</span>: <span class="number">3</span>, <span class="string">'name'</span>: <span class="string">'car'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'supercategory'</span>: <span class="string">'vehicle'</span>, <span class="string">'id'</span>: <span class="number">4</span>, <span class="string">'name'</span>: <span class="string">'motorcycle'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'supercategory'</span>: <span class="string">'vehicle'</span>, <span class="string">'id'</span>: <span class="number">5</span>, <span class="string">'name'</span>: <span class="string">'airplane'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'supercategory'</span>: <span class="string">'vehicle'</span>, <span class="string">'id'</span>: <span class="number">6</span>, <span class="string">'name'</span>: <span class="string">'bus'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'supercategory'</span>: <span class="string">'vehicle'</span>, <span class="string">'id'</span>: <span class="number">7</span>, <span class="string">'name'</span>: <span class="string">'train'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'supercategory'</span>: <span class="string">'vehicle'</span>, <span class="string">'id'</span>: <span class="number">8</span>, <span class="string">'name'</span>: <span class="string">'truck'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'supercategory'</span>: <span class="string">'vehicle'</span>, <span class="string">'id'</span>: <span class="number">9</span>, <span class="string">'name'</span>: <span class="string">'boat'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'supercategory'</span>: <span class="string">'outdoor'</span>, <span class="string">'id'</span>: <span class="number">10</span>, <span class="string">'name'</span>: <span class="string">'traffic light'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'supercategory'</span>: <span class="string">'outdoor'</span>, <span class="string">'id'</span>: <span class="number">11</span>, <span class="string">'name'</span>: <span class="string">'fire hydrant'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'supercategory'</span>: <span class="string">'outdoor'</span>, <span class="string">'id'</span>: <span class="number">13</span>, <span class="string">'name'</span>: <span class="string">'stop sign'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'supercategory'</span>: <span class="string">'outdoor'</span>, <span class="string">'id'</span>: <span class="number">14</span>, <span class="string">'name'</span>: <span class="string">'parking meter'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'supercategory'</span>: <span class="string">'outdoor'</span>, <span class="string">'id'</span>: <span class="number">15</span>, <span class="string">'name'</span>: <span class="string">'bench'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'supercategory'</span>: <span class="string">'animal'</span>, <span class="string">'id'</span>: <span class="number">16</span>, <span class="string">'name'</span>: <span class="string">'bird'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'supercategory'</span>: <span class="string">'animal'</span>, <span class="string">'id'</span>: <span class="number">17</span>, <span class="string">'name'</span>: <span class="string">'cat'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'supercategory'</span>: <span class="string">'animal'</span>, <span class="string">'id'</span>: <span class="number">18</span>, <span class="string">'name'</span>: <span class="string">'dog'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'supercategory'</span>: <span class="string">'animal'</span>, <span class="string">'id'</span>: <span class="number">19</span>, <span class="string">'name'</span>: <span class="string">'horse'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'supercategory'</span>: <span class="string">'animal'</span>, <span class="string">'id'</span>: <span class="number">20</span>, <span class="string">'name'</span>: <span class="string">'sheep'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'supercategory'</span>: <span class="string">'animal'</span>, <span class="string">'id'</span>: <span class="number">21</span>, <span class="string">'name'</span>: <span class="string">'cow'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'supercategory'</span>: <span class="string">'animal'</span>, <span class="string">'id'</span>: <span class="number">22</span>, <span class="string">'name'</span>: <span class="string">'elephant'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'supercategory'</span>: <span class="string">'animal'</span>, <span class="string">'id'</span>: <span class="number">23</span>, <span class="string">'name'</span>: <span class="string">'bear'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'supercategory'</span>: <span class="string">'animal'</span>, <span class="string">'id'</span>: <span class="number">24</span>, <span class="string">'name'</span>: <span class="string">'zebra'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'supercategory'</span>: <span class="string">'animal'</span>, <span class="string">'id'</span>: <span class="number">25</span>, <span class="string">'name'</span>: <span class="string">'giraffe'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'supercategory'</span>: <span class="string">'accessory'</span>, <span class="string">'id'</span>: <span class="number">27</span>, <span class="string">'name'</span>: <span class="string">'backpack'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'supercategory'</span>: <span class="string">'accessory'</span>, <span class="string">'id'</span>: <span class="number">28</span>, <span class="string">'name'</span>: <span class="string">'umbrella'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'supercategory'</span>: <span class="string">'accessory'</span>, <span class="string">'id'</span>: <span class="number">31</span>, <span class="string">'name'</span>: <span class="string">'handbag'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'supercategory'</span>: <span class="string">'accessory'</span>, <span class="string">'id'</span>: <span class="number">32</span>, <span class="string">'name'</span>: <span class="string">'tie'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'supercategory'</span>: <span class="string">'accessory'</span>, <span class="string">'id'</span>: <span class="number">33</span>, <span class="string">'name'</span>: <span class="string">'suitcase'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'supercategory'</span>: <span class="string">'sports'</span>, <span class="string">'id'</span>: <span class="number">34</span>, <span class="string">'name'</span>: <span class="string">'frisbee'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'supercategory'</span>: <span class="string">'sports'</span>, <span class="string">'id'</span>: <span class="number">35</span>, <span class="string">'name'</span>: <span class="string">'skis'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'supercategory'</span>: <span class="string">'sports'</span>, <span class="string">'id'</span>: <span class="number">36</span>, <span class="string">'name'</span>: <span class="string">'snowboard'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'supercategory'</span>: <span class="string">'sports'</span>, <span class="string">'id'</span>: <span class="number">37</span>, <span class="string">'name'</span>: <span class="string">'sports ball'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'supercategory'</span>: <span class="string">'sports'</span>, <span class="string">'id'</span>: <span class="number">38</span>, <span class="string">'name'</span>: <span class="string">'kite'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'supercategory'</span>: <span class="string">'sports'</span>, <span class="string">'id'</span>: <span class="number">39</span>, <span class="string">'name'</span>: <span class="string">'baseball bat'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'supercategory'</span>: <span class="string">'sports'</span>, <span class="string">'id'</span>: <span class="number">40</span>, <span class="string">'name'</span>: <span class="string">'baseball glove'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'supercategory'</span>: <span class="string">'sports'</span>, <span class="string">'id'</span>: <span class="number">41</span>, <span class="string">'name'</span>: <span class="string">'skateboard'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'supercategory'</span>: <span class="string">'sports'</span>, <span class="string">'id'</span>: <span class="number">42</span>, <span class="string">'name'</span>: <span class="string">'surfboard'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'supercategory'</span>: <span class="string">'sports'</span>, <span class="string">'id'</span>: <span class="number">43</span>, <span class="string">'name'</span>: <span class="string">'tennis racket'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'supercategory'</span>: <span class="string">'kitchen'</span>, <span class="string">'id'</span>: <span class="number">44</span>, <span class="string">'name'</span>: <span class="string">'bottle'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'supercategory'</span>: <span class="string">'kitchen'</span>, <span class="string">'id'</span>: <span class="number">46</span>, <span class="string">'name'</span>: <span class="string">'wine glass'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'supercategory'</span>: <span class="string">'kitchen'</span>, <span class="string">'id'</span>: <span class="number">47</span>, <span class="string">'name'</span>: <span class="string">'cup'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'supercategory'</span>: <span class="string">'kitchen'</span>, <span class="string">'id'</span>: <span class="number">48</span>, <span class="string">'name'</span>: <span class="string">'fork'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'supercategory'</span>: <span class="string">'kitchen'</span>, <span class="string">'id'</span>: <span class="number">49</span>, <span class="string">'name'</span>: <span class="string">'knife'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'supercategory'</span>: <span class="string">'kitchen'</span>, <span class="string">'id'</span>: <span class="number">50</span>, <span class="string">'name'</span>: <span class="string">'spoon'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'supercategory'</span>: <span class="string">'kitchen'</span>, <span class="string">'id'</span>: <span class="number">51</span>, <span class="string">'name'</span>: <span class="string">'bowl'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'supercategory'</span>: <span class="string">'food'</span>, <span class="string">'id'</span>: <span class="number">52</span>, <span class="string">'name'</span>: <span class="string">'banana'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'supercategory'</span>: <span class="string">'food'</span>, <span class="string">'id'</span>: <span class="number">53</span>, <span class="string">'name'</span>: <span class="string">'apple'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'supercategory'</span>: <span class="string">'food'</span>, <span class="string">'id'</span>: <span class="number">54</span>, <span class="string">'name'</span>: <span class="string">'sandwich'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'supercategory'</span>: <span class="string">'food'</span>, <span class="string">'id'</span>: <span class="number">55</span>, <span class="string">'name'</span>: <span class="string">'orange'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'supercategory'</span>: <span class="string">'food'</span>, <span class="string">'id'</span>: <span class="number">56</span>, <span class="string">'name'</span>: <span class="string">'broccoli'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'supercategory'</span>: <span class="string">'food'</span>, <span class="string">'id'</span>: <span class="number">57</span>, <span class="string">'name'</span>: <span class="string">'carrot'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'supercategory'</span>: <span class="string">'food'</span>, <span class="string">'id'</span>: <span class="number">58</span>, <span class="string">'name'</span>: <span class="string">'hot dog'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'supercategory'</span>: <span class="string">'food'</span>, <span class="string">'id'</span>: <span class="number">59</span>, <span class="string">'name'</span>: <span class="string">'pizza'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'supercategory'</span>: <span class="string">'food'</span>, <span class="string">'id'</span>: <span class="number">60</span>, <span class="string">'name'</span>: <span class="string">'donut'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'supercategory'</span>: <span class="string">'food'</span>, <span class="string">'id'</span>: <span class="number">61</span>, <span class="string">'name'</span>: <span class="string">'cake'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'supercategory'</span>: <span class="string">'furniture'</span>, <span class="string">'id'</span>: <span class="number">62</span>, <span class="string">'name'</span>: <span class="string">'chair'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'supercategory'</span>: <span class="string">'furniture'</span>, <span class="string">'id'</span>: <span class="number">63</span>, <span class="string">'name'</span>: <span class="string">'couch'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'supercategory'</span>: <span class="string">'furniture'</span>, <span class="string">'id'</span>: <span class="number">64</span>, <span class="string">'name'</span>: <span class="string">'potted plant'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'supercategory'</span>: <span class="string">'furniture'</span>, <span class="string">'id'</span>: <span class="number">65</span>, <span class="string">'name'</span>: <span class="string">'bed'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'supercategory'</span>: <span class="string">'furniture'</span>, <span class="string">'id'</span>: <span class="number">67</span>, <span class="string">'name'</span>: <span class="string">'dining table'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'supercategory'</span>: <span class="string">'furniture'</span>, <span class="string">'id'</span>: <span class="number">70</span>, <span class="string">'name'</span>: <span class="string">'toilet'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'supercategory'</span>: <span class="string">'electronic'</span>, <span class="string">'id'</span>: <span class="number">72</span>, <span class="string">'name'</span>: <span class="string">'tv'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'supercategory'</span>: <span class="string">'electronic'</span>, <span class="string">'id'</span>: <span class="number">73</span>, <span class="string">'name'</span>: <span class="string">'laptop'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'supercategory'</span>: <span class="string">'electronic'</span>, <span class="string">'id'</span>: <span class="number">74</span>, <span class="string">'name'</span>: <span class="string">'mouse'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'supercategory'</span>: <span class="string">'electronic'</span>, <span class="string">'id'</span>: <span class="number">75</span>, <span class="string">'name'</span>: <span class="string">'remote'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'supercategory'</span>: <span class="string">'electronic'</span>, <span class="string">'id'</span>: <span class="number">76</span>, <span class="string">'name'</span>: <span class="string">'keyboard'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'supercategory'</span>: <span class="string">'electronic'</span>, <span class="string">'id'</span>: <span class="number">77</span>, <span class="string">'name'</span>: <span class="string">'cell phone'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'supercategory'</span>: <span class="string">'appliance'</span>, <span class="string">'id'</span>: <span class="number">78</span>, <span class="string">'name'</span>: <span class="string">'microwave'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'supercategory'</span>: <span class="string">'appliance'</span>, <span class="string">'id'</span>: <span class="number">79</span>, <span class="string">'name'</span>: <span class="string">'oven'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'supercategory'</span>: <span class="string">'appliance'</span>, <span class="string">'id'</span>: <span class="number">80</span>, <span class="string">'name'</span>: <span class="string">'toaster'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'supercategory'</span>: <span class="string">'appliance'</span>, <span class="string">'id'</span>: <span class="number">81</span>, <span class="string">'name'</span>: <span class="string">'sink'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'supercategory'</span>: <span class="string">'appliance'</span>, <span class="string">'id'</span>: <span class="number">82</span>, <span class="string">'name'</span>: <span class="string">'refrigerator'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'supercategory'</span>: <span class="string">'indoor'</span>, <span class="string">'id'</span>: <span class="number">84</span>, <span class="string">'name'</span>: <span class="string">'book'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'supercategory'</span>: <span class="string">'indoor'</span>, <span class="string">'id'</span>: <span class="number">85</span>, <span class="string">'name'</span>: <span class="string">'clock'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'supercategory'</span>: <span class="string">'indoor'</span>, <span class="string">'id'</span>: <span class="number">86</span>, <span class="string">'name'</span>: <span class="string">'vase'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'supercategory'</span>: <span class="string">'indoor'</span>, <span class="string">'id'</span>: <span class="number">87</span>, <span class="string">'name'</span>: <span class="string">'scissors'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'supercategory'</span>: <span class="string">'indoor'</span>, <span class="string">'id'</span>: <span class="number">88</span>, <span class="string">'name'</span>: <span class="string">'teddy bear'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'supercategory'</span>: <span class="string">'indoor'</span>, <span class="string">'id'</span>: <span class="number">89</span>, <span class="string">'name'</span>: <span class="string">'hair drier'</span>&#125;,</span><br><span class="line"> &#123;<span class="string">'supercategory'</span>: <span class="string">'indoor'</span>, <span class="string">'id'</span>: <span class="number">90</span>, <span class="string">'name'</span>: <span class="string">'toothbrush'</span>&#125;]</span><br></pre></td></tr></table></figure><p>根据需要的类别的<code>id</code>设置输出参数，本例输出：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">coco.loadCats(coco.getCatIds(catIds=[<span class="number">1</span>]))</span><br><span class="line">[&#123;<span class="string">'supercategory'</span>: <span class="string">'person'</span>, <span class="string">'id'</span>: <span class="number">1</span>, <span class="string">'name'</span>: <span class="string">'person'</span>&#125;]</span><br></pre></td></tr></table></figure><p><strong>第42行：</strong></p><p><code>self._class_to_coco_cat_id = dict(list(zip([c[&#39;name&#39;] for c in cats],                                               self._COCO.getCatIds())))</code></p><p>修改为</p><p><code>self._class_to_coco_cat_id = dict(list(zip([c[&#39;name&#39;] for c in cats],                                               self._COCO.getCatIds(catId=[1]))))</code></p><p>同样加入训练的类别参数。</p><p><strong>第75行：</strong></p><p><code>image_ids = self._COCO.getImgIds()</code></p><p>修改为</p><p><code>image_ids = self._COCO.getImgIds(catIds=[1])</code></p><p>只获取和<code>person</code>有关的图片。感觉这里不是非必要的，因为后续获取<code>anno</code>的信息也会传入类别。</p><p><strong>第133行：</strong></p><p><code>annIds = self._COCO.getAnnIds(imgIds=index, iscrowd=None)</code></p><p>修改为</p><p><code>annIds = self._COCO.getAnnIds(imgIds=index, catIds=[1], iscrowd=None)</code></p><p>获取和<code>person</code>有关的标注信息，用于生成<code>roidb</code>训练<code>RPN</code>网络。</p><p>改完这四处就可以跑训练了。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">iter: 27300 / 490000, total loss: 0.481602</span><br><span class="line"> &gt;&gt;&gt; rpn_loss_cls: 0.035242</span><br><span class="line"> &gt;&gt;&gt; rpn_loss_box: 0.018606</span><br><span class="line"> &gt;&gt;&gt; loss_cls: 0.139855</span><br><span class="line"> &gt;&gt;&gt; loss_box: 0.159181</span><br><span class="line"> &gt;&gt;&gt; lr: 0.001000</span><br><span class="line">speed: 0.645s / iter</span><br><span class="line">iter: 27320 / 490000, total loss: 0.867995</span><br><span class="line"> &gt;&gt;&gt; rpn_loss_cls: 0.085730</span><br><span class="line"> &gt;&gt;&gt; rpn_loss_box: 0.067610</span><br><span class="line"> &gt;&gt;&gt; loss_cls: 0.204145</span><br><span class="line"> &gt;&gt;&gt; loss_box: 0.381795</span><br><span class="line"> &gt;&gt;&gt; lr: 0.001000</span><br><span class="line">speed: 0.645s / iter</span><br></pre></td></tr></table></figure><p><strong>Note：</strong></p><p>我是用<code>COCO2017</code>训练的，如果要用<code>COCO</code>2017，还需要改几处。</p><ul><li>factory.py中加入COCO2017信息</li><li>修改coco.py中image_path_from_index函数获取的图片路径，<code>COCO2017</code>图片直接就是<code>id</code>，没有别的字符。</li></ul><p>删除以前生成的文件和模型。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rm -rf output</span><br><span class="line">rm data/cache/*.pkl</span><br></pre></td></tr></table></figure><h3 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h3><p>修改demo文件，<code>./tf-faster-rcnn/tools/demo.py</code></p><p><strong>第33行：</strong></p><p><code>CLASS</code>修改为自己训练设置的类别，比如我的</p><p><code>CLASSES = (&#39;__background__&#39;, &#39;person&#39;)</code></p><p><strong>第40行：</strong></p><p><code>NET</code>中模型名改成自己的。</p><p><strong>可能遇到的问题：</strong></p><p><code>tensorflow.python.framework.errors_impl.InvalidArgumentError: Assign requires shapes of both tensors to match. lhs shape= [x] rhs shape= [y]</code></p><p><strong>第141行：</strong></p><ol><li><p><code>net.create_architecture(&quot;TEST&quot;, 21, tag=&#39;default&#39;, anchor_scales=[8, 16, 32])</code>，将21改成自己类别的数量，本例<code>__background__</code>和<code>person</code>两个类别，就改成2。</p></li><li><p><code>anchor</code>和<code>scale</code>设置引起的维度不匹配错误，训练和测试的<code>anchor</code>和<code>scale</code>要对应。</p></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文主要基于COCO数据集，需要某一类别或某几个类别的检测结果，所以针对特定的类别专门训练一个Faster RCNN的模型，后续可以针对特定的类别设置&lt;code&gt;ancher&lt;/code&gt;和&lt;code&gt;scale&lt;/code&gt;的大小以达到更好的效果。&lt;/p&gt;
    
    </summary>
    
      <category term="深度学习" scheme="http://www.junyuanw.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="python" scheme="http://www.junyuanw.com/tags/python/"/>
    
      <category term="深度学习" scheme="http://www.junyuanw.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="tensorflow" scheme="http://www.junyuanw.com/tags/tensorflow/"/>
    
      <category term="Faster RCNN" scheme="http://www.junyuanw.com/tags/Faster-RCNN/"/>
    
  </entry>
  
  <entry>
    <title>Leetcode-Median of Two Sorted Arrays</title>
    <link href="http://www.junyuanw.com/2019/11/07/Leetcode004-Median%20of%20Two%20Sorted%20Arrays/"/>
    <id>http://www.junyuanw.com/2019/11/07/Leetcode004-Median of Two Sorted Arrays/</id>
    <published>2019-11-07T12:00:00.000Z</published>
    <updated>2020-08-09T11:08:27.660Z</updated>
    
    <content type="html"><![CDATA[<p>数据分布都不明显，让机器怎么学。</p><a id="more"></a><h3 id="Problem"><a href="#Problem" class="headerlink" title="Problem"></a>Problem</h3><p>Merge two sorted linked lists and return it as a new list. The new list should be made by splicing together the nodes of the first two lists.</p><p><strong>Example:</strong></p><p>There are two sorted arrays <strong>nums1</strong> and <strong>nums2</strong> of size m and n respectively.</p><p>Find the median of the two sorted arrays. The overall run time complexity should be O(log (m+n)).</p><p>You may assume <strong>nums1</strong> and <strong>nums2</strong> cannot be both empty.</p><p><strong>Example 1:</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">nums1 = [1, 3]</span><br><span class="line">nums2 = [2]</span><br><span class="line"></span><br><span class="line">The median is 2.0</span><br></pre></td></tr></table></figure><p><strong>Example 2:</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">nums1 = [1, 2]</span><br><span class="line">nums2 = [3, 4]</span><br><span class="line"></span><br><span class="line">The median is (2 + 3)/2 = 2.5</span><br></pre></td></tr></table></figure><h3 id="Process"><a href="#Process" class="headerlink" title="Process"></a>Process</h3><ul><li>合并两个有序的数组</li><li>找到数组的中位数</li></ul><p><strong>std::meger</strong></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="class"><span class="keyword">class</span> <span class="title">InputIterator1</span>, <span class="title">class</span> <span class="title">InputIterator2</span>, <span class="title">class</span> <span class="title">OutputIterator</span>&gt;</span></span><br><span class="line"><span class="class">  <span class="title">OutputIterator</span> <span class="title">merge</span> (<span class="title">InputIterator1</span> <span class="title">first1</span>, <span class="title">InputIterator1</span> <span class="title">last1</span>,</span></span><br><span class="line"><span class="class">                        <span class="title">InputIterator2</span> <span class="title">first2</span>, <span class="title">InputIterator2</span> <span class="title">last2</span>,</span></span><br><span class="line"><span class="class">                        <span class="title">OutputIterator</span> <span class="title">result</span>)</span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">  <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">    <span class="keyword">if</span> (first1==last1) <span class="keyword">return</span> <span class="built_in">std</span>::copy(first2,last2,result);</span><br><span class="line">    <span class="keyword">if</span> (first2==last2) <span class="keyword">return</span> <span class="built_in">std</span>::copy(first1,last1,result);</span><br><span class="line">    *result++ = (*first2&lt;*first1)? *first2++ : *first1++;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>Parameters</strong></p><ul><li><p>first1, last1</p><p><a href="http://www.cplusplus.com/InputIterator" target="_blank" rel="noopener">Input iterators</a> to the initial and final positions of the first sorted sequence. The range used is <code>[first1,last1)</code>, which contains all the elements between first1 and last1, including the element pointed by first1 but not the element pointed by last1.</p></li><li><p>first2, last2</p><p><a href="http://www.cplusplus.com/InputIterator" target="_blank" rel="noopener">Input iterators</a> to the initial and final positions of the second sorted sequence. The range used is <code>[first2,last2)</code>.</p></li><li><p>result</p><p><a href="http://www.cplusplus.com/OutputIterator" target="_blank" rel="noopener">Output iterator</a> to the initial position of the range where the resulting combined range is stored. Its size is equal to the sum of both ranges above.</p></li><li><p>comp</p><p>Binary function that accepts two arguments of the types pointed by the iterators, and returns a value convertible to <code>bool</code>. The value returned indicates whether the first argument is considered to go before the second in the specific <em>strict weak ordering</em> it defines. </p><p>The function shall not modify any of its arguments. </p><p>This can either be a function pointer or a function object. </p><p><strong>Return value</strong></p><p>An iterator pointing to the <em>past-the-end</em> element in the resulting sequence.</p></li></ul><h3 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">double</span> <span class="title">findMedianSortedArrays</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums1, <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums2)</span> </span>&#123;</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; merged;</span><br><span class="line">        <span class="keyword">double</span> median;</span><br><span class="line">        merge(nums1.begin(), nums1.end(),</span><br><span class="line">              nums2.begin(), nums2.end(),</span><br><span class="line">              back_inserter(merged));</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (merged.size() % <span class="number">2</span> == <span class="number">0</span>) &#123;</span><br><span class="line">            median = (<span class="keyword">double</span>)(merged[merged.size() / <span class="number">2</span> - <span class="number">1</span>] + merged[merged.size() / <span class="number">2</span>]) / <span class="number">2</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> &#123;</span><br><span class="line">            median = merged[(merged.size() - <span class="number">1</span>) / <span class="number">2</span>];</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> median;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="Result"><a href="#Result" class="headerlink" title="Result"></a>Result</h3><div class="table-container"><table><thead><tr><th style="text-align:left">Time Submitted</th><th style="text-align:left">Status</th><th style="text-align:left">Runtime</th><th style="text-align:left">Memory</th><th style="text-align:left">Language</th></tr></thead><tbody><tr><td style="text-align:left">a few seconds ago</td><td style="text-align:left"><a href="https://leetcode.com/submissions/detail/276758080/" target="_blank" rel="noopener">Accepted</a></td><td style="text-align:left">24 ms</td><td style="text-align:left">10.5 MB</td><td style="text-align:left">cpp</td></tr></tbody></table></div><h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><p>TODO：Solution的解法如何实现。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;数据分布都不明显，让机器怎么学。&lt;/p&gt;
    
    </summary>
    
      <category term="Leetcode" scheme="http://www.junyuanw.com/categories/Leetcode/"/>
    
    
      <category term="C++" scheme="http://www.junyuanw.com/tags/C/"/>
    
      <category term="algorithm" scheme="http://www.junyuanw.com/tags/algorithm/"/>
    
  </entry>
  
  <entry>
    <title>python中super的使用</title>
    <link href="http://www.junyuanw.com/2019/10/29/Use-of-super-in-python/"/>
    <id>http://www.junyuanw.com/2019/10/29/Use-of-super-in-python/</id>
    <published>2019-10-29T11:19:59.000Z</published>
    <updated>2020-08-09T11:08:27.687Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>等终等于等明等白</p></blockquote><a id="more"></a><h3 id="调用父类的初始化方法"><a href="#调用父类的初始化方法" class="headerlink" title="调用父类的初始化方法"></a>调用父类的初始化方法</h3><p>继承父类后，直接调用父类的初始化方法。</p><p>定义一个人的类<code>Person</code>，包含人的名字和年龄，学生类<code>Student</code>继承自<code>Person</code>，多了一个分数变量：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Person</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, name, age)</span>:</span></span><br><span class="line">        self.name = name</span><br><span class="line">        self.age = age</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">info</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(<span class="string">"Person\'s name is &#123;&#125;, person\'s age is &#123;&#125;"</span>.format(self.name, self.age))</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Student</span><span class="params">(Person)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, name, age, score)</span>:</span></span><br><span class="line">        super().__init__(name, age)</span><br><span class="line">        self.score = score</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">info</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(<span class="string">"Student\'s name is &#123;&#125;, age is &#123;&#125;, score is &#123;&#125;"</span>.format(self.name, self.age, self.score))</span><br><span class="line">        </span><br><span class="line">p1 = Person(<span class="string">"Zhangsan"</span>, <span class="number">20</span>)</span><br><span class="line">p1.info()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>Person<span class="string">'s name is zhangsan, person'</span>s age <span class="keyword">is</span> <span class="number">20</span></span><br><span class="line">s1 = Student(<span class="string">"Lisi"</span>, <span class="number">18</span>, <span class="number">100</span>)</span><br><span class="line">s1.info()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>Student<span class="string">'s name is Lisi, age is 18, score is 100</span></span><br></pre></td></tr></table></figure><h3 id="同时实现父类功能"><a href="#同时实现父类功能" class="headerlink" title="同时实现父类功能"></a>同时实现父类功能</h3><p>如上一个示例，在<code>Student</code>类中重定义<code>info</code>方法直接就覆盖了父类<code>Person</code>中的<code>info</code>方法，如果需要同时实现父类的功能，就用<code>super</code>调用父类中的方法。只需要在<code>Student</code>中简单的修改下就可以：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Student</span><span class="params">(Person)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, name, age, score)</span>:</span></span><br><span class="line">        super().__init__(name, age)</span><br><span class="line">        self.score = score</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">info</span><span class="params">(self)</span>:</span></span><br><span class="line">        super().info()</span><br><span class="line">        print(<span class="string">"Student\'s score is &#123;&#125;"</span>.format(self.score))</span><br><span class="line">        </span><br><span class="line">s1 = Student(<span class="string">"Lisi"</span>, <span class="number">18</span>, <span class="number">100</span>)</span><br><span class="line">s1.info()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>Person<span class="string">'s name is Lisi, person'</span>s age <span class="keyword">is</span> <span class="number">18</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>Student<span class="string">'s score is 100</span></span><br></pre></td></tr></table></figure><p>使用<code>super</code>避免了直接用父类的名去调用，方便修改。 在上面的情况下，super 获得的类刚好是父类，但在其他情况就不一定了，<strong>super 其实和父类没有实质性的关联</strong>。 </p><h3 id="多重继承"><a href="#多重继承" class="headerlink" title="多重继承"></a>多重继承</h3><p> 上面说到的例子是单继承，用<code>父类名.属性</code>的方法调用出来代码维护时繁琐一点也并无不可，但多重继承时，还用这种方法来调用父类属性就会就会带来许多问题。假如有以下4个类，箭头指向父类，要在各子类方法中显示调用父类：</p><p><img src="/2019/10/29/Use-of-super-in-python/Inheritance-relationship.png" alt="Inheritance-relationship"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Base</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fun</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(<span class="string">"enter Base"</span>)</span><br><span class="line">        print(<span class="string">"leave Base"</span>)</span><br><span class="line">        </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">A</span><span class="params">(Base)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fun</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(<span class="string">"enter A"</span>)</span><br><span class="line">        Base.fun(self)</span><br><span class="line">        print(<span class="string">"leave A"</span>)</span><br><span class="line">        </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">B</span><span class="params">(Base)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fun</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(<span class="string">"enter B"</span>)</span><br><span class="line">        Base.fun(self)</span><br><span class="line">        print(<span class="string">"leave B"</span>)</span><br><span class="line">        </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">C</span><span class="params">(A, B)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fun</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(<span class="string">"enter C"</span>)</span><br><span class="line">        A.fun(self)</span><br><span class="line">        B.fun(self)</span><br><span class="line">        print(<span class="string">"leave C"</span>)</span><br><span class="line">        </span><br><span class="line">c = C()</span><br><span class="line">c.fun()</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>enter C</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>enter A</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>enter Base</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>leave Base</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>leave A</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>enter B</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>enter Base</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>leave Base</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>leave B</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>leave C</span><br></pre></td></tr></table></figure><p><code>Base</code>类被实例化了两次，发生菱形继承，出现调用不明确问题，并且会造成数据冗余的问题 。</p><h4 id="MRO列表"><a href="#MRO列表" class="headerlink" title="MRO列表"></a>MRO列表</h4><p> 对于定义的每一个类，Python 会计算出一个<strong>方法解析顺序（Method Resolution Order, MRO）列表</strong>，<strong>它代表了类继承的顺序</strong>，类<code>C</code>的MRO表：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">C.mro()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>[__main__.C, __main__.A, __main__.B, __main__.Base, object]</span><br></pre></td></tr></table></figure><p>  MRO 列表通过<code>C3线性化算法</code>来实现的，一个类的 MRO 列表就是合并所有父类的 MRO 列表，并遵循以下三条原则：</p><ul><li>子类永远在父类前面</li><li>如果有多个父类，会根据它们在列表中的顺序被检查。</li><li>如果对下一个类存在两个合法的选择，选择第一个父类。</li></ul><p>当用super调用父类的方法时，会按照mro表中的元素顺序去挨个查找方法。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Base</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fun</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(<span class="string">"enter Base"</span>)</span><br><span class="line">        print(<span class="string">"leave Base"</span>)</span><br><span class="line">        </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">A</span><span class="params">(Base)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fun</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(<span class="string">"enter A"</span>)</span><br><span class="line">        super().fun()</span><br><span class="line">        print(<span class="string">"leave A"</span>)</span><br><span class="line">        </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">B</span><span class="params">(Base)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fun</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(<span class="string">"enter B"</span>)</span><br><span class="line">        super().fun()</span><br><span class="line">        print(<span class="string">"leave B"</span>)</span><br><span class="line">        </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">C</span><span class="params">(A, B)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fun</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(<span class="string">"enter C"</span>)</span><br><span class="line">        super().fun()</span><br><span class="line">        print(<span class="string">"leave C"</span>)</span><br><span class="line">        </span><br><span class="line">c = C()</span><br><span class="line">c.fun()</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>enter C</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>enter A</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>enter B</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>enter Base</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>leave Base</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>leave B</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>leave A</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>leave C</span><br></pre></td></tr></table></figure><p>为什么继承顺序是 $A \rightarrow B \rightarrow Base$ ?</p><h4 id="super原理"><a href="#super原理" class="headerlink" title="super原理"></a>super原理</h4><p>super的工作原理如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">super</span><span class="params">(cls, inst)</span>:</span></span><br><span class="line">    mro = inst.__class__.mro()</span><br><span class="line">    <span class="keyword">return</span> mro[mro.index(cls) + <span class="number">1</span>]</span><br></pre></td></tr></table></figure><p>其中，<code>cls</code>代表类，<code>inst</code>代表实例，上面的代码做了两件事：</p><ul><li>获取<code>inst</code>的MRO列表</li><li>查找<code>cls</code>在当前MRO列表中的index, 并返回它的下一个类，即<code>mro[index + 1]</code></li></ul><p>当你使用 <code>super(cls, inst)</code> 时，Python 会在<code>inst</code>的 MRO 列表上搜索<code>cls</code>的下一个类。</p><p>所以根据MRO表，类<code>C</code>的下一个类是<code>A</code>，以此类推，得到 $A \rightarrow B \rightarrow Base$ 的继承顺序。</p><h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><ol><li><p><a href="https://www.cnblogs.com/silencestorm/p/8404046.html" target="_blank" rel="noopener">python 中 super函数的使用</a></p></li><li><p><a href="https://blog.csdn.net/dxk_093812/article/details/87553937" target="_blank" rel="noopener">Python中super的用法</a></p></li><li><a href="https://www.cnblogs.com/lsh123/p/7912623.html" target="_blank" rel="noopener">菱形继承问题和虚继承</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;等终等于等明等白&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="python" scheme="http://www.junyuanw.com/categories/python/"/>
    
    
      <category term="python" scheme="http://www.junyuanw.com/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>Tensorflow compute_gradirnts和apply_gradients原理浅析</title>
    <link href="http://www.junyuanw.com/2019/10/29/Tensorflow-compute-gradirnts-and-apply-gradients/"/>
    <id>http://www.junyuanw.com/2019/10/29/Tensorflow-compute-gradirnts-and-apply-gradients/</id>
    <published>2019-10-29T03:03:37.000Z</published>
    <updated>2020-08-09T11:08:27.666Z</updated>
    
    <content type="html"><![CDATA[<p>转自<a href="https://www.cnblogs.com/marsggbo/p/10056057.html" target="_blank" rel="noopener">TensorFlow学习笔记之—[compute_gradients和apply_gradients原理浅析]</a></p><a id="more"></a><p>最近在看fatser rcnn的源码，发现优化梯度的时候不是直接用的<code>Optimizer.minimize()</code>，而是先计算梯度<code>Optimizer.compute_gradients()</code>，然后<code>Optimizer.apply_gradients()</code>。</p><h3 id="optimizer-minimizer-loss-var-list"><a href="#optimizer-minimizer-loss-var-list" class="headerlink" title="optimizer.minimizer(loss, var_list)"></a>optimizer.minimizer(loss, var_list)</h3><p> 我们都知道，TensorFlow为我们提供了丰富的优化函数，例如GradientDescentOptimizer。这个方法会自动根据loss计算对应variable的导数。示例如下： </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">loss = ...</span><br><span class="line">opt = tf.tf.train.GradientDescentOptimizer(learning_rate=<span class="number">0.1</span>)</span><br><span class="line">train_op = opt.minimize(loss)</span><br><span class="line">init = tf.initialize_all_variables()</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Seesion() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(init)</span><br><span class="line">    <span class="keyword">for</span> step <span class="keyword">in</span> range(<span class="number">10</span>):  </span><br><span class="line">      session.run(train_op)</span><br></pre></td></tr></table></figure><p> 首先我们看一下<code>minimize()</code>的源代码(为方便说明，部分参数已删除): </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">minimize</span><span class="params">(self, loss, global_step=None, var_list=None, name=None)</span>:</span></span><br><span class="line"></span><br><span class="line">    grads_and_vars = self.compute_gradients(loss, var_list=var_list)</span><br><span class="line"></span><br><span class="line">    vars_with_grad = [v <span class="keyword">for</span> g, v <span class="keyword">in</span> grads_and_vars <span class="keyword">if</span> g <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>]</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> vars_with_grad:</span><br><span class="line">      <span class="keyword">raise</span> ValueError(</span><br><span class="line">          <span class="string">"No gradients provided for any variable, check your graph for ops"</span></span><br><span class="line">          <span class="string">" that do not support gradients, between variables %s and loss %s."</span> %</span><br><span class="line">          ([str(v) <span class="keyword">for</span> _, v <span class="keyword">in</span> grads_and_vars], loss))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> self.apply_gradients(grads_and_vars, global_step=global_step,</span><br><span class="line">                                name=name)</span><br></pre></td></tr></table></figure><p> 由源代码可以知道<code>minimize()</code>实际上包含了两个步骤，即<code>compute_gradients</code>和<code>apply_gradients</code>，前者用于计算梯度，后者用于使用计算得到的梯度来更新对应的variable。下面对这两个函数做具体介绍。 </p><h3 id="compute-gradients-loss-val-list"><a href="#compute-gradients-loss-val-list" class="headerlink" title="compute_gradients(loss, val_list)"></a>compute_gradients(loss, val_list)</h3><p>参数含义:</p><ul><li><strong>loss</strong>: 需要被优化的Tensor</li><li><strong>val_list</strong>: Optional list or tuple of <code>tf.Variable</code> to update to minimize <code>loss</code>. Defaults to the list of variables collected in the graph under the key <code>GraphKeys.TRAINABLE_VARIABLES</code>.</li></ul><p>简单说该函数就是用于计算loss对于指定val_list的导数的，最终返回的是元组列表，即[(gradient, variable),…]。</p><p>看下面的示例:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">x = tf.Variable(initial_value=<span class="number">50.</span>, dtype=<span class="string">'float32'</span>)</span><br><span class="line">w = tf.Variable(initial_value=<span class="number">10.</span>, dtype=<span class="string">'float32'</span>)</span><br><span class="line">y = w*x</span><br><span class="line"></span><br><span class="line">opt = tf.train.GradientDescentOptimizer(<span class="number">0.1</span>)</span><br><span class="line">grad = opt.compute_gradients(y, [w,x])</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line">    print(sess.run(grad))</span><br></pre></td></tr></table></figure><p> 返回值如下: </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>[(<span class="number">50.0</span>, <span class="number">10.0</span>), (<span class="number">10.0</span>, <span class="number">50.0</span>)]</span><br></pre></td></tr></table></figure><p>可以看到返回了一个list，list中的元素是元组。第一个元组第一个元素是50，表示∂y∂w∂y∂w的计算结果，第二个元素表示ww。第二个元组同理不做赘述。</p><p>其中<code>tf.gradients(loss, tf.variables)</code>的作用和这个函数类似,但是它只会返回计算得到的梯度，而不会返回对应的variable。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Graph().as_default():</span><br><span class="line">    x = tf.Variable(initial_value=<span class="number">3.</span>, dtype=<span class="string">'float32'</span>)</span><br><span class="line">    w = tf.Variable(initial_value=<span class="number">4.</span>, dtype=<span class="string">'float32'</span>)</span><br><span class="line">    y = w*x</span><br><span class="line"></span><br><span class="line">    grads = tf.gradients(y, [w])</span><br><span class="line">    print(grads)</span><br><span class="line">    </span><br><span class="line">    opt = tf.train.GradientDescentOptimizer(<span class="number">0.1</span>)</span><br><span class="line">    grads_vals = opt.compute_gradients(y, [w])</span><br><span class="line">    print(grad_vals)</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line">[&lt;tf.Tensor <span class="string">'gradients/mul_grad/Mul:0'</span> shape=() dtype=float32&gt;]</span><br><span class="line">[(&lt;tf.Tensor <span class="string">'gradients_1/mul_grad/tuple/control_dependency:0'</span> shape=() dtype=float32&gt;, &lt;tf.Variable <span class="string">'Variable_1:0'</span> shape=() dtype=float32_ref&gt;)]</span><br></pre></td></tr></table></figure><h3 id="apply-gradients-grads-and-vars-global-tep-None-name-None"><a href="#apply-gradients-grads-and-vars-global-tep-None-name-None" class="headerlink" title="apply_gradients(grads_and_vars,global_tep=None,name=None)"></a>apply_gradients(grads_and_vars,global_tep=None,name=None)</h3><p>该函数的作用是将<code>compute_gradients()</code>返回的值作为输入参数对variable进行更新。</p><p>那为什么<code>minimize()</code>会分开两个步骤呢？原因是因为在某些情况下我们需要对梯度做一定的修正，例如为了防止梯度消失(gradient vanishing)或者梯度爆炸(gradient explosion)，我们需要事先干预一下以免程序出现<strong>Nan</strong>的尴尬情况；有的时候也许我们需要给计算得到的梯度乘以一个权重或者其他乱七八糟的原因，所以才分开了两个步骤。</p><h3 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h3><p> 下面给出一个使用<code>tf.clip_by_norm</code>来修正梯度的例子: </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Graph().as_default():</span><br><span class="line">    x = tf.Variable(initial_value=<span class="number">3.</span>, dtype=<span class="string">'float32'</span>)</span><br><span class="line">    w = tf.Variable(initial_value=<span class="number">4.</span>, dtype=<span class="string">'float32'</span>)</span><br><span class="line">    y = w*x</span><br><span class="line">    </span><br><span class="line">    opt = tf.train.GradientDescentOptimizer(<span class="number">0.1</span>)</span><br><span class="line">    grads_vals = opt.compute_gradients(y, [w])</span><br><span class="line">    <span class="keyword">for</span> i, (g, v) <span class="keyword">in</span> enumerate(grads_vals):</span><br><span class="line">        <span class="keyword">if</span> g <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            grads_vals[i] = (tf.clip_by_norm(g, <span class="number">5</span>), v)  <span class="comment"># clip gradients</span></span><br><span class="line">    train_op = opt.apply_gradients(grads_vals)</span><br><span class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">        sess.run(tf.global_variables_initializer())</span><br><span class="line">        print(sess.run(grads_vals))</span><br><span class="line">        print(sess.run([x,w,y]))</span><br><span class="line">        </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>    </span><br><span class="line">[(<span class="number">3.0</span>, <span class="number">4.0</span>)]</span><br><span class="line">[<span class="number">3.0</span>, <span class="number">4.0</span>, <span class="number">12.0</span>]</span><br></pre></td></tr></table></figure><h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><ol><li><a href="https://blog.csdn.net/Huang_Fj/article/details/102688509" target="_blank" rel="noopener">TensorFlow中Optimizer.minimize()与Optimizer.compute_gradients()和Optimizer.apply_gradients()的用法</a></li><li><a href="https://blog.csdn.net/abc13526222160/article/details/89497497#_3" target="_blank" rel="noopener">TensorFlow2.0笔记12：梯度下降,函数优化实战,手写数字问题实战以及Tensorboard可视化！</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;转自&lt;a href=&quot;https://www.cnblogs.com/marsggbo/p/10056057.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;TensorFlow学习笔记之—[compute_gradients和apply_gradients原理浅析]&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="深度学习" scheme="http://www.junyuanw.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="tensorflow" scheme="http://www.junyuanw.com/tags/tensorflow/"/>
    
  </entry>
  
  <entry>
    <title>Leetcode042-Trapping Rain Water</title>
    <link href="http://www.junyuanw.com/2019/10/22/Leetcode042-Trapping-Rain-Water/"/>
    <id>http://www.junyuanw.com/2019/10/22/Leetcode042-Trapping-Rain-Water/</id>
    <published>2019-10-22T12:44:58.000Z</published>
    <updated>2020-08-09T11:08:27.665Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>努力，奋斗。</p></blockquote><a id="more"></a><p><strong>Note: </strong> 这是一个标准的错误答案，但是思路我觉得还可以，只是记录一下，方便日后学习。</p><p>还以为自己想到了一个不错的方法，现实又是一记重拳。</p><h3 id="Problem"><a href="#Problem" class="headerlink" title="Problem"></a>Problem</h3><p> Given <em>n</em> non-negative integers representing an elevation map where the width of each bar is 1, compute how much water it is able to trap after raining. </p><p><img src="/2019/10/22/Leetcode042-Trapping-Rain-Water/rainwatertrap.png" alt></p><p> <em>The above elevation map is represented by array [0,1,0,2,1,0,1,3,2,1,2,1]. In this case, 6 units of rain water (blue section) are being trapped. </em></p><p><strong>Example:</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Input: [0,1,0,2,1,0,1,3,2,1,2,1]</span><br><span class="line">Output: 6</span><br></pre></td></tr></table></figure><p>题读起来很简单，就是将黑色部分看成一个容器，计算容器中雨水（蓝色块）的数量。</p><h3 id="Process"><a href="#Process" class="headerlink" title="Process"></a>Process</h3><p><strong>思路1：</strong>暴力方法，就是从前往后一点点比较，但是设置的变量越来越多，用的有点懵， 而且最后那一部分出来起来实在是闲麻烦，突然就想到一层一层统计了。</p><p><strong>思路2：</strong>每层是否有雨水，肯定与容器的高度有关，可以统计每层雨水的数量，只要两边被块包围，中间为空的地方肯定就是有雨水的；所以按照框的长度和最高的高度创建一个容器，根据每列数组的大小设置每列中1的数量，最后分层处理，也就是一行一行统计，求和得到雨水的水量。</p><p>没想到内存炸了。</p><h3 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h3><p><strong>Note: </strong> 这个解法内存占用没通过测试。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">trap</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; height)</span> </span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> water = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> max = <span class="number">0</span>;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> val: height)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">if</span> (val &gt; max)</span><br><span class="line">            &#123;</span><br><span class="line">                max = val;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 创建二维数组</span></span><br><span class="line">        <span class="built_in">vector</span> &lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; &gt; rain_arr;</span><br><span class="line">        rain_arr.resize(max);</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span> ; i &lt; max; i++)</span><br><span class="line">    &#123;</span><br><span class="line">    rain_arr[i].resize(height.size());</span><br><span class="line">    &#125;</span><br><span class="line">            </span><br><span class="line">        <span class="comment">// 二维数组赋值</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; max; i++)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; height.size(); j++)</span><br><span class="line">            &#123;</span><br><span class="line">                rain_arr[i][j] = <span class="number">0</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 根据每个bar的大小为每一列添加bar个1</span></span><br><span class="line">        <span class="comment">// 注意索引的变化</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; height.size(); i++)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; height[i]; j++)</span><br><span class="line">            &#123;</span><br><span class="line">                rain_arr[j][i] = <span class="number">1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; max; i++)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; height.size(); j++)</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="built_in">cout</span> &lt;&lt; rain_arr[i][j] &lt;&lt; <span class="string">" "</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="built_in">cout</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; max; i++)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="comment">// 这里怎么求起始1和结束1之间0的个数有问题</span></span><br><span class="line">            <span class="comment">// 暂时用vector了</span></span><br><span class="line">            <span class="built_in">vector</span> &lt;<span class="keyword">int</span>&gt; index_one;</span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; height.size(); j++)</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="keyword">if</span> (rain_arr[i][j] == <span class="number">1</span>)</span><br><span class="line">                &#123;</span><br><span class="line">                    index_one.push_back(j);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// cout &lt;&lt; index_one.back() &lt;&lt; ", " &lt;&lt; index_one.front() &lt;&lt; ", " &lt;&lt; index_one.size() &lt;&lt; endl;</span></span><br><span class="line">            <span class="comment">// front和back是第一个元素和最后一个元素的引用，不是begin和end</span></span><br><span class="line">            water += index_one.back() - index_one.front() + <span class="number">1</span> - index_one.size();  </span><br><span class="line">        &#125;</span><br><span class="line">               </span><br><span class="line">        <span class="keyword">return</span> water;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="Result"><a href="#Result" class="headerlink" title="Result"></a>Result</h3><div class="table-container"><table><thead><tr><th style="text-align:left">Time Submitted</th><th style="text-align:left">Status</th><th style="text-align:left">Runtime</th><th style="text-align:left">Memory</th><th style="text-align:left">Language</th></tr></thead><tbody><tr><td style="text-align:left">7 minutes ago</td><td style="text-align:left"><a href="https://leetcode.com/submissions/detail/272213495/" target="_blank" rel="noopener">Memory Limit Exceeded</a></td><td style="text-align:left">N/A</td><td style="text-align:left">N/A</td><td style="text-align:left">cpp</td></tr></tbody></table></div><blockquote><p><strong>314 / 315</strong> test cases passed.</p></blockquote><p> 证明思路还是对的。</p><h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><p>兜兜转转，坏消息好消息轮着来，好在可能离算法近了一步；常师兄说话和张老师好像，感觉他俩的性格就很合适一起合作。</p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;努力，奋斗。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Leetcode" scheme="http://www.junyuanw.com/categories/Leetcode/"/>
    
    
      <category term="C++" scheme="http://www.junyuanw.com/tags/C/"/>
    
      <category term="algorithm" scheme="http://www.junyuanw.com/tags/algorithm/"/>
    
  </entry>
  
  <entry>
    <title>栈和队列的应用——二叉树的深度遍历和广度遍历</title>
    <link href="http://www.junyuanw.com/2019/10/19/TraversalOfBinaryTree/"/>
    <id>http://www.junyuanw.com/2019/10/19/TraversalOfBinaryTree/</id>
    <published>2019-10-19T04:07:00.000Z</published>
    <updated>2020-08-09T11:08:27.685Z</updated>
    
    <content type="html"><![CDATA[<p>莫名其妙，可能这就是生活的意义。</p> <a id="more"></a><p>还是昨天面试的问题，问完栈和队列，说栈和队列的应用，当时就想起了括号的匹配，没想到二叉树的深度遍历和广度遍历，这两种遍历方式分别对应的就是栈和队列的一个应用。</p><h3 id="1-深度优先遍历"><a href="#1-深度优先遍历" class="headerlink" title="1. 深度优先遍历"></a>1. 深度优先遍历</h3><h4 id="1-1-定义"><a href="#1-1-定义" class="headerlink" title="1.1 定义"></a>1.1 定义</h4><p>深度优先遍历：对每一个可能的分支路径深入到不能再深入为止，而且每个结点只能访问一次。深度优先遍历可以细分为先序遍历、中序遍历、后序遍历。具体说明如下：</p><ul><li>先序遍历：对任一子树，先访问根，然后遍历其左子树，最后遍历其右子树。</li><li>中序遍历：对任一子树，先遍历其左子树，然后访问根，最后遍历其右子树。</li><li>后序遍历：对任一子树，先遍历其左子树，然后遍历其右子树，最后访问根。</li></ul><h4 id="1-2-实现"><a href="#1-2-实现" class="headerlink" title="1.2 实现"></a>1.2 实现</h4><p> 因为深度优先搜索算法是先访问根节点，接着遍历左子树再遍历右子树。因为栈是<strong>后进先出</strong>的结构，先将<strong>右子树压栈，再将左子树压栈</strong>，这样左子树就位于栈顶，可以保证先遍历左子树再遍历右子树。 </p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">depthFirstTravel</span><span class="params">(Node* root)</span></span>&#123;</span><br><span class="line">    <span class="built_in">stack</span>&lt;Node *&gt; nodeStack; </span><br><span class="line">    nodeStack.push(root);</span><br><span class="line">    Node *node;</span><br><span class="line">    <span class="keyword">while</span>(!nodeStack.empty())&#123;</span><br><span class="line">        node = nodeStack.top();</span><br><span class="line">        <span class="built_in">cout</span> &lt;&lt; node-&gt;key &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">        nodeStack.pop();</span><br><span class="line">        <span class="keyword">if</span>(node-&gt;rchild)&#123;</span><br><span class="line">            nodeStack.push(node-&gt;rchild);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(node-&gt;lchild)&#123;</span><br><span class="line">            nodeStack.push(node-&gt;lchild);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="2-广度优先遍历"><a href="#2-广度优先遍历" class="headerlink" title="2. 广度优先遍历"></a>2. 广度优先遍历</h3><h4 id="2-1-定义"><a href="#2-1-定义" class="headerlink" title="2.1 定义"></a>2.1 定义</h4><p> 从根节点开始，沿着树的宽度遍历树的节点，直到所有节点都被遍历完为止。 </p><h4 id="2-2-实现"><a href="#2-2-实现" class="headerlink" title="2.2 实现"></a>2.2 实现</h4><p>因为是一层一层遍历的，所以使用<strong>队列</strong>这种数据结构，先将一层节点放到队列中，当遍历完当前这一层后，再分别出队列，同时遍历当前节点的子节点，达到一层一层遍历的目的。若使用<strong>栈</strong>，压入第二层时，出栈就无法按照正常顺序输出了。你品，你细品。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">breadthFirstTravel</span><span class="params">(Node* root)</span></span>&#123;</span><br><span class="line"><span class="built_in">queue</span>&lt;Node *&gt; nodeQueue;</span><br><span class="line">    nodeQueue.push(root);</span><br><span class="line">    Node *node;</span><br><span class="line">    <span class="keyword">while</span>(!nodeQueue.empty())&#123;</span><br><span class="line">        node = nodeQueue.front();</span><br><span class="line">        nodeQueue.pop();</span><br><span class="line">        <span class="built_in">cout</span> &lt;&lt; node-&gt;key &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">        <span class="keyword">if</span>(node-&gt;lchild)&#123;</span><br><span class="line">            nodeQueue.push(node-&gt;lchild);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(node-&gt;rchild)&#123;</span><br><span class="line">            nodeQueue.push(node-&gt;rchild);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="3-完整实现"><a href="#3-完整实现" class="headerlink" title="3. 完整实现"></a>3. 完整实现</h3><p>以下图的二叉树为例。</p><p><img src="/2019/10/19/TraversalOfBinaryTree/binarytree.png" alt></p><p>二叉树节点定义：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">STreeNode</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">    <span class="keyword">char</span> key;</span><br><span class="line">    pSTreeNode lchild;</span><br><span class="line">    pSTreeNode rchild;</span><br><span class="line"></span><br><span class="line">    STreeNode(<span class="keyword">char</span> Value)</span><br><span class="line">    &#123;</span><br><span class="line">        key = Value;</span><br><span class="line">        lchild = <span class="literal">NULL</span>;</span><br><span class="line">        rchild = <span class="literal">NULL</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stack&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;queue&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    Node *root = <span class="keyword">new</span> Node(<span class="string">'A'</span>);</span><br><span class="line">    root-&gt;lchild = <span class="keyword">new</span> Node(<span class="string">'B'</span>);</span><br><span class="line">    root-&gt;rchild = <span class="keyword">new</span> Node(<span class="string">'G'</span>);</span><br><span class="line">    Node *p = root-&gt;lchild;</span><br><span class="line">    Node *q = root-&gt;rchild;</span><br><span class="line">    p-&gt;lchild = <span class="keyword">new</span> Node(<span class="string">'C'</span>);</span><br><span class="line">    p-&gt;rchild = <span class="keyword">new</span> Node(<span class="string">'D'</span>);</span><br><span class="line">    p = p-&gt;rchild;</span><br><span class="line">    p-&gt;lchild = <span class="keyword">new</span> Node(<span class="string">'E'</span>);</span><br><span class="line">    p-&gt;rchild = <span class="keyword">new</span> Node(<span class="string">'F'</span>);</span><br><span class="line">    q-&gt;lchild = <span class="keyword">new</span> Node(<span class="string">'H'</span>);</span><br><span class="line">    q-&gt;rchild = <span class="keyword">new</span> Node(<span class="string">'I'</span>);</span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; <span class="string">"depthFirstTravel is: "</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">    depthFirstTravel(root);</span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; <span class="string">"breadthFirstTravel is: "</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">    breadthFirstTravel(root);</span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">    system(<span class="string">"pause"</span>);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 结果</span></span><br><span class="line"><span class="comment">// depthFirstTravel is:</span></span><br><span class="line"><span class="comment">// A B C D E F G H I</span></span><br><span class="line"><span class="comment">// breadthFirstTravel is:</span></span><br><span class="line"><span class="comment">// A B G C D H I E F</span></span><br></pre></td></tr></table></figure><h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><p>[1] <a href="https://www.jianshu.com/p/62f186bae583" target="_blank" rel="noopener">二叉树的深度遍历和广度遍历</a></p><p>[2] <a href="https://blog.csdn.net/Fantasy_Lin_/article/details/52751559" target="_blank" rel="noopener">二叉树的深度优先遍历和广度优先遍历</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;莫名其妙，可能这就是生活的意义。&lt;/p&gt;
    
    </summary>
    
      <category term="C++" scheme="http://www.junyuanw.com/categories/C/"/>
    
    
      <category term="C++" scheme="http://www.junyuanw.com/tags/C/"/>
    
      <category term="面试题" scheme="http://www.junyuanw.com/tags/%E9%9D%A2%E8%AF%95%E9%A2%98/"/>
    
  </entry>
  
  <entry>
    <title>C++判断一个单链表是否有环</title>
    <link href="http://www.junyuanw.com/2019/10/18/C++linklist-has-hoop/"/>
    <id>http://www.junyuanw.com/2019/10/18/C++linklist-has-hoop/</id>
    <published>2019-10-18T08:23:00.000Z</published>
    <updated>2020-08-09T11:08:27.654Z</updated>
    
    <content type="html"><![CDATA[<p>基础薄弱。</p> <a id="more"></a><p>面试时只想到了最简单的遍历方法，每遍历一个节点，都保存节点，到新节点时，从保存的节点中查找是否存在地址相同的，存在就是有环的，否则无环。问我有没有别的方法时，就想不到了。</p><h3 id="有环链表"><a href="#有环链表" class="headerlink" title="有环链表"></a>有环链表</h3><p><img src="/2019/10/18/C++linklist-has-hoop/CycleChain.jpg" alt="有环链表"></p><p>看图更直观。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 指针节点定义</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">node</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">    <span class="keyword">int</span> val;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">node</span> *<span class="title">next</span>;</span></span><br><span class="line">    node(<span class="keyword">int</span> x) : val(x), next(<span class="literal">NULL</span>) &#123;&#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="方法1"><a href="#方法1" class="headerlink" title="方法1"></a>方法1</h3><p>定义一个快指针和一个慢指针，慢指针一次走一步，快指针一次走两步。如果快指针追上了慢指针，则链表有环；如果快指针走到末尾也没追上慢指针，则无环。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">IsLoop</span><span class="params">(node *head)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (head == <span class="literal">NULL</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    node *slow = head-&gt;next;</span><br><span class="line">    <span class="keyword">if</span> (slow == <span class="literal">NULL</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    node *fast = slow-&gt;next;</span><br><span class="line">    <span class="keyword">while</span> (fast != <span class="literal">NULL</span> &amp;&amp; slow != <span class="literal">NULL</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span> (fast == slow)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        slow = slow-&gt;next;</span><br><span class="line">        fast = fast-&gt;next;</span><br><span class="line">        <span class="keyword">if</span> (fast != <span class="literal">NULL</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            fast = fast-&gt;next;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="方法2"><a href="#方法2" class="headerlink" title="方法2"></a>方法2</h3><p> 通过使用STL库中的<code>map</code>表进行映射。首先定义 <code>map&lt;node *, int&gt; m</code>; 将一个 <code>node *</code>指针映射成数组的下标，并赋值为一个 <code>int</code>类型的数值。然后从链表的头指针开始往后遍历，每次遇到一个指针<code>p</code>，就判断<code>m[p]</code>是否为0。如果为0，则将<code>m[p]</code>赋值为1，表示该节点第一次访问；而如果<code>m[p]</code>的值为1，则说明这个节点已经被访问过一次了，说明链表有环。 </p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">IsLoop_2</span><span class="params">(node *head)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">map</span>&lt;node *, <span class="keyword">int</span>&gt; m;</span><br><span class="line">    <span class="keyword">if</span> (head == <span class="literal">NULL</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    node *p = head;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> (p)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span> (m[p] == <span class="number">0</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            m[p] = <span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> (m[p] == <span class="number">1</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        p = p-&gt;next;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;map&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">//创建单链表</span></span><br><span class="line">    node *l1 = <span class="keyword">new</span> node(<span class="number">0</span>);</span><br><span class="line">    node *p = l1;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt;= <span class="number">7</span>; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        p-&gt;next = <span class="keyword">new</span> node(i);</span><br><span class="line">        p = p-&gt;next;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//创建有环链表</span></span><br><span class="line">    node *l2 = <span class="keyword">new</span> node(<span class="number">0</span>);</span><br><span class="line">    p = l2;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt;= <span class="number">7</span>; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        p-&gt;next = <span class="keyword">new</span> node(i);</span><br><span class="line">        p = p-&gt;next;</span><br><span class="line">    &#125;</span><br><span class="line">    node *q = l2;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">4</span>; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        q = q-&gt;next;</span><br><span class="line">    &#125;</span><br><span class="line">    p-&gt;next = q;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//输出链表</span></span><br><span class="line">    <span class="comment">// q = l2;</span></span><br><span class="line">    <span class="comment">// while (q)</span></span><br><span class="line">    <span class="comment">// &#123;</span></span><br><span class="line">    <span class="comment">//     cout &lt;&lt; q-&gt;val &lt;&lt; endl;</span></span><br><span class="line">    <span class="comment">//     q = q-&gt;next;</span></span><br><span class="line">    <span class="comment">// &#125;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (IsLoop(l1))</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">cout</span> &lt;&lt; <span class="string">"List l1 is a cycle chain"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> </span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">cout</span> &lt;&lt; <span class="string">"List l1 is not a cycle chain"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (IsLoop(l2))</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">cout</span> &lt;&lt; <span class="string">"List l2 is a cycle chain"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> </span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">cout</span> &lt;&lt; <span class="string">"List l2 is not a cycle chain"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">       <span class="keyword">if</span> (IsLoop_2(l1))</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">cout</span> &lt;&lt; <span class="string">"List l1 is a cycle chain"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> </span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">cout</span> &lt;&lt; <span class="string">"List l1 is not a cycle chain"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (IsLoop_2(l2))</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">cout</span> &lt;&lt; <span class="string">"List l2 is a cycle chain"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> </span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">cout</span> &lt;&lt; <span class="string">"List l2 is not a cycle chain"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    system(<span class="string">"pause"</span>);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 结果</span></span><br><span class="line">List l1 is <span class="keyword">not</span> a cycle chain</span><br><span class="line">List l2 is a cycle chain</span><br><span class="line">List l1 is <span class="keyword">not</span> a cycle chain</span><br><span class="line">List l2 is a cycle chain</span><br></pre></td></tr></table></figure><h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><p>[1] <a href="https://www.cnblogs.com/cone/p/11257063.html" target="_blank" rel="noopener">如何判断链表有环</a></p><p>[2] <a href="https://www.cnblogs.com/xiaodi914/p/5795096.html" target="_blank" rel="noopener">判断一个单链表是否有环，若有，找出环的入口节点</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;基础薄弱。&lt;/p&gt;
    
    </summary>
    
      <category term="C++" scheme="http://www.junyuanw.com/categories/C/"/>
    
    
      <category term="C++" scheme="http://www.junyuanw.com/tags/C/"/>
    
      <category term="面试题" scheme="http://www.junyuanw.com/tags/%E9%9D%A2%E8%AF%95%E9%A2%98/"/>
    
  </entry>
  
  <entry>
    <title>Weight Initialization in Neural Networks$:$ A Journey From the Basics to Kaiming(上)</title>
    <link href="http://www.junyuanw.com/2019/10/17/weight-Initialization-1/"/>
    <id>http://www.junyuanw.com/2019/10/17/weight-Initialization-1/</id>
    <published>2019-10-17T03:11:11.000Z</published>
    <updated>2020-08-09T11:08:27.710Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>或许去趟沙滩 或许去看看夕阳</p><p>或许任何一个可以想心事的地方</p><p>​                                                    ——《手写的从前》</p></blockquote><a id="more"></a><p>原文链接<a href="https://towardsdatascience.com/weight-initialization-in-neural-networks-a-journey-from-the-basics-to-kaiming-954fb9b47c79" target="_blank" rel="noopener">点击前往</a>。</p><p>本文通过简短的实验说明为什么适当的初始化权值在深度神经网络训练中如此重要。 分别用<code>Tensorflow2.0</code>和<code>Pytorch</code>实现。</p><h3 id="Why-Initialize-Weight"><a href="#Why-Initialize-Weight" class="headerlink" title="Why Initialize Weight"></a>Why Initialize Weight</h3><p>  权重初始化的目的是防止层激活输出在深度神经网络的正向传递过程中爆炸或消失。如果发生以上任何一种情况，损失梯度不是太大就是太小，无法有利地反向传播，如果发生了以上的情况，网络收敛则需要更长的时间。</p><p> 矩阵乘法是神经网络的基本数学运算。在多层的深度神经网络中，一个前向传播需要在每一层上执行入和权重矩阵之间的矩阵乘法，得到的结果又作为下一层的输入，以此类推。 </p><p> 举一个简单的例子，假设我们有一个向量 $x$ 作为网络的输入。训练神经网络时的标准做法是对输入做一个处理，使它的值落在均值为 $0$、标准差为 $1$ 的正态分布内。 </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># pytorch输入</span></span><br><span class="line">th_x= torch.randn(<span class="number">512</span>)</span><br><span class="line"><span class="comment"># tensorflow输入</span></span><br><span class="line">tf_x = tf.random.normal([<span class="number">512</span>, <span class="number">1</span>], mean=<span class="number">0.0</span>, stddev=<span class="number">1.0</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看输入x的均值和标准差</span></span><br><span class="line">th_mean = th_x.mean()</span><br><span class="line">th_var = th_x.var()</span><br><span class="line">print(<span class="string">'mean of th_x is &#123;:.5f&#125;, var of th_x is &#123;:.5f&#125;'</span>.format(th_mean, th_var))</span><br><span class="line"><span class="comment"># mean of th_x is -0.00323, var of th_x is 1.04362</span></span><br><span class="line"></span><br><span class="line">tf_mean, tf_var = tf.nn.moments(tf_x, axes=<span class="number">0</span>)</span><br><span class="line">print(<span class="string">'mean of tf_x is &#123;:.5f&#125;, var of tf_x is &#123;:.5f&#125;'</span>.format(tf_mean[<span class="number">0</span>], tf_var[<span class="number">0</span>]))</span><br></pre></td></tr></table></figure><p> 假设我们有一个简单的 $100$ 层网络，没有激活函数，每一层都有一个矩阵 $a$ 作为权值。为了完成单个的前向传递，我们必须在层输入和每一层的权值之间执行一个矩阵乘法，这将产生总计 $100$ 个连续的矩阵乘法。 </p><p> 由此看出使用相同的标准正态分布处理输入并不是一个好的办法。为了找出原因，我们可以模拟前向传播通过我们假设的网络。 </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># pytorch</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">100</span>):</span><br><span class="line">    th_a = torch.randn(<span class="number">512</span>, <span class="number">512</span>)</span><br><span class="line">    th_x = th_a @ th_x</span><br><span class="line">print(th_x.mean(), th_x.std())</span><br><span class="line"><span class="comment"># tensor(nan) tensor(nan)</span></span><br><span class="line"></span><br><span class="line">th_x = torch.randn(<span class="number">512</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">100</span>):</span><br><span class="line">    th_a = torch.randn(<span class="number">512</span>, <span class="number">512</span>)</span><br><span class="line">    th_x = th_a @ th_x</span><br><span class="line">    <span class="keyword">if</span> torch.isnan(th_x.std()): <span class="keyword">break</span></span><br><span class="line">i</span><br><span class="line"><span class="comment"># 28</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># tensorflow</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">100</span>):</span><br><span class="line">    tf_a = tf.random.normal([<span class="number">512</span>, <span class="number">512</span>])</span><br><span class="line">    tf_x = tf.matmul(tf_a, tf_x)</span><br><span class="line">tf_mean, tf_var = tf.nn.moments(tf_x,axes=<span class="number">0</span>)</span><br><span class="line">print(tf_mean, tf_var)</span><br><span class="line"><span class="comment"># tf.Tensor([nan], shape=(1,), dtype=float32) tf.Tensor([nan], shape=(1,), dtype=float32)</span></span><br><span class="line"></span><br><span class="line">tf_x = tf.random.normal([<span class="number">512</span>, <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">100</span>):</span><br><span class="line">    tf_a = tf.random.normal([<span class="number">512</span>, <span class="number">512</span>])</span><br><span class="line">    tf_x = tf.matmul(tf_a, tf_x)</span><br><span class="line">    tf_mean, tf_var = tf.nn.moments(tf_x,axes=<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">if</span> np.isnan(tf_var): <span class="keyword">break</span> <span class="comment"># 在tf2.0中没有找到判断nan的函数，使用numpy判断</span></span><br><span class="line">i</span><br><span class="line"><span class="comment"># 27</span></span><br></pre></td></tr></table></figure><p>网络在 $29$ （tensorflow在 $28$ 层）层输出已经爆炸了。</p><p>除了防止输出结果爆炸，还要防止输出消失。调整网络的权值，使它们仍然落在均值为0的正态分布内，但标准差为0.01 。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># pytorch</span></span><br><span class="line">th_x = torch.randn(<span class="number">512</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">100</span>):</span><br><span class="line">    th_a = torch.randn(<span class="number">512</span>, <span class="number">512</span>) * <span class="number">0.01</span></span><br><span class="line">    th_x = th_a @ th_x</span><br><span class="line">th_x.mean(), th_x.var()</span><br><span class="line"><span class="comment"># (tensor(0.), tensor(0.))</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># tensorflow</span></span><br><span class="line">tf_x = tf.random.normal([<span class="number">512</span>, <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">100</span>):</span><br><span class="line">    tf_a = tf.random.normal([<span class="number">512</span>, <span class="number">512</span>], mean=<span class="number">0.0</span>, stddev=<span class="number">0.01</span>)</span><br><span class="line">    tf_x = tf.matmul(tf_a, tf_x)</span><br><span class="line">    tf_mean, tf_var = tf.nn.moments(tf_x,axes=<span class="number">0</span>)</span><br><span class="line">tf_mean.numpy(), tf_var.numpy()</span><br><span class="line"><span class="comment"># (array([0.], dtype=float32), array([0.], dtype=float32))</span></span><br></pre></td></tr></table></figure><p> 在上面假设的正向传播过程中，激活输出完全消失。</p><p>总而言之，当权重初始化过大或过小时，网络都不能很好的学习。 </p><h3 id="How-can-we-find-the-sweet-spot"><a href="#How-can-we-find-the-sweet-spot" class="headerlink" title="How can we find the sweet spot?"></a>How can we find the sweet spot?</h3><p> 如上所述，完成通过神经网络的前向传播所需要的数学只不过是一系列矩阵乘法。如果我们有一个输出 $y$ 是输入向量 $x$ 和权重矩阵 $a$ 之间的矩阵乘法的乘积， $y$ 中的每个元素 $i$ 被定义为</p><script type="math/tex; mode=display">\begin{equation}\begin{split} y_i = \sum_{k=1}^{n-1}{a_{i,k}x_k}\end{split}\end{equation}</script><p> 其中 $i$ 是给定的权矩阵 $a$ 的行索引，$k$ 是给定的权矩阵 $a$ 的列索引和输入向量 $x$ 的元素索引，$n$ 是 $x$ 中元素的范围或总数，这在Python中也可以定义为:  </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">y[i] = sum([c*d <span class="keyword">for</span> c,d <span class="keyword">in</span> zip(a[i], x)])</span><br></pre></td></tr></table></figure><p> 可以证明，在给定的层上，我们从标准正态分布初始化的输入 $x$ 和权重矩阵 $a$ 的矩阵乘积通常将非常接近输入层节点数的平方根， 它在我们的例子中是 $\sqrt512$。 </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># pytorch</span></span><br><span class="line">th_mean, th_var = <span class="number">0.</span>, <span class="number">0.</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10000</span>):</span><br><span class="line">    th_x = torch.randn(<span class="number">512</span>)</span><br><span class="line">    th_a = torch.randn(<span class="number">512</span>, <span class="number">512</span>)</span><br><span class="line">    th_y = th_a @ th_x</span><br><span class="line">    th_mean += th_y.mean().item()</span><br><span class="line">    th_var += th_y.pow(<span class="number">2</span>).mean().item()</span><br><span class="line">print(th_mean/<span class="number">10000</span>, np.sqrt(th_var/<span class="number">10000</span>))</span><br><span class="line">print(np.sqrt(<span class="number">512</span>))</span><br><span class="line"><span class="comment"># -0.002851470077782869 22.624340364162048</span></span><br><span class="line"><span class="comment"># 22.627416997969522</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># tensorflow</span></span><br><span class="line">tf_mean, tf_var = <span class="number">0.</span>, <span class="number">0.</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10000</span>):</span><br><span class="line">    tf_x = tf.random.normal([<span class="number">512</span>, <span class="number">1</span>])</span><br><span class="line">    tf_a = tf.random.normal([<span class="number">512</span>, <span class="number">512</span>])</span><br><span class="line">    tf_y = tf.matmul(tf_a, tf_x)</span><br><span class="line">    tf_mean += tf.reduce_mean(tf_y)</span><br><span class="line">    tf_var += tf.reduce_mean(tf.square(tf_y))</span><br><span class="line">print(tf_mean/<span class="number">10000</span>, np.sqrt(tf_var/<span class="number">10000</span>))</span><br><span class="line">print(np.sqrt(<span class="number">512</span>))</span><br><span class="line"><span class="comment"># tf.Tensor(-0.011328138, shape=(), dtype=float32) 22.623604</span></span><br><span class="line"><span class="comment"># 22.627416997969522</span></span><br></pre></td></tr></table></figure><p> 如果从定义矩阵乘法的角度来看，这个性质并不奇怪： 为了计算 $y$，我们将输入 $x$ 的一个元素与权重 $a$ 的一列相乘，得到 $512$ 个乘积。在我们的示例中，$x$ 和 $a$ 都使用标准正态分布初始化，这 $512$ 个乘积的均值为 $0$，标准差为 $1$。 </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># pytorch</span></span><br><span class="line">th_mean, th_var = <span class="number">0.</span>, <span class="number">0.</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10000</span>):</span><br><span class="line">    th_x = torch.randn(<span class="number">1</span>)</span><br><span class="line">    th_a = torch.randn(<span class="number">1</span>)</span><br><span class="line">    th_y = th_a * th_x</span><br><span class="line">    th_mean += th_y.item()</span><br><span class="line">    th_var += th_y.pow(<span class="number">2</span>).item()</span><br><span class="line">print(th_mean/<span class="number">10000</span>, np.sqrt(th_var/<span class="number">10000</span>))</span><br><span class="line"><span class="comment"># 0.012777583549162991 0.9860565282847021</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># tensorflow</span></span><br><span class="line"><span class="comment"># tensorflow</span></span><br><span class="line">tf_mean, tf_var = <span class="number">0.</span>, <span class="number">0.</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10000</span>):</span><br><span class="line">    tf_x = tf.random.normal([<span class="number">1</span>])</span><br><span class="line">    tf_a = tf.random.normal([<span class="number">1</span>])</span><br><span class="line">    tf_y = tf.multiply(tf_a, tf_x)</span><br><span class="line">    tf_mean += tf.reduce_mean(tf_y)</span><br><span class="line">    tf_var += tf.reduce_mean(tf.square(tf_y))</span><br><span class="line">print(tf_mean/<span class="number">10000</span>, np.sqrt(tf_var/<span class="number">10000</span>))</span><br><span class="line"><span class="comment"># tf.Tensor(-0.007080218, shape=(), dtype=float32) 1.004455</span></span><br></pre></td></tr></table></figure><p> 因此，这 $512$ 个乘积的和的均值为 $0$，方差为 $512$，因此标准差为 $\sqrt 512$。 </p><p> 这就是为什么在我们上面的例子中，我们看到我们的层输出在 $29$ 次连续的矩阵乘法后爆炸。在我们最基本的 $100$ 层网络架构中，我们希望每个层的输出的标准偏差为 $1$。可以想象，这将允许我们在任意多的网络层上重复矩阵乘法，而不会触发或消失。 </p><p> 如果我们首先通过将所有随机选择的值除以 $\sqrt 512$ 来对权重矩阵 $a$ 进行缩放，那么填充输出 $y$ 的一个元素的元素乘法现在的平均方差只有 $1/\sqrt 512$。 </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># pytorch</span></span><br><span class="line">th_mean, th_var = <span class="number">0.</span>, <span class="number">0.</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10000</span>):</span><br><span class="line">    th_x = torch.randn(<span class="number">1</span>)</span><br><span class="line">    th_a = torch.randn(<span class="number">1</span>) * np.sqrt(<span class="number">1.</span>/<span class="number">512</span>)</span><br><span class="line">    th_y = th_a * th_x</span><br><span class="line">    th_mean += th_y.item()</span><br><span class="line">    th_var += th_y.pow(<span class="number">2</span>).item()</span><br><span class="line">print(th_mean/<span class="number">10000</span>, th_var/<span class="number">10000</span>)</span><br><span class="line">print(<span class="number">1</span>/<span class="number">512</span>)</span><br><span class="line"><span class="comment"># 0.0005586366911495901 0.0019827878041473895</span></span><br><span class="line"><span class="comment"># 0.001953125</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># tensorflow</span></span><br><span class="line">tf_mean, tf_var = <span class="number">0.</span>, <span class="number">0.</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10000</span>):</span><br><span class="line">    tf_x = tf.random.normal([<span class="number">1</span>])</span><br><span class="line">    tf_a = tf.random.normal([<span class="number">1</span>]) * np.sqrt(<span class="number">1.</span>/<span class="number">512</span>)</span><br><span class="line">    tf_y = tf.multiply(tf_a, tf_x)</span><br><span class="line">    tf_mean += tf.reduce_mean(tf_y)</span><br><span class="line">    tf_var += tf.reduce_mean(tf.square(tf_y))</span><br><span class="line">print(tf_mean/<span class="number">10000</span>, tf_var/<span class="number">10000</span>)</span><br><span class="line">print(<span class="number">1</span>/<span class="number">512</span>)</span><br><span class="line"><span class="comment"># tf.Tensor(-0.00051529706, shape=(), dtype=float32) tf.Tensor(0.002007504, shape=(), dtype=float32)</span></span><br><span class="line"><span class="comment"># 0.001953125</span></span><br></pre></td></tr></table></figure><p> 这意味着矩阵  $y$ 的标准差为 $1$，其中包含输入 $x$ 与权重 $a$ 相乘生成的 $512$ 个值中的每一个。让我们通过实验来证实这一点。 </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># pytorch</span></span><br><span class="line">th_mean, th_var = <span class="number">0.</span>, <span class="number">0.</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10000</span>):</span><br><span class="line">    th_x = torch.randn(<span class="number">512</span>)</span><br><span class="line">    th_a = torch.randn(<span class="number">512</span>, <span class="number">512</span>) * np.sqrt(<span class="number">1.</span>/<span class="number">512</span>)</span><br><span class="line">    th_y = th_a @ th_x</span><br><span class="line">    th_mean += th_y.mean().item()</span><br><span class="line">    th_var += th_y.pow(<span class="number">2</span>).mean().item()</span><br><span class="line">print(th_mean/<span class="number">10000</span>, np.sqrt(th_var/<span class="number">10000</span>))</span><br><span class="line"><span class="comment"># 0.0008099440926453099 1.0001812369800038</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># tensorflow</span></span><br><span class="line">tf_mean, tf_var = <span class="number">0.</span>, <span class="number">0.</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10000</span>):</span><br><span class="line">    tf_x = tf.random.normal([<span class="number">512</span>, <span class="number">1</span>])</span><br><span class="line">    tf_a = tf.random.normal([<span class="number">512</span>, <span class="number">512</span>]) * np.sqrt(<span class="number">1.</span>/<span class="number">512</span>)</span><br><span class="line">    tf_y = tf.matmul(tf_a, tf_x)</span><br><span class="line">    tf_mean += tf.reduce_mean(tf_y)</span><br><span class="line">    tf_var += tf.reduce_mean(tf.square(tf_y))</span><br><span class="line">print(tf_mean/<span class="number">10000</span>, np.sqrt(tf_var/<span class="number">10000</span>))</span><br><span class="line"><span class="comment"># tf.Tensor(0.00010935542, shape=(), dtype=float32) 1.0003854</span></span><br></pre></td></tr></table></figure><p> 现在让我们重新运行我们的100层网络。和之前一样，我们首先从 $[-1,1]$ 内部的标准正态分布中随机选择层权值，但这次我们将这些权值缩放 $1/\sqrt n$<em>，其中</em> $n$ 是一层的网络输入连接数，在我们的示例中为 $512$。 </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># pytorch</span></span><br><span class="line">th_x = torch.randn(<span class="number">512</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">100</span>):</span><br><span class="line">    th_a = torch.randn(<span class="number">512</span>, <span class="number">512</span>) * np.sqrt(<span class="number">1.</span>/<span class="number">512</span>)</span><br><span class="line">    th_x = th_a @ th_x</span><br><span class="line">th_x.mean(), th_x.std()</span><br><span class="line"><span class="comment"># (tensor(-0.0199), tensor(1.1058))</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># tensorflow</span></span><br><span class="line">tf_x = tf.random.normal([<span class="number">512</span>, <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">100</span>):</span><br><span class="line">    tf_a = tf.random.normal([<span class="number">512</span>, <span class="number">512</span>]) * np.sqrt(<span class="number">1.</span>/<span class="number">512</span>)</span><br><span class="line">    tf_x = tf.matmul(tf_a, tf_x)</span><br><span class="line">tf_mean, tf_var = tf.nn.moments(tf_x,axes=<span class="number">0</span>)</span><br><span class="line">tf_mean.numpy(), tf_var.numpy()</span><br><span class="line"><span class="comment"># (array([-0.06913895], dtype=float32), array([0.9944094], dtype=float32))</span></span><br></pre></td></tr></table></figure><p> 乍一看似乎时可以收工了，但现实世界的神经网络并不像第一个例子所显示的那么简单，为了简单起见，这里省略了激活函数。然而，在实际中，神经网络每一层的结尾都会加上一层激活函数，以此，深度神经网络可以近似的逼近一个复杂的函数来描述实际生活中的现象，比如手写数字的分类 。</p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;或许去趟沙滩 或许去看看夕阳&lt;/p&gt;
&lt;p&gt;或许任何一个可以想心事的地方&lt;/p&gt;
&lt;p&gt;​                                                    ——《手写的从前》&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="深度学习" scheme="http://www.junyuanw.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="深度学习" scheme="http://www.junyuanw.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>Leetcode-Merge Two Sorted Lists</title>
    <link href="http://www.junyuanw.com/2019/10/16/Leetcode021-Merge%20Two%20Sorted%20Lists/"/>
    <id>http://www.junyuanw.com/2019/10/16/Leetcode021-Merge Two Sorted Lists/</id>
    <published>2019-10-16T10:52:00.000Z</published>
    <updated>2020-08-09T11:08:27.663Z</updated>
    
    <content type="html"><![CDATA[<p>天黑有伞，下雨有灯。</p><a id="more"></a><h3 id="Problem"><a href="#Problem" class="headerlink" title="Problem"></a>Problem</h3><p>Merge two sorted linked lists and return it as a new list. The new list should be made by splicing together the nodes of the first two lists.</p><p><strong>Example:</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Input: 1-&gt;2-&gt;4, 1-&gt;3-&gt;4</span><br><span class="line">Output: 1-&gt;1-&gt;2-&gt;3-&gt;4-&gt;4</span><br></pre></td></tr></table></figure><h3 id="Process"><a href="#Process" class="headerlink" title="Process"></a>Process</h3><ul><li>遍历两个链表，比较元素的值</li><li>设置一个值，指向当前的节点，方便向合并的链表中增加元素</li><li>最后将剩余的值放到最后面</li></ul><h3 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Definition for singly-linked list.</span></span><br><span class="line"><span class="comment"> * struct ListNode &#123;</span></span><br><span class="line"><span class="comment"> *     int val;</span></span><br><span class="line"><span class="comment"> *     ListNode *next;</span></span><br><span class="line"><span class="comment"> *     ListNode(int x) : val(x), next(NULL) &#123;&#125;</span></span><br><span class="line"><span class="comment"> * &#125;;</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function">ListNode* <span class="title">mergeTwoLists</span><span class="params">(ListNode* l1, ListNode* l2)</span> </span>&#123;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> (l1 == <span class="literal">NULL</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> l2;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> (l2 == <span class="literal">NULL</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> l1;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        ListNode *l3, *res;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> (l1-&gt;val &lt;= l2-&gt;val) &#123;</span><br><span class="line">            l3 = <span class="keyword">new</span> ListNode(l1-&gt;val);</span><br><span class="line">            l1 = l1-&gt;next;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> &#123;</span><br><span class="line">            l3 = <span class="keyword">new</span> ListNode(l2-&gt;val);</span><br><span class="line">            l2 = l2-&gt;next;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        res = l3;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">while</span> (l1 != <span class="literal">NULL</span> &amp;&amp; l2 != <span class="literal">NULL</span>) &#123;</span><br><span class="line">            <span class="keyword">if</span> (l1-&gt;val &lt;= l2-&gt;val) &#123;</span><br><span class="line">                 l3-&gt;next = l1;</span><br><span class="line">                 l1 = l1-&gt;next;</span><br><span class="line">             &#125;</span><br><span class="line">            <span class="keyword">else</span> &#123;</span><br><span class="line">                l3-&gt;next = l2;</span><br><span class="line">                l2 = l2-&gt;next;</span><br><span class="line">            &#125;</span><br><span class="line">            l3 = l3-&gt;next;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (l1 != <span class="literal">NULL</span>) &#123;</span><br><span class="line">            l3-&gt;next = l1;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (l2 != <span class="literal">NULL</span>) &#123;</span><br><span class="line">            l3-&gt;next = l2;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="Result"><a href="#Result" class="headerlink" title="Result"></a>Result</h3><div class="table-container"><table><thead><tr><th style="text-align:left">Time Submitted</th><th style="text-align:left">Status</th><th style="text-align:left">Runtime</th><th style="text-align:left">Memory</th><th style="text-align:left">Language</th></tr></thead><tbody><tr><td style="text-align:left">2 minutes ago</td><td style="text-align:left"><a href="https://leetcode.com/submissions/detail/270390606/" target="_blank" rel="noopener">Accepted</a></td><td style="text-align:left">8 ms</td><td style="text-align:left">8.7 MB</td><td style="text-align:left">cpp</td></tr></tbody></table></div><h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><p>没什么特别的地方，做的还是稀碎。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;天黑有伞，下雨有灯。&lt;/p&gt;
    
    </summary>
    
      <category term="Leetcode" scheme="http://www.junyuanw.com/categories/Leetcode/"/>
    
    
      <category term="C++" scheme="http://www.junyuanw.com/tags/C/"/>
    
      <category term="algorithm" scheme="http://www.junyuanw.com/tags/algorithm/"/>
    
  </entry>
  
  <entry>
    <title>Leetcode-Longest Substring Without Repeating Characters</title>
    <link href="http://www.junyuanw.com/2019/10/11/Leetcode003-Longest%20Substring%20Without%20Repeating%20Characters/"/>
    <id>http://www.junyuanw.com/2019/10/11/Leetcode003-Longest Substring Without Repeating Characters/</id>
    <published>2019-10-11T04:40:00.000Z</published>
    <updated>2020-08-09T11:08:27.659Z</updated>
    
    <content type="html"><![CDATA[<p>金九已过，还在挣扎。</p><a id="more"></a><h3 id="Problem"><a href="#Problem" class="headerlink" title="Problem"></a>Problem</h3><p>Given a string, find the length of the <strong>longest substring</strong> without repeating characters.</p><p><strong>Example 1:</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Input: &quot;abcabcbb&quot;</span><br><span class="line">Output: 3 </span><br><span class="line">Explanation: The answer is &quot;abc&quot;, with the length of 3.</span><br></pre></td></tr></table></figure><p><strong>Example 2:</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Input: &quot;bbbbb&quot;</span><br><span class="line">Output: 1</span><br><span class="line">Explanation: The answer is &quot;b&quot;, with the length of 1.</span><br></pre></td></tr></table></figure><p><strong>Example 3:</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Input: &quot;pwwkew&quot;</span><br><span class="line">Output: 3</span><br><span class="line">Explanation: The answer is &quot;wke&quot;, with the length of 3. </span><br><span class="line">             Note that the answer must be a substring, &quot;pwke&quot; is a subsequence and not a substring.</span><br></pre></td></tr></table></figure><p>题干要理解清楚，<strong>要找到最长的不重复的子序列</strong>，不是从重复的位置重新统计，踩坑了。</p><h3 id="Process"><a href="#Process" class="headerlink" title="Process"></a>Process</h3><ul><li>从第二个元素开始，只要与已有的序列不重复，序列长度加1</li><li>如果重复，比较当前序列与上一个序列的长度，留下长度大的</li><li>反向遍历当前序列，从没有重复的位置开始继续保存序列</li><li>输出最长的序列的长度</li></ul><h3 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">lengthOfLongestSubstring</span><span class="params">(<span class="built_in">string</span> s)</span> </span>&#123;</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">char</span>&gt; subString;</span><br><span class="line">        <span class="keyword">int</span> length = <span class="number">0</span>;</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">char</span>&gt;::iterator iter;</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">char</span>&gt;::reverse_iterator riter;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; s.size(); i++) &#123;</span><br><span class="line">            <span class="keyword">if</span> (subString.empty()) &#123;</span><br><span class="line">                subString.push_back(s[i]);</span><br><span class="line">            &#125;</span><br><span class="line">            iter = find(subString.begin(), subString.end(), s[i]);</span><br><span class="line">            <span class="keyword">if</span>(iter != subString.end()) &#123; <span class="comment">//s[i] in subString</span></span><br><span class="line">                <span class="keyword">if</span> (subString.size() &gt; length) &#123;</span><br><span class="line">                    length = subString.size();</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="comment">// 反向迭代vector，找到s[i]之前与s[i]不相等的元素</span></span><br><span class="line">                <span class="keyword">int</span> index = <span class="number">0</span>;</span><br><span class="line">                <span class="keyword">for</span>(riter = subString.rbegin(); riter != subString.rend();++riter)</span><br><span class="line">                &#123;</span><br><span class="line">                    <span class="keyword">if</span> (*riter == s[i]) &#123;</span><br><span class="line">                        <span class="keyword">break</span>;</span><br><span class="line">                    &#125; </span><br><span class="line">                    index++;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">int</span> delete_length = subString.size() - index;</span><br><span class="line">                subString.erase(subString.begin(), subString.begin() + delete_length);</span><br><span class="line">                subString.push_back(s[i]);</span><br><span class="line">            &#125; </span><br><span class="line">            <span class="keyword">else</span> &#123;</span><br><span class="line">                subString.push_back(s[i]);</span><br><span class="line">                <span class="keyword">if</span> (subString.size() &gt; length) &#123;</span><br><span class="line">                    length = subString.size();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> length;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="Better-Solution"><a href="#Better-Solution" class="headerlink" title="Better Solution"></a>Better Solution</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">lengthOfLongestSubstring</span><span class="params">(<span class="built_in">string</span> s)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> left = <span class="number">0</span>, len = <span class="number">0</span>;</span><br><span class="line">        <span class="built_in">map</span>&lt;<span class="keyword">char</span>, <span class="keyword">int</span>&gt; dict;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> right=<span class="number">0</span>; right&lt;s.size(); right++) &#123;</span><br><span class="line">            <span class="keyword">if</span> (dict.find(s[right]) != dict.end()) &#123;</span><br><span class="line">                left = max(left, dict[s[right]] + <span class="number">1</span>);</span><br><span class="line">            &#125;</span><br><span class="line">            dict[s[right]] = right;</span><br><span class="line">            len = max(len, right - left + <span class="number">1</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> len;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="Result"><a href="#Result" class="headerlink" title="Result"></a>Result</h3><div class="table-container"><table><thead><tr><th style="text-align:left">Time Submitted</th><th style="text-align:left">Status</th><th style="text-align:left">Runtime</th><th style="text-align:left">Memory</th><th style="text-align:left">Language</th></tr></thead><tbody><tr><td style="text-align:left">a few seconds ago</td><td style="text-align:left"><a href="https://leetcode.com/submissions/detail/268837409/" target="_blank" rel="noopener">Accepted</a></td><td style="text-align:left">40 ms</td><td style="text-align:left">9.3 MB</td><td style="text-align:left">cpp</td></tr><tr><td style="text-align:left">2 minutes ago</td><td style="text-align:left"><a href="https://leetcode.com/submissions/detail/268836788/" target="_blank" rel="noopener">Wrong Answer</a></td><td style="text-align:left">N/A</td><td style="text-align:left">N/A</td><td style="text-align:left">cpp</td></tr><tr><td style="text-align:left">40 minutes ago</td><td style="text-align:left"><a href="https://leetcode.com/submissions/detail/268826526/" target="_blank" rel="noopener">Wrong Answer</a></td><td style="text-align:left">N/A</td><td style="text-align:left">N/A</td><td style="text-align:left">cpp</td></tr><tr><td style="text-align:left">44 minutes ago</td><td style="text-align:left"><a href="https://leetcode.com/submissions/detail/268825655/" target="_blank" rel="noopener">Wrong Answer</a></td><td style="text-align:left">N/A</td><td style="text-align:left">N/A</td><td style="text-align:left">cpp</td></tr><tr><td style="text-align:left">an hour ago</td><td style="text-align:left"><a href="https://leetcode.com/submissions/detail/268812576/" target="_blank" rel="noopener">Compile Error</a></td><td style="text-align:left">N/A</td><td style="text-align:left">N/A</td><td style="text-align:left">cpp</td></tr></tbody></table></div><h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><p>最开始想到的方法是栈，后来查找元素的时候发现用栈不太方便；后来换了vector，题没审明白，找到重复的元素直接清空了vector，导致结果出错。</p><p>从不重复的元素开始统计，正序遍历vector容易忽略后面存在的重复的元素，所以反向遍历vector，找到第一个重复的元素，然后删除其实元素到该重复元素，继续找不重复的序列，输出最长子序列的长度。</p><p>感觉用双端队列可能会稍微简单点吧，就不存在反向遍历的操作了。</p><p>better solution只是先拷过来，map操作还是不太能看得懂。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;金九已过，还在挣扎。&lt;/p&gt;
    
    </summary>
    
      <category term="Leetcode" scheme="http://www.junyuanw.com/categories/Leetcode/"/>
    
    
      <category term="C++" scheme="http://www.junyuanw.com/tags/C/"/>
    
      <category term="algorithm" scheme="http://www.junyuanw.com/tags/algorithm/"/>
    
  </entry>
  
  <entry>
    <title>分类损失用交叉熵的原因</title>
    <link href="http://www.junyuanw.com/2019/10/11/reason-of-using-cross-entropy/"/>
    <id>http://www.junyuanw.com/2019/10/11/reason-of-using-cross-entropy/</id>
    <published>2019-10-11T01:19:33.000Z</published>
    <updated>2020-08-09T11:08:27.696Z</updated>
    
    <content type="html"><![CDATA[<p>最近一直在纠结的一个问题，为什么分类损失用交叉熵（cross entry）而不用看起来更简单的二次代价函数（square mean），偶然间搜到一篇博客（<a href="https://blog.csdn.net/zlsjsj/article/details/80264927" target="_blank" rel="noopener">查看原文</a>），貌似是领悟了一点，简单整理下。</p><a id="more"></a><h3 id="前向传播"><a href="#前向传播" class="headerlink" title="前向传播"></a>前向传播</h3><p>前向传播的流程都是一样的，以二分类为例，以 $Sigmoid$ 为激活函数，当到达网络最后一层时：</p><p>$z = w \cdot x + b$</p><p>$a = \sigma (z) = sigmoid(z)$</p><h3 id="反向传播"><a href="#反向传播" class="headerlink" title="反向传播"></a>反向传播</h3><p>为了方便计算，只取一个样本：</p><h4 id="1-二次代价函数"><a href="#1-二次代价函数" class="headerlink" title="1. 二次代价函数"></a>1. 二次代价函数</h4><p>损失：</p><script type="math/tex; mode=display">\begin{equation}\begin{split} c = \frac{(a-y)^2}{2}\end{split}\end{equation}</script><p>$w$ 和 $b$ 的梯度为：</p><script type="math/tex; mode=display">\begin{equation}\begin{split} \frac{\partial c}{\partial w} &= (a - y ) \cdot a' \\&= (a - y) \cdot [\sigma(wx + b)]' \\&= (a - y) \cdot \sigma'(z) \cdot x\end{split}\end{equation}</script><script type="math/tex; mode=display">\begin{equation}\begin{split} \frac{\partial c}{\partial b} &= (a - y ) \cdot a' \\&= (a - y) \cdot [\sigma(wx + b)]' \\&= (a - y) \cdot \sigma'(z)\end{split}\end{equation}</script><h4 id="2-交叉熵"><a href="#2-交叉熵" class="headerlink" title="2. 交叉熵"></a>2. 交叉熵</h4><p>损失：</p><script type="math/tex; mode=display">\begin{equation}\begin{split} c = -y log(a) - (1 - y)log(1 - a)\end{split}\end{equation}</script><p>$w$ 和 $b$ 的梯度为：</p><script type="math/tex; mode=display">\begin{equation}\begin{split} \frac{\partial c}{\partial w} &= -(\frac{y}{a} - \frac{1 - y}{1 - a}) \frac{\partial \sigma(z)}{\partial w} \\ &= -(\frac{y}{a} - \frac{1 - y}{1 - a}) \cdot \sigma'(z) \cdot x \\&= -( \frac{y}{\sigma(z)} - \frac{1 - y}{1 - \sigma(z)} ) \cdot \sigma(z) \cdot (1 - \sigma(z)) \cdot x \\&= -( \frac{(1 - \sigma(z))y - \sigma(z)(1 - y)}{\sigma(z)(1 - \sigma(z)} ) \cdot \sigma(z) \cdot (1 - \sigma(z)) \cdot x \\&= (\sigma(z) - y) \cdot x\end{split}\end{equation}</script><script type="math/tex; mode=display">\begin{equation}\begin{split} \frac{\partial c}{\partial b} = \sigma(z) - y\end{split}\end{equation}</script><p><strong>Note: </strong> Sigmoid的导数为 $\sigma’(z) = \sigma(z) \cdot (1 - \sigma(z)$</p><h3 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h3><p>在反向传播时：</p><ol><li><p>对于square mean在更新 $w$，$b$ 时候， $w$，$b$ 的梯度跟激活函数的梯度成正比，激活函数梯度越大， $w$，$b$ 调整就越快，训练收敛就越快，但是Simoid函数在值非常高时候，梯度是很小的，比较平缓。</p></li><li><p>对于cross entropy在更新 $w$，$b$ 时候， $w$，$b$ 的梯度跟激活函数的梯度没有关系了，$\sigma’(z)$ 已经被抵消掉了，其中$(\sigma(z) - y)$ 表示的是预测值跟实际值差距，如果差距越大，那么 $w$，$b$ 调整就越快，收敛就越快。</p></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近一直在纠结的一个问题，为什么分类损失用交叉熵（cross entry）而不用看起来更简单的二次代价函数（square mean），偶然间搜到一篇博客（&lt;a href=&quot;https://blog.csdn.net/zlsjsj/article/details/80264927&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;查看原文&lt;/a&gt;），貌似是领悟了一点，简单整理下。&lt;/p&gt;
    
    </summary>
    
      <category term="深度学习" scheme="http://www.junyuanw.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="深度学习" scheme="http://www.junyuanw.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>Python &#39;Object of type &#39;***&#39; is not JSON serializable&#39;</title>
    <link href="http://www.junyuanw.com/2019/08/30/TypeError/"/>
    <id>http://www.junyuanw.com/2019/08/30/TypeError/</id>
    <published>2019-08-30T08:23:46.000Z</published>
    <updated>2020-08-09T11:08:27.687Z</updated>
    
    <content type="html"><![CDATA[<p>这是想要将数据写到<code>json</code>文件遇到的问题，<code>Object of type int32/int64/ndarray is not JSON serializable</code>，归根结底都是一个问题。</p><a id="more"></a><h4 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h4><p>由于<code>numpy.array</code>的数据类型不符合<code>json</code>的解码类型，使用<code>tolist()</code>方法将<code>array</code>转换成<code>list</code>。</p><p><strong>NOTE:</strong> 不能使用<code>list()</code>方法，<code>list()</code>转换的list不会改变<code>array</code>的数据类型。</p><h4 id="问题分析"><a href="#问题分析" class="headerlink" title="问题分析"></a>问题分析</h4><p>先看json可以解码的数据类型， Python操作json的<a href="http://docs.python.org/library/json.html" target="_blank" rel="noopener">标准api库</a>：</p><div class="table-container"><table><thead><tr><th style="text-align:left">JSON</th><th style="text-align:left">Python</th></tr></thead><tbody><tr><td style="text-align:left">object</td><td style="text-align:left">dict</td></tr><tr><td style="text-align:left">array</td><td style="text-align:left">list</td></tr><tr><td style="text-align:left">string</td><td style="text-align:left">str</td></tr><tr><td style="text-align:left">number (int)</td><td style="text-align:left">int</td></tr><tr><td style="text-align:left">number (real)</td><td style="text-align:left">float</td></tr><tr><td style="text-align:left">true</td><td style="text-align:left">True</td></tr><tr><td style="text-align:left">false</td><td style="text-align:left">False</td></tr><tr><td style="text-align:left">null</td><td style="text-align:left">None</td></tr></tbody></table></div><p>支持的数据类型基本都是常见的<code>int</code>，<code>str</code>类型，而<code>numpy.array</code>的数据类型都是<code>numpy</code>内置的类型。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line">y = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">5</span>):</span><br><span class="line">    x = np.random.randint(<span class="number">10</span>, size=(<span class="number">5</span>,))</span><br><span class="line">    y.append(x)</span><br><span class="line">print(y)</span><br><span class="line"></span><br><span class="line">d = &#123;&#125;</span><br><span class="line">d[<span class="string">"y"</span>] = y</span><br><span class="line"><span class="keyword">with</span> open(<span class="string">"res.json"</span>, <span class="string">"w"</span>) <span class="keyword">as</span> f:</span><br><span class="line">    json.dump(d, f)</span><br><span class="line"></span><br><span class="line">Output:</span><br><span class="line">[array([<span class="number">4</span>, <span class="number">6</span>, <span class="number">8</span>, <span class="number">8</span>, <span class="number">1</span>]),</span><br><span class="line"> array([<span class="number">2</span>, <span class="number">0</span>, <span class="number">9</span>, <span class="number">7</span>, <span class="number">1</span>]),</span><br><span class="line"> array([<span class="number">8</span>, <span class="number">7</span>, <span class="number">9</span>, <span class="number">7</span>, <span class="number">4</span>]),</span><br><span class="line"> array([<span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">7</span>, <span class="number">2</span>]),</span><br><span class="line"> array([<span class="number">6</span>, <span class="number">4</span>, <span class="number">9</span>, <span class="number">3</span>, <span class="number">3</span>])]</span><br><span class="line"></span><br><span class="line">TypeError: Object of type <span class="string">'ndarray'</span> <span class="keyword">is</span> <span class="keyword">not</span> JSON serializable</span><br></pre></td></tr></table></figure><p><code>ndarray</code>类型不能保存，<code>list</code>总能保存吧，所以先尝试<code>list()</code>方法。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">y = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">5</span>):</span><br><span class="line">    x = np.random.randint(<span class="number">10</span>, size=(<span class="number">5</span>,))</span><br><span class="line">    y.append(list(x)</span><br><span class="line">print(y)</span><br><span class="line"></span><br><span class="line">Output:</span><br><span class="line">[[<span class="number">7</span>, <span class="number">9</span>, <span class="number">6</span>, <span class="number">8</span>, <span class="number">1</span>],</span><br><span class="line"> [<span class="number">2</span>, <span class="number">8</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>],</span><br><span class="line"> [<span class="number">8</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">3</span>],</span><br><span class="line"> [<span class="number">8</span>, <span class="number">0</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="number">5</span>],</span><br><span class="line"> [<span class="number">7</span>, <span class="number">1</span>, <span class="number">4</span>, <span class="number">7</span>, <span class="number">0</span>]]</span><br></pre></td></tr></table></figure><p>看似没有任何问题，但是每次保存<code>json</code>都会遇到<code>Object of type &#39;int32&#39; is not JSON serializable</code>的问题，参考json可以解码的数据类型，查看<code>x</code>中的数据类型。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">x = np.random.randint(<span class="number">10</span>, size=(<span class="number">5</span>,))</span><br><span class="line">x = list(x)</span><br><span class="line">print(type(x[<span class="number">0</span>]))</span><br><span class="line">Output:</span><br><span class="line">&lt;<span class="class"><span class="keyword">class</span> '<span class="title">numpy</span>.<span class="title">int32</span>'&gt;</span></span><br></pre></td></tr></table></figure><p>因此判断是<code>numpy.array</code>的数据类型的问题，所以尝试<code>tolist()</code>方法。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">x = np.random.randint(<span class="number">10</span>, size=(<span class="number">5</span>,))</span><br><span class="line">x = x.tolist()</span><br><span class="line">print(type(x[<span class="number">0</span>]))</span><br><span class="line">Output:</span><br><span class="line">&lt;<span class="class"><span class="keyword">class</span> '<span class="title">int</span>'&gt;</span></span><br></pre></td></tr></table></figure><p>符合Json解码的标准，保存文件成功。</p><h4 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h4><p><code>tolist()</code>方法和<code>list()</code>方法的区别没查到，为什么一个改变数据类型，一个未改变数据类型。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这是想要将数据写到&lt;code&gt;json&lt;/code&gt;文件遇到的问题，&lt;code&gt;Object of type int32/int64/ndarray is not JSON serializable&lt;/code&gt;，归根结底都是一个问题。&lt;/p&gt;
    
    </summary>
    
      <category term="python" scheme="http://www.junyuanw.com/categories/python/"/>
    
    
      <category term="python" scheme="http://www.junyuanw.com/tags/python/"/>
    
      <category term="json" scheme="http://www.junyuanw.com/tags/json/"/>
    
  </entry>
  
  <entry>
    <title>2013.6-2019.6</title>
    <link href="http://www.junyuanw.com/2019/06/09/hualao1/"/>
    <id>http://www.junyuanw.com/2019/06/09/hualao1/</id>
    <published>2019-06-09T02:07:00.000Z</published>
    <updated>2019-10-18T09:09:20.946Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>一盏黄黄旧旧的灯 时间在旁闷不吭声</p><p>寂寞下手毫无分寸 不懂得轻重之分</p></blockquote><a id="more"></a><p>用幽默的方式表达自己的情绪，真是一个令人羡慕的技能，然而我却一直学不会。</p><h3 id="端午"><a href="#端午" class="headerlink" title="端午"></a>端午</h3><p>如果大BOSS不说放假，那默认就是不放了，想象中的做项目和现实中的做项目真是截然不同的两件事，都一年多了，从一开始的学习、兴奋，到现在厌倦，现在就希望它能早点结束。</p><p>前几天张老师就问我们端午回不回家，我就猜他要请我们吃饭，果然被我言中了，作为一个离不开女儿的父亲，他自然是不会去的，把发票给他就行了；作为一个组织能力极差的人，这顿饭我张罗的真费劲，同门叫不出来，张老师的第一反应就是同门是不是生他气了，不太理解老师为什么会这么想，而且不止一次了，哈哈哈，果然啊，孩子多了，做家长的真的很不容易啊，而且还是一个惯孩子的家长。</p><p>好久之前在网上看的一个短视频，说大部分人眼中的”公平“，所谓的公平，就是给我了没给你，这是“公平”，都给了，这就不算公平。然而这并不是一种健康的心态，共勉。</p><h3 id="高考"><a href="#高考" class="headerlink" title="高考"></a>高考</h3><p>和端午撞车了，高考的被关注度又提高了不少，天天喜提热搜，虽然已经过去6年了，但有些体会就更深了。</p><blockquote><p>@<a href="https://weibo.com/xuebaxueshu" target="_blank" rel="noopener">科普君XueShu雪树</a></p><p>题海战术非常痛苦，折磨人，也不太符合教育规律。可这是当下中国竞争激烈的高中生绕不过去的一道坎。<br>衡水中学这样的通道毕竟是普罗大众的靠谱出路，高中生为美好未来拼搏奋斗也是国家和时代朝气蓬勃的象征。<br>另一方面，我也不相信存在完美的教育，任何时代的教育都不会尽如人意，幻想通过教育改革有朝一日就能轻轻松松上大学也是幼稚的。<br>题海战术是否一定会摧毁人的创造力和想象力？这不一定，看你怎么反刍和反思。<br>题海战术最大弊端在于，它会给你一种假象，仿佛你必须通过海量做题把每一点知识都碾压得粉碎才能吸收和学习，如果不这样就感觉不踏实也没办法学好知识。<br>这种假象一定要在大学里撕破。高中那点知识从含金量上说还不够大学里一个学期的内容。知识本身就浩如烟海了，你再指望题海战术，那是海的平方，肯定是寸步难行。<br>好消息是，你根本不需要做这么多题，你只要能『独立』做出课后习题就足够了。<br>一个高中生初看这句话一定会感到惊讶。如果你只会做数学和物理课本上的习题就去高考，后果可能很惨。<br>问题在哪呢？中学的知识量有限，又年复一年这么多人这么多考试，只能导致一个后果:<br>绝大部分试题都显得扭捏造作极不自然。</p></blockquote><p>对于智商在Baseline徘徊的我们，高中的大部分时间都是在刷题，从老师的灌输到自己的憧憬，都认为大学的校门就是从地狱到天堂的一道门，迈过了那道坎，放眼望去，全是自由，这就是最大的误区，千万不要用自己以为的自由去类比大学的自由，大学自由的前提还是在完成当前学业的基础上，毕竟身份还是学生，所谓大学的自由，就是没有了题海的束缚，可以在学完知识的时候，做一些自己喜欢的事情，上网就算了，可以但没必要。</p><p>虽然小破博客没人看，但我还是想说，高考虽然是当下的全部，但不是人生的全部，考的好也罢，不好也罢，只要带着学习的热情，就不会太差。</p><h3 id="一个笑话"><a href="#一个笑话" class="headerlink" title="一个笑话"></a>一个笑话</h3><p>吃饭回来的时候，看到老年服装表演系在招生，</p><p>浩文就调侃说，“谁老年还去学这个？”</p><p>我，“不要小看这个，你60岁的时候说不定也要去学。”</p><p>贵儿哥，“60岁的时候打英雄联盟，一只手掐着自己的人中，另一只手和人对喷。”</p><p>都是嘴强王者。</p><h3 id="话痨说"><a href="#话痨说" class="headerlink" title="话痨说"></a>话痨说</h3><p>有些东西，不说就憋得慌，但也不知道该和谁说，说多了，不免显得矫情，日记也好久没更新了，正好有个小破博客，主要就是Github好久没绿了，心里有点不舒服，天天泡实验室的时间很长，但做的东西就很少，磨洋工的一把好手，下午要把这周的周报写了，但愿我能写完。</p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;一盏黄黄旧旧的灯 时间在旁闷不吭声&lt;/p&gt;
&lt;p&gt;寂寞下手毫无分寸 不懂得轻重之分&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="话痨说" scheme="http://www.junyuanw.com/categories/%E8%AF%9D%E7%97%A8%E8%AF%B4/"/>
    
    
  </entry>
  
  <entry>
    <title>Leetcode-Add Two Numbers</title>
    <link href="http://www.junyuanw.com/2019/05/25/Leetcode002-Add%20Two%20Numbers/"/>
    <id>http://www.junyuanw.com/2019/05/25/Leetcode002-Add Two Numbers/</id>
    <published>2019-05-25T07:06:00.000Z</published>
    <updated>2020-08-09T11:08:27.659Z</updated>
    
    <content type="html"><![CDATA[<p>本打算好好看看数据结构，结果看到递归后就被一些乱七八糟的事一直拖着，一直也没往下看，而且隔段时间不回去看一下，就容易忘了，所以心血来潮，挑战了了第一道<code>Medium</code>，其实也没想的那么难，只不过考虑的东西要比<code>Easy</code>的多一些而已，然而，能踩的坑我还是都踩了一遍。</p><a id="more"></a><h3 id="Problem"><a href="#Problem" class="headerlink" title="Problem"></a>Problem</h3><p>You are given two <strong>non-empty</strong> linked lists representing two non-negative integers. The digits are stored in <strong>reverse order</strong> and each of their nodes contain a single digit. Add the two numbers and return it as a linked list.</p><p>You may assume the two numbers do not contain any leading zero, except the number 0 itself.</p><p><strong>Example:</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Input: (2 -&gt; 4 -&gt; 3) + (5 -&gt; 6 -&gt; 4)</span><br><span class="line">Output: 7 -&gt; 0 -&gt; 8</span><br><span class="line">Explanation: 342 + 465 = 807.</span><br></pre></td></tr></table></figure><p>给了两个非空的单链表，每一个单链表作为一个倒序的十进制的数，对这两个十进制数求和，得到的结果<strong>倒序输出</strong>，既然同样倒序放到一个新的列表中，其实这样就没那么复杂了，既然都是倒序，那就从头开始做，先从单链表的第一个元素，即十进制数对应的个位数开始计算，只需要考虑进位的问题就可以了。</p><h3 id="Process"><a href="#Process" class="headerlink" title="Process"></a>Process</h3><ul><li><p>两个单链表的长度可能不同，如果不同，在短的后面补零；</p><p><strong>Note：</strong>对两个同时判断，否则长度相同时会死循环。</p></li><li><p>对同一个位置的数求和$ (sum) $，如果$sum &gt; 10$，则对$ sum $取余，进位数加$ 1 $；</p></li><li><p>当两个链表的<code>next</code>都为空时就意味着加法结束了，如果进位数$ &gt; 0 $，则结果再增加一位最高位，并设置为$ 1 $。</p></li></ul><h3 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Definition for singly-linked list.</span></span><br><span class="line"><span class="comment"> * struct ListNode &#123;</span></span><br><span class="line"><span class="comment"> *     int val;</span></span><br><span class="line"><span class="comment"> *     ListNode *next;</span></span><br><span class="line"><span class="comment"> *     ListNode(int x) : val(x), next(NULL) &#123;&#125;</span></span><br><span class="line"><span class="comment"> * &#125;;</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function">ListNode* <span class="title">addTwoNumbers</span><span class="params">(ListNode* l1, ListNode* l2)</span> </span>&#123;</span><br><span class="line">        ListNode* res = <span class="keyword">new</span> ListNode(<span class="number">0</span>);</span><br><span class="line">        ListNode* ptr = res;</span><br><span class="line">        <span class="keyword">int</span> sum, carry = <span class="number">0</span>;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">while</span> (l1 || l2) &#123;</span><br><span class="line">            <span class="keyword">if</span> (l1-&gt;next == <span class="literal">NULL</span> &amp;&amp; l2-&gt;next != <span class="literal">NULL</span>) &#123;</span><br><span class="line">                l1-&gt;next = <span class="keyword">new</span> ListNode(<span class="number">0</span>);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (l2-&gt;next == <span class="literal">NULL</span>&amp;&amp; l1-&gt;next != <span class="literal">NULL</span>) &#123;</span><br><span class="line">                l2-&gt;next = <span class="keyword">new</span> ListNode(<span class="number">0</span>);</span><br><span class="line">            &#125;</span><br><span class="line">             sum = l1-&gt;val + l2-&gt;val + carry;</span><br><span class="line">            </span><br><span class="line">             carry = <span class="number">0</span>;</span><br><span class="line">             <span class="keyword">if</span> (sum &gt;= <span class="number">10</span>) &#123;</span><br><span class="line">                 sum = sum % <span class="number">10</span>;</span><br><span class="line">                 carry = <span class="number">1</span>;</span><br><span class="line">             &#125;    </span><br><span class="line">             ptr-&gt;next = <span class="keyword">new</span> ListNode(sum);</span><br><span class="line">             ptr = ptr-&gt;next;</span><br><span class="line">             <span class="keyword">if</span> (l1-&gt;next == <span class="literal">NULL</span> &amp;&amp; l2-&gt;next == <span class="literal">NULL</span> &amp;&amp; carry &gt; <span class="number">0</span>) &#123;</span><br><span class="line">                 ptr-&gt;next = <span class="keyword">new</span> ListNode(<span class="number">1</span>);</span><br><span class="line">                 l1 = l1-&gt;next;</span><br><span class="line">                 l2 = l2-&gt;next;</span><br><span class="line">             &#125;</span><br><span class="line">             <span class="keyword">else</span> &#123;</span><br><span class="line">                 l1 = l1-&gt;next;</span><br><span class="line">                 l2 = l2-&gt;next;</span><br><span class="line">             &#125;</span><br><span class="line">         &#125;</span><br><span class="line">        ptr = res-&gt;next;</span><br><span class="line">        <span class="keyword">delete</span> res;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> ptr;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="Better-Solution"><a href="#Better-Solution" class="headerlink" title="Better Solution"></a>Better Solution</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function">ListNode* <span class="title">addTwoNumbers</span><span class="params">(ListNode* l1, ListNode* l2)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> sum=<span class="number">0</span>;</span><br><span class="line">        ListNode *l3=<span class="literal">NULL</span>;</span><br><span class="line">        ListNode **node=&amp;l3;</span><br><span class="line">        <span class="keyword">while</span>(l1!=<span class="literal">NULL</span>||l2!=<span class="literal">NULL</span>||sum&gt;<span class="number">0</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">if</span>(l1!=<span class="literal">NULL</span>)</span><br><span class="line">            &#123;</span><br><span class="line">                sum+=l1-&gt;val;</span><br><span class="line">                l1=l1-&gt;next;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span>(l2!=<span class="literal">NULL</span>)</span><br><span class="line">            &#123;</span><br><span class="line">                sum+=l2-&gt;val;</span><br><span class="line">                l2=l2-&gt;next;</span><br><span class="line">            &#125;</span><br><span class="line">            (*node)=<span class="keyword">new</span> ListNode(sum%<span class="number">10</span>);</span><br><span class="line">            sum/=<span class="number">10</span>;</span><br><span class="line">            node=&amp;((*node)-&gt;next);</span><br><span class="line">        &#125;        </span><br><span class="line">        <span class="keyword">return</span> l3;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>思路其实没什么区别，但是这样写很明显比我的更好理解。</p><h3 id="Result"><a href="#Result" class="headerlink" title="Result"></a>Result</h3><div class="table-container"><table><thead><tr><th>Time Submitted</th><th>Status</th><th>Runtime</th><th>Memory</th><th>Language</th></tr></thead><tbody><tr><td>a few seconds ago</td><td><a href="https://leetcode.com/submissions/detail/221560125/" target="_blank" rel="noopener">Accepted</a></td><td>4 ms</td><td>8.4 MB</td><td>cpp</td></tr></tbody></table></div><h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><p>数据结构和语言的学习要一直在路上了，这一道题，加踩坑加磨叽，用了好长时间，实在不应该。</p><p>p.s. 每次在学校的理发店剪完头都想和理发师拼命啊有木有！！！</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本打算好好看看数据结构，结果看到递归后就被一些乱七八糟的事一直拖着，一直也没往下看，而且隔段时间不回去看一下，就容易忘了，所以心血来潮，挑战了了第一道&lt;code&gt;Medium&lt;/code&gt;，其实也没想的那么难，只不过考虑的东西要比&lt;code&gt;Easy&lt;/code&gt;的多一些而已，然而，能踩的坑我还是都踩了一遍。&lt;/p&gt;
    
    </summary>
    
      <category term="Leetcode" scheme="http://www.junyuanw.com/categories/Leetcode/"/>
    
    
      <category term="C++" scheme="http://www.junyuanw.com/tags/C/"/>
    
      <category term="algorithm" scheme="http://www.junyuanw.com/tags/algorithm/"/>
    
  </entry>
  
  <entry>
    <title>tensorwatch——可视化深度学习库的使用</title>
    <link href="http://www.junyuanw.com/2019/05/24/tensorwatch-tutorial/"/>
    <id>http://www.junyuanw.com/2019/05/24/tensorwatch-tutorial/</id>
    <published>2019-05-24T03:19:16.000Z</published>
    <updated>2020-08-09T11:08:27.698Z</updated>
    
    <content type="html"><![CDATA[<p>tensorwatch地址：<a href="https://github.com/microsoft/tensorwatch" target="_blank" rel="noopener">Github</a></p><a id="more"></a><blockquote><p>TensorWatch is a debugging and visualization tool designed for deep learning and reinforcement learning. It fully leverages Jupyter Notebook to show real time visualizations and offers unique capabilities to query the live training process without having to sprinkle logging statements all over. You can also use TensorWatch to build your own UIs and dashboards. In addition, TensorWatch leverages several excellent libraries for visualizing model graph, review model statistics, explain prediction and so on.</p></blockquote><p>Tensorwatch可以在网络训练的过程中可视化网络的损失以及各种参数，相比于print，能看的更直观一些，而且，看着很高端啊。</p><p>通过<code>pip</code>安装<code>tensorwatch</code>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install tensorwatch</span><br></pre></td></tr></table></figure><p>中间可能会在安装pytorch那里报错，只需要单独把torch装一下就行。话说这个东西为什么会和pytorch挂钩，而且，Anaconda的清华源已经不能用了啊！！！</p><p>然后就是动态显示的过程了，这里官方文档说的不是很具体，走了不少弯路。</p><p><code>tensorwatch</code>只是一个可视化的工具，不会产生任何数据，都是从执行代码的终端那里来的，都是从执行代码的终端那里来的，都是从执行代码的终端那里来的。</p><p>所以，首先要有产生数据的终端：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#***************** gen_data.py *******************</span></span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> tensorwatch <span class="keyword">as</span> tw</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="comment"># create watcher, notice that we are not logging anything</span></span><br><span class="line">w = tw.Watcher()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10000</span>):</span><br><span class="line">    x = i</span><br><span class="line">    loss = random.random() * <span class="number">10</span></span><br><span class="line">    train_accuracy = random.random()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># we are just observing variables</span></span><br><span class="line">    <span class="comment"># observation has no cost, nothing gets logged anywhere</span></span><br><span class="line">    w.observe(iter=x, loss=loss, train_accuracy=train_accuracy)</span><br><span class="line"></span><br><span class="line">    time.sleep(<span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>通过<code>tw.Watcher()</code>创建一个观察的对象，将要可视化的数据放在<code>observe</code>中，这里假设是个神经网络，<code>x</code>代表迭代的次数，<code>loss</code>代表每次迭代后的损失，<code>train_accuracy</code>代表每次迭代后在训练集上的准确率。</p><p>到这里，生成数据的终端就完成了，下一步，在<code>jupyter notebook</code>中可视化每一步的结果。</p><p>打开<code>jupyter notebook</code>，新建一个<code>notebook</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib notebook</span><br><span class="line"><span class="keyword">import</span> tensorwatch <span class="keyword">as</span> tw</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 连接执行tensorwatch的终端</span></span><br><span class="line">client = tw.WatcherClient()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用lambda获取终端中的参数</span></span><br><span class="line">loss_stream = client.create_stream(expr=<span class="string">'lambda d:(d.iter, d.loss)'</span>)</span><br><span class="line"><span class="comment"># 可视化设置</span></span><br><span class="line">loss_plot = tw.Visualizer(loss_stream, vis_type=<span class="string">'line'</span>, xtitle=<span class="string">'Epoch'</span>, ytitle=<span class="string">'Train Loss'</span>)</span><br><span class="line">loss_plot.show()</span><br></pre></td></tr></table></figure><p>执行完上面的代码会生成一个可视化的界面，用来表示迭代次数和损失之间的关系：</p><p><img src="/2019/05/24/tensorwatch-tutorial/loss_stream.png" alt></p><p>继续执行，用以表示迭代次数和训练的正确率之间的关系：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">acc_stream = client.create_stream(expr=<span class="string">'lambda d:(d.iter, d.train_accuracy)'</span>)</span><br><span class="line">acc_plot = tw.Visualizer(acc_stream, vis_type=<span class="string">'line'</span>, host=loss_plot, xtitle=<span class="string">'Epoch'</span>, ytitle=<span class="string">'Train Accuracy'</span>, yrange=(<span class="number">0</span>,))</span><br><span class="line">acc_plot.show()</span><br></pre></td></tr></table></figure><p>执行完Figure会变成下图的样子：</p><p><img src="/2019/05/24/tensorwatch-tutorial/acc_stream.png" alt></p><p><strong>注意在终端执行完之前不要关闭figure，否则可视化就结束了。</strong></p><p>最后新建一个终端，在终端中执行：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python gen_data.py</span><br></pre></td></tr></table></figure><p>就可以在<code>jupyter notebook</code>中可视化结果啦。</p><p><img src="/2019/05/24/tensorwatch-tutorial/start.gif" alt></p><p>至此，可视化的任务就结束了。</p><p>拿<code>Tensorflow</code>做了一个简单的测试，可视化的参数和上面<code>jupyter notebook</code>中的相同，只需要将终端中执行的<code>gen_data.py</code>换成<code>mnist_train.py</code>就可以了。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#***************** mnist_train.py *******************</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line"><span class="keyword">import</span> tensorwatch <span class="keyword">as</span> tw</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">weight_variable</span><span class="params">(shape)</span>:</span></span><br><span class="line">    initial = tf.truncated_normal(shape, stddev=<span class="number">0.1</span>)</span><br><span class="line">    <span class="keyword">return</span> tf.Variable(initial)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bias_variable</span><span class="params">(shape)</span>:</span></span><br><span class="line">    initial = tf.constant(<span class="number">0.1</span>, shape=shape)</span><br><span class="line">    <span class="keyword">return</span> tf.Variable(initial)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">conv2d</span><span class="params">(x, W)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> tf.nn.conv2d(x, W, strides=[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], padding=<span class="string">'SAME'</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">max_pool_2x2</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> tf.nn.max_pool(x, ksize=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], strides=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], padding=<span class="string">'SAME'</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="comment"># convolution layer 1</span></span><br><span class="line">    W_conv1 = weight_variable([<span class="number">5</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">32</span>])</span><br><span class="line">    b_conv1 = bias_variable([<span class="number">32</span>])</span><br><span class="line">    </span><br><span class="line">    x_image = tf.reshape(x, [<span class="number">-1</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>])</span><br><span class="line">    </span><br><span class="line">    h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)</span><br><span class="line">    h_pool1 = max_pool_2x2(h_conv1)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># convolution layer 2</span></span><br><span class="line">    W_conv2 = weight_variable([<span class="number">5</span>, <span class="number">5</span>, <span class="number">32</span>, <span class="number">64</span>])</span><br><span class="line">    b_conv2 = bias_variable([<span class="number">64</span>])</span><br><span class="line">    </span><br><span class="line">    h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)</span><br><span class="line">    h_pool2 = max_pool_2x2(h_conv2)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># full convolution</span></span><br><span class="line">    W_fc1 = weight_variable([<span class="number">7</span> * <span class="number">7</span> * <span class="number">64</span>, <span class="number">1024</span>])</span><br><span class="line">    b_fc1 = bias_variable([<span class="number">1024</span>])</span><br><span class="line">    </span><br><span class="line">    h_pool2_flat = tf.reshape(h_pool2, [<span class="number">-1</span>, <span class="number">7</span>*<span class="number">7</span>*<span class="number">64</span>])</span><br><span class="line">    h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># output layer, softmax</span></span><br><span class="line">    W_fc2 = weight_variable([<span class="number">1024</span>, <span class="number">10</span>])</span><br><span class="line">    b_fc2 = bias_variable([<span class="number">10</span>])</span><br><span class="line">    </span><br><span class="line">    y_conv=tf.nn.softmax(tf.matmul(h_fc1, W_fc2) + b_fc2, name=<span class="string">"output"</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> y_conv</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">()</span>:</span></span><br><span class="line">    mnist = input_data.read_data_sets(<span class="string">"/MNIST_data"</span>, one_hot=<span class="literal">True</span>)</span><br><span class="line">    </span><br><span class="line">    w = tw.Watcher()</span><br><span class="line"></span><br><span class="line">    x = tf.placeholder(tf.float32, [<span class="literal">None</span>, <span class="number">784</span>], name=<span class="string">"input"</span>)</span><br><span class="line">    y_ = tf.placeholder(tf.float32, [<span class="literal">None</span>, <span class="number">10</span>], name=<span class="string">"label"</span>)</span><br><span class="line">    </span><br><span class="line">    y_conv = forward(x)</span><br><span class="line">    cost = -tf.reduce_sum(y_*tf.log(y_conv))</span><br><span class="line">    train_step = tf.train.AdamOptimizer(<span class="number">1e-4</span>).minimize(cost)</span><br><span class="line">    correct_prediction = tf.equal(tf.argmax(y_conv,<span class="number">1</span>), tf.argmax(y_,<span class="number">1</span>))</span><br><span class="line">    accuracy = tf.reduce_mean(tf.cast(correct_prediction, <span class="string">"float"</span>))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">        sess.run(tf.global_variables_initializer())</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">5000</span>):</span><br><span class="line">            batch = mnist.train.next_batch(<span class="number">64</span>)</span><br><span class="line">            _, loss = sess.run([train_step, cost], feed_dict=&#123;x: batch[<span class="number">0</span>], y_: batch[<span class="number">1</span>]&#125;)</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> i%<span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">                train_accuracy = sess.run(accuracy, feed_dict=&#123;x:batch[<span class="number">0</span>], y_: batch[<span class="number">1</span>]&#125;)</span><br><span class="line">                print(<span class="string">"step %d, training accuracy %g"</span>%(i, train_accuracy))</span><br><span class="line"></span><br><span class="line">            w.observe(iter=i, loss=loss, train_accuracy=train_accuracy)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">train()</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;tensorwatch地址：&lt;a href=&quot;https://github.com/microsoft/tensorwatch&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Github&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="深度学习" scheme="http://www.junyuanw.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="深度学习" scheme="http://www.junyuanw.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="tensorflow" scheme="http://www.junyuanw.com/tags/tensorflow/"/>
    
      <category term="可视化" scheme="http://www.junyuanw.com/tags/%E5%8F%AF%E8%A7%86%E5%8C%96/"/>
    
      <category term="tensorwatch" scheme="http://www.junyuanw.com/tags/tensorwatch/"/>
    
  </entry>
  
  <entry>
    <title>Google免费云环境Colaboratory使用教程</title>
    <link href="http://www.junyuanw.com/2019/05/05/Google-Colaboratory-tutorial/"/>
    <id>http://www.junyuanw.com/2019/05/05/Google-Colaboratory-tutorial/</id>
    <published>2019-05-05T11:11:20.000Z</published>
    <updated>2020-08-09T11:08:27.657Z</updated>
    
    <content type="html"><![CDATA[<p> Colaboratory是Google的一个免费的深度学习云端环境，提供免费的GPU和TPU，除了需要科学上网，用起来还是非常舒服的。</p><p>Colab地址：<a href="https://colab.research.google.com/notebook" target="_blank" rel="noopener">点击前往</a></p><a id="more"></a><h4 id="基本使用"><a href="#基本使用" class="headerlink" title="基本使用"></a>基本使用</h4><p>进入Google云端硬盘，右键$\rightarrow$更多$\rightarrow$关联更多应用 搜索Colaboratory并添加，添加完成后，右键选择Colaboratory就可以创建一个新的notebook。</p><p>Colab的用法和Jupyter notebook一样，可以直接执行Python代码，也可以通过<code>!+command</code>执行linux命令。</p><p>执行Python代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">a = np.random.random((<span class="number">3</span>, <span class="number">3</span>))</span><br><span class="line">print(a)</span><br><span class="line">print(<span class="string">"sum: "</span>, np.sum(a))</span><br><span class="line"></span><br><span class="line">[[<span class="number">0.24678976</span> <span class="number">0.47023166</span> <span class="number">0.00604048</span>]</span><br><span class="line"> [<span class="number">0.81917307</span> <span class="number">0.9650736</span>  <span class="number">0.9974302</span> ]</span><br><span class="line"> [<span class="number">0.88696709</span> <span class="number">0.92203368</span> <span class="number">0.31132943</span>]]</span><br><span class="line">sum:  <span class="number">5.625068960056541</span></span><br></pre></td></tr></table></figure><p>使用命令查看Ubuntu的版本：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">!lsb_release -a</span><br><span class="line"></span><br><span class="line">No LSB modules are available.</span><br><span class="line">Distributor ID:Ubuntu</span><br><span class="line">Description:Ubuntu 18.04.2 LTS</span><br><span class="line">Release:    18.04</span><br><span class="line">Codename:    bionic</span><br></pre></td></tr></table></figure><h4 id="连接Google云端硬盘"><a href="#连接Google云端硬盘" class="headerlink" title="连接Google云端硬盘"></a>连接Google云端硬盘</h4><p>执行下面代码，点击输出链接，登陆Google账号，获取授权码，粘贴到输入框中，链接到云端硬盘，硬盘挂载在<code>/content/drive</code>下。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Load the Drive helper and mount</span></span><br><span class="line"><span class="keyword">from</span> google.colab <span class="keyword">import</span> drive</span><br><span class="line"><span class="comment"># This will prompt for authorization.</span></span><br><span class="line">drive.mount(<span class="string">'/content/drive'</span>)</span><br></pre></td></tr></table></figure><p>使用<code>ls</code>命令查看云端硬盘中的文件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">!ls &quot;/content/drive/My Drive&quot;</span><br><span class="line"></span><br><span class="line"> Cifar10</span><br><span class="line">&apos;Colab Notebooks&apos;</span><br><span class="line"> CornerNet</span><br><span class="line"> deep-learning-keras-tensorflow</span><br><span class="line"> keras_Realtime_Multi-Person_Pose_Estimation-master</span><br><span class="line"> MCM</span><br><span class="line"> pose-residual-network-pytorch</span><br></pre></td></tr></table></figure><p>也可以展开侧边栏查看文件：</p><p><img src="/2019/05/05/Google-Colaboratory-tutorial/connect_to_drive.png" alt="file"></p><h4 id="查看配置"><a href="#查看配置" class="headerlink" title="查看配置"></a>查看配置</h4><p>点击 代码执行程序$\rightarrow$更改运行时类型$\rightarrow$硬件加速器 选择GPU。</p><p>执行：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.python.client <span class="keyword">import</span> device_lib</span><br><span class="line">device_lib.list_local_devices()</span><br><span class="line"></span><br><span class="line">[name: <span class="string">"/device:CPU:0"</span></span><br><span class="line"> device_type: <span class="string">"CPU"</span></span><br><span class="line"> memory_limit: <span class="number">268435456</span></span><br><span class="line"> locality &#123;</span><br><span class="line"> &#125;</span><br><span class="line"> incarnation: <span class="number">677841662562579601</span>, name: <span class="string">"/device:XLA_CPU:0"</span></span><br><span class="line"> device_type: <span class="string">"XLA_CPU"</span></span><br><span class="line"> memory_limit: <span class="number">17179869184</span></span><br><span class="line"> locality &#123;</span><br><span class="line"> &#125;</span><br><span class="line"> incarnation: <span class="number">9258589908592365980</span></span><br><span class="line"> physical_device_desc: <span class="string">"device: XLA_CPU device"</span>, name: <span class="string">"/device:XLA_GPU:0"</span></span><br><span class="line"> device_type: <span class="string">"XLA_GPU"</span></span><br><span class="line"> memory_limit: <span class="number">17179869184</span></span><br><span class="line"> locality &#123;</span><br><span class="line"> &#125;</span><br><span class="line"> incarnation: <span class="number">10896633435725669876</span></span><br><span class="line"> physical_device_desc: <span class="string">"device: XLA_GPU device"</span>, name: <span class="string">"/device:GPU:0"</span></span><br><span class="line"> device_type: <span class="string">"GPU"</span></span><br><span class="line"> memory_limit: <span class="number">14800692839</span></span><br><span class="line"> locality &#123;</span><br><span class="line">   bus_id: <span class="number">1</span></span><br><span class="line">   links &#123;</span><br><span class="line">   &#125;</span><br><span class="line"> &#125;</span><br><span class="line"> incarnation: <span class="number">711525362527462258</span></span><br><span class="line"> physical_device_desc: <span class="string">"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5"</span>]</span><br></pre></td></tr></table></figure><p>用nvidia命令查看显卡使用情况：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">!nvidia-smi</span><br><span class="line"></span><br><span class="line">Sun May  5 11:51:49 2019       </span><br><span class="line">+-----------------------------------------------------------------------------+</span><br><span class="line">| NVIDIA-SMI 418.56       Driver Version: 410.79       CUDA Version: 10.0     |</span><br><span class="line">|-------------------------------+----------------------+----------------------+</span><br><span class="line">| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |</span><br><span class="line">| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |</span><br><span class="line">|===============================+======================+======================|</span><br><span class="line">|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |</span><br><span class="line">| N/A   71C    P0    31W /  70W |    221MiB / 15079MiB |      0%      Default |</span><br><span class="line">+-------------------------------+----------------------+----------------------+</span><br><span class="line">                                                                               </span><br><span class="line">+-----------------------------------------------------------------------------+</span><br><span class="line">| Processes:                                                       GPU Memory |</span><br><span class="line">|  GPU       PID   Type   Process name                             Usage      |</span><br><span class="line">|=============================================================================|</span><br><span class="line">+-----------------------------------------------------------------------------+</span><br></pre></td></tr></table></figure><h4 id="一个示例"><a href="#一个示例" class="headerlink" title="一个示例"></a>一个示例</h4><p>为了操作方便，先将路径换成云端硬盘的路径：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.chdir(<span class="string">'/content/drive/My Drive/'</span>)</span><br></pre></td></tr></table></figure><p>执行<code>mnist_train</code>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">!python test_code/mnist_train.py</span><br><span class="line"></span><br><span class="line">step 0, training accuracy 0.171875</span><br><span class="line">step 900, training accuracy 0.96875</span><br><span class="line">step 1900, training accuracy 1</span><br><span class="line">step 3900, training accuracy 0.984375</span><br><span class="line">step 4900, training accuracy 1</span><br></pre></td></tr></table></figure><p>测试结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">!python test_code/mnist_test.py</span><br><span class="line"></span><br><span class="line">accuracy is:  0.9778</span><br></pre></td></tr></table></figure><p><strong>完整教程代码：</strong><a href="https://colab.research.google.com/drive/1YxSGGWx_d8QSE7rctj_ms7q1uWJT0TGj" target="_blank" rel="noopener">点击前往</a></p><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>Colab对想搞深度学习没有好卡的人是一个非常好的工具，环境配置简单，自带tensorflow，还可以安装其他的深度学习的框架，还可以直接从github导入，虽然每次最多只能连续用12小时，但对于学习来说已经非常够用了。更重要的一点，对于动辄几百上千的GPU云服务器，colab是免费的！</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt; Colaboratory是Google的一个免费的深度学习云端环境，提供免费的GPU和TPU，除了需要科学上网，用起来还是非常舒服的。&lt;/p&gt;
&lt;p&gt;Colab地址：&lt;a href=&quot;https://colab.research.google.com/notebook&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;点击前往&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="python" scheme="http://www.junyuanw.com/categories/python/"/>
    
    
      <category term="python" scheme="http://www.junyuanw.com/tags/python/"/>
    
      <category term="tensorflow" scheme="http://www.junyuanw.com/tags/tensorflow/"/>
    
      <category term="colaboratory" scheme="http://www.junyuanw.com/tags/colaboratory/"/>
    
  </entry>
  
  <entry>
    <title>Tensorflow1.x加载模型的方法</title>
    <link href="http://www.junyuanw.com/2019/05/04/Tensorflow1-x-lode-model/"/>
    <id>http://www.junyuanw.com/2019/05/04/Tensorflow1-x-lode-model/</id>
    <published>2019-05-04T12:16:21.000Z</published>
    <updated>2020-08-09T11:08:27.667Z</updated>
    
    <content type="html"><![CDATA[<p>代码地址：<a href="https://github.com/Junyuan12/Tensorflow1.x_save_and_load_model" target="_blank" rel="noopener">查看完整代码</a></p><a id="more"></a><h4 id="一个错误的使用"><a href="#一个错误的使用" class="headerlink" title="一个错误的使用"></a>一个错误的使用</h4><p>之前有同学问过我这个问题，<code>TF</code>加载模型，跑出来的结果不对，代码见<code>incurrect_usage.py</code>，正确率和猜的一样，怀疑是模型加载那里出问题了。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#****************** incurrent usage.py*********************</span></span><br><span class="line">x = tf.placeholder(tf.float32, [<span class="literal">None</span>, <span class="number">784</span>], name=<span class="string">"input"</span>)</span><br><span class="line">y_ = tf.placeholder(tf.float32, [<span class="literal">None</span>, <span class="number">10</span>], name=<span class="string">"label"</span>)</span><br><span class="line">pred = forward(x)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line">    saver = tf.train.import_meta_graph(<span class="string">'./model/mnist_model-4000.meta'</span>)</span><br><span class="line">    saver.restore(sess, <span class="string">'./model/mnist_model-4000'</span>)</span><br><span class="line">    correct_prediction = tf.equal(tf.argmax(pred,<span class="number">1</span>), tf.argmax(test_label, <span class="number">1</span>))</span><br><span class="line">    accuracy = tf.reduce_mean(tf.cast(correct_prediction, <span class="string">"float"</span>))</span><br><span class="line">    acc = sess.run(accuracy, feed_dict=&#123;x: test_image, y_: test_label&#125;)</span><br></pre></td></tr></table></figure><p>跑出来的正确率都在0.1左右，训练正确率都在0.9以上，再差也不会这样，所以加载模型哪里出错了。</p><h4 id="Tensorflow加载模型的方法"><a href="#Tensorflow加载模型的方法" class="headerlink" title="Tensorflow加载模型的方法"></a>Tensorflow加载模型的方法</h4><p>本例使用<code>tf.train.Saver()</code>保存模型的方法，执行<code>saver.save(sess, model_name)</code>后，会得到3个名为<code>model_name</code>的文件，<code>.data-00000-of-00001</code>中保存了网络训练的参数，<code>.meta</code>保存了网络的图结构。</p><p><code>Tensorflow</code>在加载模型的时候就需要上述的两个东西，网络参数和图结构，而加载图有两种方式，<strong>重新搭建网络</strong>或<strong>直接用.meta</strong>文件。</p><h4 id="重新搭建网络"><a href="#重新搭建网络" class="headerlink" title="重新搭建网络"></a>重新搭建网络</h4><p>顾名思义，在测试代码中重新把训练时<code>forward</code>的流程再搭一遍，这样就能得到由训练好的参数得到<code>forward</code>的结果。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#****************** test with network.py*********************</span></span><br><span class="line">x = tf.placeholder(tf.float32, [<span class="literal">None</span>, <span class="number">784</span>], name=<span class="string">"input"</span>)</span><br><span class="line">y_ = tf.placeholder(tf.float32, [<span class="literal">None</span>, <span class="number">10</span>], name=<span class="string">"label"</span>)</span><br><span class="line">pred = forward(x)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line">    saver = tf.train.Saver()</span><br><span class="line">    saver.restore(sess, <span class="string">'./model/mnist_model-4000'</span>)</span><br><span class="line">    correct_prediction = tf.equal(tf.argmax(pred,<span class="number">1</span>), tf.argmax(test_label, <span class="number">1</span>))</span><br><span class="line">    accuracy = tf.reduce_mean(tf.cast(correct_prediction, <span class="string">"float"</span>))</span><br><span class="line">    acc = sess.run(accuracy, feed_dict=&#123;x: test_image, y_: test_label&#125;)</span><br></pre></td></tr></table></figure><p>因为<code>forward</code>流程和训练时一样，所以直接在训练代码里拿来用，已经重新搭建了图，就不要加载<code>.meta</code>文件了，所以直接<code>restore</code>参数文件就可以了。</p><p>拿测试集中前5000个样本做测试，测试结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">test with network: </span><br><span class="line">INFO:tensorflow:Restoring parameters from ./model/mnist_model-4000</span><br><span class="line">accuracy is:  0.9784</span><br></pre></td></tr></table></figure><p>网络结构：</p><p><img src="/2019/05/04/Tensorflow1-x-lode-model/test_with_network.png" alt="test_with_network"></p><h4 id="使用-meta文件构建图"><a href="#使用-meta文件构建图" class="headerlink" title="使用.meta文件构建图"></a>使用.meta文件构建图</h4><p>使用<code>.meta</code>文件需要注意，在训练时最好为输入和输出取一个名字，因为需要直接从<code>.meta</code>保存的图结构中取输入和输出，有名字的时候会更明确一些。</p><p>像这样：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = tf.placeholder(tf.float32, [<span class="literal">None</span>, <span class="number">784</span>], name=<span class="string">"input"</span>)</span><br><span class="line">y_ = tf.placeholder(tf.float32, [<span class="literal">None</span>, <span class="number">10</span>], name=<span class="string">"label"</span>)</span><br></pre></td></tr></table></figure><p>加载<code>.meta</code>代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#****************** test with meta.py*********************</span></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    saver = tf.train.import_meta_graph(<span class="string">'./model/mnist_model-4000.meta'</span>)</span><br><span class="line">    saver.restore(sess, tf.train.latest_checkpoint(<span class="string">"./model/"</span>))</span><br><span class="line">    </span><br><span class="line">    graph = tf.get_default_graph()</span><br><span class="line">    input_x = graph.get_operation_by_name(<span class="string">"input"</span>).outputs[<span class="number">0</span>]</span><br><span class="line">    feed_dict = &#123;<span class="string">"input:0"</span>:test_image, <span class="string">"label:0"</span>:test_label&#125;</span><br><span class="line">    pred = graph.get_tensor_by_name(<span class="string">"output:0"</span>)</span><br><span class="line">    correct_prediction = tf.equal(tf.argmax(pred, <span class="number">1</span>), tf.argmax(test_label, <span class="number">1</span>))</span><br><span class="line">    accuracy = tf.reduce_mean(tf.cast(correct_prediction, <span class="string">"float"</span>))</span><br><span class="line">    acc = sess.run(accuracy, feed_dict=feed_dict)</span><br></pre></td></tr></table></figure><p>使用<code>.meta</code>文件，直接根据名字找到对应的输出和输出，获取默认图结构，不需要重新初始化参数。</p><p>拿测试集中前5000个样本做测试，测试结果：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">test <span class="keyword">with</span> .meta:</span><br><span class="line">INFO:tensorflow:Restoring parameters <span class="keyword">from</span> ./model/mnist_model<span class="number">-4000</span></span><br><span class="line">accuracy <span class="keyword">is</span>:  <span class="number">0.9784</span></span><br></pre></td></tr></table></figure><p>测试结果和重新构建网络是一样的。</p><p>网络结构：</p><p><img src="/2019/05/04/Tensorflow1-x-lode-model/test_with_meta.png" alt="test_with_network"></p><p>使用<code>.meta</code>测试时，网络输出那里出现了两个分支，猜测是<code>.meta</code>保存了训练时测试<code>accuracy</code>那部分图，我在测试的代码里又写了一个测试<code>accuracy</code>的部分，所以两部分都被保存了，但不影响测试的结果。</p><h4 id="错误的原因"><a href="#错误的原因" class="headerlink" title="错误的原因"></a>错误的原因</h4><p>很容易猜到，图加载了两次，已经重建网络了，然后又加载了<code>.meta</code>，导致图的结构乱了，看图：</p><p><img src="/2019/05/04/Tensorflow1-x-lode-model/incorrect_usage.png" alt="test_with_network"></p><p>网络的结构已经变了，所以加载训练好的模型时，要么重建图，要么加载<code>.meta</code>，混合起来就容易出错。</p><p>TODO：使用滑动平均如何加载模型</p><h4 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h4><p>Mnist网络backbone：<a href="https://www.cnblogs.com/willnote/p/6874699.html" target="_blank" rel="noopener">点击前往</a></p><p>TF加载模型方法： <a href="https://blog.csdn.net/sjtuxx_lee/article/details/82663394" target="_blank" rel="noopener">点击前往</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;代码地址：&lt;a href=&quot;https://github.com/Junyuan12/Tensorflow1.x_save_and_load_model&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;查看完整代码&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="深度学习" scheme="http://www.junyuanw.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="python" scheme="http://www.junyuanw.com/tags/python/"/>
    
      <category term="tensorflow" scheme="http://www.junyuanw.com/tags/tensorflow/"/>
    
      <category term="加载模型" scheme="http://www.junyuanw.com/tags/%E5%8A%A0%E8%BD%BD%E6%A8%A1%E5%9E%8B/"/>
    
  </entry>
  
  <entry>
    <title>论文阅读——Faster RCNN,详解RPN的好处</title>
    <link href="http://www.junyuanw.com/2019/04/30/advantage-of-RPN-in-Faster-RCNN/"/>
    <id>http://www.junyuanw.com/2019/04/30/advantage-of-RPN-in-Faster-RCNN/</id>
    <published>2019-04-30T02:36:52.000Z</published>
    <updated>2020-08-09T11:08:27.688Z</updated>
    
    <content type="html"><![CDATA[<p><code>Faster RCNN</code>是为目标检测而提出的一种网络，目标检测的任务是从一张给定的图片中不仅要对图像中的物体进行分类，而且要为每个类别的物体加一个<code>Box</code>，也就是要确定检测到的物体的位置。</p> <a id="more"></a><h3 id="阅读前准备"><a href="#阅读前准备" class="headerlink" title="阅读前准备"></a>阅读前准备</h3><p><code>Faster RCNN</code>由<code>Fast RCNN</code>改进，所以简单了解<code>RCNN</code>和<code>Fast RCNN</code>。</p><h4 id="RCNN"><a href="#RCNN" class="headerlink" title="RCNN"></a>RCNN</h4><p><code>RCNN</code>使用<code>selective search</code>方法，为每张图片提出大概1k~2k个候选区域，然后将每个候选区域都输入到网络中，进行特征提取，之后输入到一个SVM分类器中判断物体类别，最后使用一个回归器得到物体的精确位置，即<code>Box</code>。通过简单描述就可以看出，<code>RCNN</code>的缺点非常明显，对于现在的网络，基本都是端到端的结构，而<code>RCNN</code>的处理流程很复杂，并且保存每个候选区域的特征也会占用非常多的空间；其二，对这么多的候选区域，计算会浪费非常多的时间，而且提取的特征会重复。<br><img src="/2019/04/30/advantage-of-RPN-in-Faster-RCNN/RCNN.png" alt="RCNN"></p><h4 id="Fast-RCNN"><a href="#Fast-RCNN" class="headerlink" title="Fast RCNN"></a>Fast RCNN</h4><p><code>Fast RCNN</code>作为<code>RCNN</code>的进阶版，主要改进在两方面，一个是只需要对输入图像提一次特征，然后将找到候选区域对应的特征，对特征进行分类和回归得到<code>Box</code>；另一方面是<code>ROI Pooling</code>，由于网络中全连接层的存在，所以要求网络所谓输入大小必须是相同的，但<code>selective search</code>选出的候选区域大小不同，如果直接将输入图像都缩放到相同的大小，会丢失图像的信息；通过<code>ROI Pooling</code>可以解决这个问题，相比较于<code>Max Pooling</code>固定的<code>stride</code>，<code>ROI Pooling</code>的<code>stride</code>是根据输出的大小来决定的，比如当前<code>ROI feature map</code>的大小为$h \times w$，经过<code>ROI Pooling</code>后输出的固定大小为$H \times W$，那么<code>ROI Pooling</code>的<code>stride</code>就是$\frac{h}{H} \times \frac{w}{W}$。<br><img src="/2019/04/30/advantage-of-RPN-in-Faster-RCNN/Fast RCNN.png" alt="Fast RCNN"></p><h3 id="Faster-RCNN"><a href="#Faster-RCNN" class="headerlink" title="Faster RCNN"></a>Faster RCNN</h3><h4 id="论文核心"><a href="#论文核心" class="headerlink" title="论文核心"></a>论文核心</h4><blockquote><p>we introduce a Region Proposal Network (RPN) that shares full-image convolutional features with the detection network, thus enabling nearly cost-free region proposals. </p></blockquote><p>论文中提出一种新的选择<code>Region proposals</code>的方法，用<code>RPN</code>代替<code>Fast RCNN</code>中<code>Selective search</code>，<code>RPN</code>与<code>object detection network</code>共享卷积层，节省了大量选择候选区域的时间，<code>SS</code> $2s$ per image, <code>RPN</code> $10ms$ per image。</p><h4 id="Anchor"><a href="#Anchor" class="headerlink" title="Anchor"></a>Anchor</h4><blockquote><p>RPNs are designed to efficiently predict region proposals with a wide range of scales and aspect ratios.  </p></blockquote><p>提出了<code>anchor</code>做多尺度和长宽比的参考，避免了枚举多个尺度的信息。</p><p><code>anchor</code>的<a href="https://blog.csdn.net/sinat_33486980/article/details/81099093" target="_blank" rel="noopener">实现过程</a>：</p><p>对一幅图像，经过网络下采样得到<code>feature map</code>，对<code>feature map</code>中的一个点，找到其在原始图形对应的区域，比如，一幅图像经过3次<code>Pooling</code>，那么得到的特征中的一个点对应原始图像就是一个$16 \times 16$ 的区域，对这个区域生成不同<code>anchor</code>。</p><p>首先对该区域生成3种长宽比的<code>anchor</code>（$ratios=[0.5,1,2]$）：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_whctrs</span><span class="params">(anchor)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Return width, height, x center, and y center of an anchor.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    w = anchor[<span class="number">2</span>] - anchor[<span class="number">0</span>] + <span class="number">1</span></span><br><span class="line">    h = anchor[<span class="number">3</span>] - anchor[<span class="number">1</span>] + <span class="number">1</span></span><br><span class="line">    x_ctr = anchor[<span class="number">0</span>] + <span class="number">0.5</span> * (w - <span class="number">1</span>)</span><br><span class="line">    y_ctr = anchor[<span class="number">1</span>] + <span class="number">0.5</span> * (h - <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> w, h, x_ctr, y_ctr</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_mkanchors</span><span class="params">(ws, hs, x_ctr, y_ctr)</span>:</span>   </span><br><span class="line">    <span class="string">""" </span></span><br><span class="line"><span class="string">    Getting coordinates of different window width ratios around the same center.</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Parameters:</span></span><br><span class="line"><span class="string">        ws : A sist of X coordinates in the upper left corner of a anchor.</span></span><br><span class="line"><span class="string">        hs : A sist of Y coordinates in the upper left corner of a anchor.</span></span><br><span class="line"><span class="string">        x_ctr : X-coordinates of the center of a anchor.</span></span><br><span class="line"><span class="string">        y_ctr : Y-coordinates of the center of a anchor.</span></span><br><span class="line"><span class="string">    Return:</span></span><br><span class="line"><span class="string">        anchors : Coordinates with different aspect ratios.</span></span><br><span class="line"><span class="string">    """</span>  </span><br><span class="line">    ws = ws[:, np.newaxis]</span><br><span class="line">    hs = hs[:, np.newaxis]  </span><br><span class="line">    anchors = np.hstack((x_ctr - <span class="number">0.5</span> * (ws - <span class="number">1</span>),</span><br><span class="line">                         y_ctr - <span class="number">0.5</span> * (hs - <span class="number">1</span>),</span><br><span class="line">                         x_ctr + <span class="number">0.5</span> * (ws - <span class="number">1</span>),</span><br><span class="line">                         y_ctr + <span class="number">0.5</span> * (hs - <span class="number">1</span>)))</span><br><span class="line">    <span class="keyword">return</span> anchors</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_ratio_enum</span><span class="params">(anchor, ratios)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    Enumerate a set of anchors for each aspect ratio wrt an anchor.</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Parameters:</span></span><br><span class="line"><span class="string">        anchor : A list contains coordinates of the upper left and lower right corners.</span></span><br><span class="line"><span class="string">        ratios : A list contains different aspect ratios.</span></span><br><span class="line"><span class="string">    Return:</span></span><br><span class="line"><span class="string">        anchors : Coordinates with different aspect ratios.</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    w, h, x_ctr, y_ctr = _whctrs(anchor)</span><br><span class="line">    size = w * h                            <span class="comment">#size:16*16=256</span></span><br><span class="line">    size_ratios = size / np.array(ratios)   <span class="comment">#256/ratios[0.5,1,2]=[512,256,128]</span></span><br><span class="line">    ws = np.round(np.sqrt(size_ratios))     <span class="comment">#ws:[23 16 11]</span></span><br><span class="line">    hs = np.round(ws * ratios)              <span class="comment">#hs:[12 16 22]</span></span><br><span class="line"></span><br><span class="line">    anchors = _mkanchors(ws, hs, x_ctr, y_ctr)  </span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> anchors</span><br></pre></td></tr></table></figure><p>运行结果，得到同一中心3个长宽比的<code>anchor</code>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">_ratio_enum([<span class="number">0</span>, <span class="number">0</span>, <span class="number">15</span>, <span class="number">15</span>], [<span class="number">0.5</span>, <span class="number">1</span>, <span class="number">2</span>])</span><br><span class="line"></span><br><span class="line">array([[<span class="number">-3.5</span>,  <span class="number">2.</span> , <span class="number">18.5</span>, <span class="number">13.</span> ],</span><br><span class="line">       [ <span class="number">0.</span> ,  <span class="number">0.</span> , <span class="number">15.</span> , <span class="number">15.</span> ],</span><br><span class="line">       [ <span class="number">2.5</span>, <span class="number">-3.</span> , <span class="number">12.5</span>, <span class="number">18.</span> ]])</span><br></pre></td></tr></table></figure><p>然后对每个长宽比的<code>anchor</code>进行3种面积变换（$scales=[8, 16, 32]$）：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_scale_enum</span><span class="params">(anchor, scales)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Enumerate a set of anchors for each scale wrt an anchor.</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Parameters:</span></span><br><span class="line"><span class="string">        anchor : Orginal anchor.</span></span><br><span class="line"><span class="string">        scales : Scaling factor.</span></span><br><span class="line"><span class="string">    Return:</span></span><br><span class="line"><span class="string">        Scaled coordinates of anchor.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    w, h, x_ctr, y_ctr = _whctrs(anchor)</span><br><span class="line">    ws = w * scales</span><br><span class="line">    hs = h * scales</span><br><span class="line">    anchors = _mkanchors(ws, hs, x_ctr, y_ctr)</span><br><span class="line">    <span class="keyword">return</span> anchors</span><br></pre></td></tr></table></figure><p>运行结果，得到1个特征点对应的不同长宽比和不同缩放系数对应的9个<code>anchor</code>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">scales = <span class="number">2</span>**np.arange(<span class="number">3</span>, <span class="number">6</span>) <span class="comment">#[8, 16, 32]</span></span><br><span class="line"><span class="comment">#别问我里为什么是15不是16，我也在研究</span></span><br><span class="line">ratio_anchors = _ratio_enum([<span class="number">0</span>,<span class="number">0</span>,<span class="number">15</span>,<span class="number">15</span>], [<span class="number">0.5</span>, <span class="number">1</span>, <span class="number">2</span>])</span><br><span class="line">np.vstack([_scale_enum(ratio_anchors[i, :], scales)</span><br><span class="line">                        <span class="keyword">for</span> i <span class="keyword">in</span> range(ratio_anchors.shape[<span class="number">0</span>])])</span><br><span class="line"></span><br><span class="line">array([[ <span class="number">-84.</span>,  <span class="number">-40.</span>,   <span class="number">99.</span>,   <span class="number">55.</span>],</span><br><span class="line">       [<span class="number">-176.</span>,  <span class="number">-88.</span>,  <span class="number">191.</span>,  <span class="number">103.</span>],</span><br><span class="line">       [<span class="number">-360.</span>, <span class="number">-184.</span>,  <span class="number">375.</span>,  <span class="number">199.</span>],</span><br><span class="line">       [ <span class="number">-56.</span>,  <span class="number">-56.</span>,   <span class="number">71.</span>,   <span class="number">71.</span>],</span><br><span class="line">       [<span class="number">-120.</span>, <span class="number">-120.</span>,  <span class="number">135.</span>,  <span class="number">135.</span>],</span><br><span class="line">       [<span class="number">-248.</span>, <span class="number">-248.</span>,  <span class="number">263.</span>,  <span class="number">263.</span>],</span><br><span class="line">       [ <span class="number">-36.</span>,  <span class="number">-80.</span>,   <span class="number">51.</span>,   <span class="number">95.</span>],</span><br><span class="line">       [ <span class="number">-80.</span>, <span class="number">-168.</span>,   <span class="number">95.</span>,  <span class="number">183.</span>],</span><br><span class="line">       [<span class="number">-168.</span>, <span class="number">-344.</span>,  <span class="number">183.</span>,  <span class="number">359.</span>]])</span><br></pre></td></tr></table></figure><p>下面这个表格对比了9种尺寸的anchor的变换：</p><table class="tg"><tr><th class="tg-xldj">base_anchor</th><th class="tg-xldj">ratios</th><th class="tg-xldj">宽，高，中心点横坐标，中心点纵坐标</th><th class="tg-xldj">坐标</th></tr><tr><td class="tg-xldj" rowspan="9">16x16</td><td class="tg-uys7" rowspan="3">23x12<br>2:1</td><td class="tg-xldj">[184,96,7.5,7.5]    scale=8</td><td class="tg-xldj">[ -84.  -40.   99.   55.]</td></tr><tr><td class="tg-xldj">[368,192,7.5,7.5]   scale=16</td><td class="tg-xldj">[-176.  -88.  191.  103.]</td></tr><tr><td class="tg-xldj">[736,384,7.5,7.5]    scale=32</td><td class="tg-xldj">[-360. -184.  375.  199.]</td></tr><tr><td class="tg-uys7" rowspan="3">16x16<br>1:1</td><td class="tg-xldj">[128,128,7.5,7.5]    scale=8</td><td class="tg-xldj">[ -56.  -56.   71.   71.]</td></tr><tr><td class="tg-xldj">[256,256,7.5,7.5]    scale=16</td><td class="tg-xldj">[-120. -120.  135.  135.]</td></tr><tr><td class="tg-xldj">[512,512,7.5,7.5]    scale=32</td><td class="tg-xldj">[-248. -248.  263.  263.]</td></tr><tr><td class="tg-uys7" rowspan="3">11x22<br>1:2</td><td class="tg-xldj">[88,176,7.5,7.5]    scale=8</td><td class="tg-xldj">[ -36.  -80.   51.   95.]</td></tr><tr><td class="tg-xldj">[176,352,7.5,7.5]    scale=16</td><td class="tg-xldj">[ -80. -168.   95.  183.]</td></tr><tr><td class="tg-xldj">[352,704,7.5,7.5]    scale=32</td><td class="tg-xldj">[-168. -344.  183.  359.]</td></tr></table><p>得到的<code>anchor</code>如下图所示，蓝色点代表<code>feature map</code>中的特征点，每种颜色框代表一种长宽比，同一颜色不同大小的矩形框代表不同的尺度：<br><img src="/2019/04/30/advantage-of-RPN-in-Faster-RCNN/anchor.png" alt="Faster RCNN"><br>手贱就想画图，结果就被自己蠢到了。</p><p><strong><code>plt</code>画矩形的默认坐标系大小都是1，所以想画大一点的矩形，一定要先设置坐标系的大小</strong></p><p>我一度以为我发现了<code>matplotlib</code>的<code>BUG</code>😫😫😫</p><p>附代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">colors = [<span class="string">"red"</span>, <span class="string">"blue"</span>, <span class="string">"green"</span>]</span><br><span class="line">fig = plt.figure(figsize=(<span class="number">10</span>, <span class="number">10</span>))</span><br><span class="line">ax = fig.add_subplot(<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">plt.xlim((<span class="number">-500</span>, <span class="number">500</span>))<span class="comment">#设置x轴的大小</span></span><br><span class="line">plt.ylim((<span class="number">-500</span>, <span class="number">500</span>))<span class="comment">#设置y轴的大小</span></span><br><span class="line">plt.scatter(<span class="number">7.5</span>, <span class="number">7.5</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">9</span>):</span><br><span class="line">    rect = plt.Rectangle((anchors[i][<span class="number">0</span>], anchors[i][<span class="number">1</span>] + anchors[i][<span class="number">3</span>] - anchors[i][<span class="number">1</span>]), </span><br><span class="line">    anchors[i][<span class="number">2</span>] - anchors[i][<span class="number">0</span>], anchors[i][<span class="number">1</span>] - anchors[i][<span class="number">3</span>], </span><br><span class="line">    fill=<span class="literal">False</span>, edgecolor = colors[i//<span class="number">3</span>],linewidth=<span class="number">2</span>)</span><br><span class="line">    ax.add_patch(rect)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><h4 id="Region-proposal-Network"><a href="#Region-proposal-Network" class="headerlink" title="Region proposal Network"></a>Region proposal Network</h4><blockquote><p>Faster R-CNN is composed of two modules. The first module is a deep fully convolutional network that proposes regions, and the second module is the Fast R-CNN detector that uses the proposed regions.  </p></blockquote><p><code>Faster R-CNN</code>由两部分组成，一部分是是<code>Region proposal network</code>，突出用于检测的候选区域，另一部分和<code>Fast RCNN</code>一样，对候选区域进行检测，输出目标的类别和框的位置，网络结构如图：<br><img src="/2019/04/30/advantage-of-RPN-in-Faster-RCNN/Faster RCNN.png" alt="Faster RCNN"><br>这里我理解就是在网络提完特征后再加一层，用于选出候选区域。<br><img src="/2019/04/30/advantage-of-RPN-in-Faster-RCNN/RPN.png" alt="RPN"></p><p>对卷积得到的 $H\times W$ 的<code>feature map</code>，用一个 $n \times n$ 的滑动窗口对每个窗口的中心点提$k$个<code>anchors</code>，取3个长宽比，3个缩放比，即$k=9$，对该<code>feature map</code>，会生成 $k \times H \times W$ 个<code>anchors</code> ，对每个<code>anchor</code>的 $cls$ 分支，用一个 $score$ 判断这个<code>anchor</code>是前景还是背景，所以 $score$ 的数量是 $2k$ ；对 $reg$ 分支，需要判断框的位置，所以保存每个<code>anchor</code>的位置信息（左下和右上的坐标，<strong>这里有歧义，好多博客里写的都是左上右下，但实际画图第一个点是左下的坐标</strong>），所以 $coordinates$ 的数量是 $4k$ 。</p><h4 id="相比于SS，RPN的优势"><a href="#相比于SS，RPN的优势" class="headerlink" title="相比于SS，RPN的优势"></a>相比于SS，RPN的优势</h4><p>上面说过<code>anchor</code>，用<code>anchor</code>的话，就相当于，先知道大致位置，再知道具体位置，举个例子，<code>anchor</code>就是先上这个区域看一眼是啥，比如一个<code>anchor</code>区域里看见了一个马身子（马头一部分不在区域里面），然后再看到的马身子猜测一下这个物体的位置。但穷举搜索就不是，马身子的这个区域不是一个马的区域，必须得去搜索这个区域，直到这个区域包含整个马。<br><code>rpn</code>的优点就是你能用神经网络去从一个图像区域拟合出目标的位置来，这在非神经网络方法上肯定不能用。因为神经网络是一个复杂的非线性函数，传统的方法并不能轻易的做出复杂函数来。虽然传统的方法也能拟合复杂函数，如<code>svm</code>。不过传统方法很多都是模板匹配类的方法，只能记住训练图片中的整体特征。<br>神经网络是层级特征提取的，在图像上更加符合特点。例如识别自行车，<code>svm</code>方法就是把训练图像的自行车都记住 如果新来一辆车，和这些特点不太相同，<code>svm</code>就挂了。但神经网络不同，方式倾向于训练出车把和车轮子等的检测器，再对部件进行组合。所以<code>rpn</code>中训练的东西就是一些根据底层得到的部件检测器推测物体位置的一个函数。<br>以上内容来自于老师给我的讲解，看完了也就能理解的差不多了，<code>RPN</code>的作用更像是人的感觉一样的网络，这么说可能不太合适，比如看一辆自行车，人可能只看到一部分，前轮或后轮，就能知道这是一辆自行车了，而<code>RPN</code>的作用正是如此，所以<code>RPN</code>可以选出更少的<code>region proposal</code>而且更加准确，<code>anchor</code>是在选好<code>region proposal</code>的基础上，用不同长宽比的不同尺度能去尽量的把这个物体包进去。</p><h4 id="Share-features"><a href="#Share-features" class="headerlink" title="Share features"></a>Share features</h4><p>采用4步交替训练的方法：</p><ol><li>用一个<code>ImageNet</code>预训练模型对RPN网络做<code>finetune</code>（RPN的作用在上面说过，这里<code>finetune</code>的目的是为了生成更好的<code>region proposal</code>）；</li><li>用第一步得到的<code>region proposal</code>单独的训练一个<code>Fast RCNN</code>（<code>Fast RCNN</code>的参数也由<code>ImageNet</code>的与训练模型初始化，但这里不共享参数）；</li><li>使用第2步训练好的<code>Fast RCNN</code>模型做预训练模型，固定<code>RPN</code>层以外的参数，只对<code>RPN</code>层做<code>finetune</code>，这里已经开始共享卷积层了；</li><li>最后一步，固定共享卷积层的参数，对<code>fast RCNN</code>部分做<code>finetune</code>，至此，整个<code>faster RCNN</code>训练完成。</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;code&gt;Faster RCNN&lt;/code&gt;是为目标检测而提出的一种网络，目标检测的任务是从一张给定的图片中不仅要对图像中的物体进行分类，而且要为每个类别的物体加一个&lt;code&gt;Box&lt;/code&gt;，也就是要确定检测到的物体的位置。&lt;/p&gt;
    
    </summary>
    
      <category term="论文阅读" scheme="http://www.junyuanw.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"/>
    
    
      <category term="python" scheme="http://www.junyuanw.com/tags/python/"/>
    
      <category term="Faster RCNN" scheme="http://www.junyuanw.com/tags/Faster-RCNN/"/>
    
      <category term="论文阅读" scheme="http://www.junyuanw.com/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"/>
    
  </entry>
  
  <entry>
    <title>Leetcode-Search Insert Position</title>
    <link href="http://www.junyuanw.com/2019/04/29/Leetcode035-Search%20Insert%20Position/"/>
    <id>http://www.junyuanw.com/2019/04/29/Leetcode035-Search Insert Position/</id>
    <published>2019-04-29T04:00:00.000Z</published>
    <updated>2020-08-09T11:08:27.664Z</updated>
    
    <content type="html"><![CDATA[<p>Given a sorted array and a target value, return the index if the target is found. If not, return the index where it would be if it were inserted in order.</p><a id="more"></a><p>You may assume no duplicates in the array.</p><p><strong>Example 1:</strong></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Input: [<span class="number">1</span>,<span class="number">3</span>,<span class="number">5</span>,<span class="number">6</span>], <span class="number">5</span></span><br><span class="line">Output: <span class="number">2</span></span><br></pre></td></tr></table></figure><p><strong>Example 2:</strong></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Input: [<span class="number">1</span>,<span class="number">3</span>,<span class="number">5</span>,<span class="number">6</span>], <span class="number">2</span></span><br><span class="line">Output: <span class="number">1</span></span><br></pre></td></tr></table></figure><p><strong>Example 3:</strong></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Input: [<span class="number">1</span>,<span class="number">3</span>,<span class="number">5</span>,<span class="number">6</span>], <span class="number">7</span></span><br><span class="line">Output: <span class="number">4</span></span><br></pre></td></tr></table></figure><p><strong>Example 4:</strong></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Input: [<span class="number">1</span>,<span class="number">3</span>,<span class="number">5</span>,<span class="number">6</span>], <span class="number">0</span></span><br><span class="line">Output: <span class="number">0</span></span><br></pre></td></tr></table></figure><p><strong>Solution:</strong></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">searchInsert</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums, <span class="keyword">int</span> target)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> res = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">if</span> (nums.size() == <span class="number">0</span> || nums[<span class="number">0</span>] &gt; target) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> (nums.back() &lt; target) &#123;</span><br><span class="line">            <span class="keyword">return</span> nums.size();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; nums.size() - <span class="number">1</span>; i++) &#123;</span><br><span class="line">                <span class="keyword">if</span> (nums[i] == target) &#123;</span><br><span class="line">                    res = i;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">if</span> (nums[i] &lt; target &amp;&amp; nums[i+<span class="number">1</span>] &gt;= target) &#123;</span><br><span class="line">                    res = i+<span class="number">1</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">return</span> res;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><div class="table-container"><table><thead><tr><th style="text-align:left">Time Submitted</th><th style="text-align:left">Status</th><th style="text-align:left">Runtime</th><th style="text-align:left">Memory</th><th style="text-align:left">Language</th></tr></thead><tbody><tr><td style="text-align:left">a few seconds ago</td><td style="text-align:left"><a href="https://leetcode.com/submissions/detail/225636350/" target="_blank" rel="noopener">Accepted</a></td><td style="text-align:left">8 ms</td><td style="text-align:left">8.9 MB</td><td style="text-align:left">cpp</td></tr></tbody></table></div><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Runtime: 8 ms, faster than 98.61% of C++ online submissions for Search Insert Position.</span><br><span class="line">Memory Usage: 8.9 MB, less than 98.08% of C++ online submissions for Search Insert Position.</span><br></pre></td></tr></table></figure><p>查找的部分应该还可以优化，用二分查找做还可以再快一点。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Given a sorted array and a target value, return the index if the target is found. If not, return the index where it would be if it were inserted in order.&lt;/p&gt;
    
    </summary>
    
      <category term="Leetcode" scheme="http://www.junyuanw.com/categories/Leetcode/"/>
    
    
      <category term="C++" scheme="http://www.junyuanw.com/tags/C/"/>
    
      <category term="algorithm" scheme="http://www.junyuanw.com/tags/algorithm/"/>
    
  </entry>
  
</feed>
